{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cedbb1b4",
   "metadata": {},
   "source": [
    "\n",
    "<div style=\"background-color:#CCCCCC; padding:12px; border-radius:8px;\">\n",
    "<h1 style=\"color:#003366; text-align:center; margin:8px 0;\">Revisión y limpieza de 3 DataFrames (TPI - Data Analytics)</h1>\n",
    "<p style=\"text-align:center; color:#003366; margin:0;\"><em>Notebook docente en castellano — nombres descriptivos en snake_case — código y documentación</em></p>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c723b86a",
   "metadata": {},
   "source": [
    "\n",
    "<div style=\"background-color:#CCCCCC; padding:10px; border-radius:6px;\">\n",
    "<h2 style=\"color:black; text-align:center; margin-top:6px;\">Resumen</h2>\n",
    "\n",
    "<p style=\"color:black;\">\n",
    "Este notebook está diseñado con finalidades pedagógicas. Revisa, normaliza y valida tres datasets contenidos en CSV:\n",
    "</p>\n",
    "\n",
    "<ul style=\"color:black;\">\n",
    "<li><code>marketing.csv</code> → variable: <code>df_marketing</code></li>\n",
    "<li><code>ventas.csv</code> → variable: <code>df_ventas</code></li>\n",
    "<li><code>clientes.csv</code> → variable: <code>df_clientes</code></li>\n",
    "</ul>\n",
    "\n",
    "<p style=\"color:black;\">\n",
    "Coloca los CSV en <code>./data_in/</code> o en <code>/mnt/data/</code>. El notebook busca primero en <code>./data_in/</code> y si no encuentra, usa <code>/mnt/data/</code> (útil para entornos donde los archivos están pre-subidos).\n",
    "</p>\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be46fb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports y configuración inicial (nombres en castellano)\n",
    "import os\n",
    "from pathlib import Path\n",
    "import json\n",
    "import unicodedata\n",
    "import zipfile\n",
    "\n",
    "#!pip install gdown\n",
    "\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import zipfile\n",
    "from collections import defaultdict\n",
    "from datetime import datetime\n",
    "from math import isnan\n",
    "ruta_base = \"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63edff5b-828e-4254-a4d7-4b0ef05ecea6",
   "metadata": {},
   "source": [
    "## 1. Crear un documento en Google Colaboratory y cargar los sets de datos como DataFrames"
   ]
  },
  {
   "cell_type": "raw",
   "id": "97e86735-e26d-4583-a22b-a2d79a57666c",
   "metadata": {},
   "source": [
    "# --- Paso 1: Montar Google Drive ---\n",
    "# Montar tu Google Drive\n",
    "!pip install google\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "!ls \"/content/drive/MyDrive/CABA/Garcia Traba Ariel H - Comisión 25262 - TPI Data Analytics/\"\n",
    "# Ruta del archivo (ajústala a la carpeta real en tu Drive)\n",
    "ruta_base = \"/content/drive/MyDrive/CABA/Garcia Traba Ariel H - Comisión 25262 - TPI Data Analytics/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "605182b8-9652-410e-8c79-13b10a33e692",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rutas: busca en ./data_in primero, si no existe usa /mnt/data\n",
    "\n",
    "carpeta_entrada    = Path(ruta_base)\n",
    "#carpeta_entrada_mnt   = Path('/mnt/data')\n",
    "\n",
    "carpeta_reportes   = carpeta_entrada / 'reportes'\n",
    "carpeta_reportes.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "carpeta_limpios    = carpeta_entrada / 'limpios'\n",
    "carpeta_limpios.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Nombres esperados de archivos\n",
    "archivo_ventas     = 'ventas.csv'\n",
    "archivo_clientes   = 'clientes.csv'\n",
    "archivo_marketing  = 'marketing.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "052e6d76-d227-4749-af2c-f065eabf82f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargando datasets del curso...\n"
     ]
    }
   ],
   "source": [
    "# --- Paso 3: Cargar archivos del curso ---\n",
    "print(\"Cargando datasets del curso...\")\n",
    "ruta_ventas     = os.path.join(ruta_base, archivo_ventas)\n",
    "ruta_clientes   = os.path.join(ruta_base, archivo_clientes)\n",
    "ruta_marketing  = os.path.join(ruta_base, archivo_marketing)\n",
    "\n",
    "df_ventas    = pd.read_csv(f\"{ruta_ventas}\")\n",
    "df_clientes  = pd.read_csv(f\"{ruta_clientes}\")\n",
    "df_marketing = pd.read_csv(f\"{ruta_marketing}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a06a6528-ba7e-4f2c-889a-5d428f5a1cf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "df_ventas\n",
      "      id_venta                producto   precio  cantidad fecha_venta  \\\n",
      "0          792       Cuadro decorativo   $69.94       5.0  02/01/2024   \n",
      "1          811         Lámpara de mesa  $105.10       5.0  02/01/2024   \n",
      "2         1156                Secadora   $97.96       3.0  02/01/2024   \n",
      "3         1372                Heladera  $114.35       8.0  02/01/2024   \n",
      "4         1546                Secadora  $106.21       4.0  02/01/2024   \n",
      "...        ...                     ...      ...       ...         ...   \n",
      "3030      1837         Horno eléctrico  $104.12       9.0  30/12/2024   \n",
      "3031      2276                  Laptop   $85.27       9.0  30/12/2024   \n",
      "3032      2696                  Laptop  $107.81       4.0  30/12/2024   \n",
      "3033      2913              Smartphone   $99.85       7.0  30/12/2024   \n",
      "3034      2930  Consola de videojuegos   $55.47       6.0  30/12/2024   \n",
      "\n",
      "              categoria  \n",
      "0            Decoración  \n",
      "1            Decoración  \n",
      "2     Electrodomésticos  \n",
      "3     Electrodomésticos  \n",
      "4     Electrodomésticos  \n",
      "...                 ...  \n",
      "3030  Electrodomésticos  \n",
      "3031        Electrónica  \n",
      "3032        Electrónica  \n",
      "3033        Electrónica  \n",
      "3034        Electrónica  \n",
      "\n",
      "[3035 rows x 6 columns]\n",
      "**************************************************\n",
      "df_clientes\n",
      "     id_cliente               nombre  edad         ciudad  ingresos\n",
      "0             1      Aloysia Screase    44  Mar del Plata  42294.68\n",
      "1             2  Kristina Scaplehorn    25        Posadas  24735.04\n",
      "2             3       Filip Castagne    50    Resistencia  35744.85\n",
      "3             4          Liuka Luard    39   Bahía Blanca  27647.96\n",
      "4             5        Dore Cockshtt    28        Rosario  28245.65\n",
      "..          ...                  ...   ...            ...       ...\n",
      "562         563        Dione Forsyde    29        Posadas  26757.73\n",
      "563         564          Fleming Gow    39       Santa Fe  43674.96\n",
      "564         565      Jewelle Mabbett    33        Córdoba  30522.64\n",
      "565         566          Lauri Munns    23    Resistencia  31259.14\n",
      "566         567          Micah Matis    31     Corrientes  42927.86\n",
      "\n",
      "[567 rows x 5 columns]\n",
      "**************************************************\n",
      "df_marketing\n",
      "    id_campanha            producto  canal  costo fecha_inicio   fecha_fin\n",
      "0            74     Adorno de pared     TV   4.81   20/03/2024  03/05/2024\n",
      "1            12              Tablet   RRSS   3.40   26/03/2024  13/05/2024\n",
      "2            32     Lámpara de mesa  Email   5.54   28/03/2024  20/04/2024\n",
      "3            21          Smartphone   RRSS   6.37   29/03/2024  16/05/2024\n",
      "4            58            Alfombra  Email   4.25   31/03/2024  05/05/2024\n",
      "..          ...                 ...    ...    ...          ...         ...\n",
      "85           70          Aspiradora     TV   3.06   13/12/2024  29/12/2024\n",
      "86           89           Televisor     TV   4.98   13/12/2024    8/2/2025\n",
      "87           68   Rincón de plantas     TV   5.81   17/12/2024   14/2/2025\n",
      "88           33            Secadora  Email   3.80   20/12/2024    7/1/2025\n",
      "89           11  Freidora eléctrica   RRSS   5.27   29/12/2024   21/1/2025\n",
      "\n",
      "[90 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "# Mostrar el DataFrame\n",
    "print(f\"\"\"\n",
    "df_ventas\n",
    "{df_ventas}\n",
    "{\"*\"*50}\n",
    "df_clientes\n",
    "{df_clientes}\n",
    "{\"*\"*50}\n",
    "df_marketing\n",
    "{df_marketing}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21030142",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Funciones utilitarias en castellano (snake_case) ----------\n",
    "def sacar_acentos(texto):\n",
    "    \"\"\"\n",
    "    Elimina acentos (tildes/diacríticos) de un texto.\n",
    "    Mantiene NaN intactos.\n",
    "    \"\"\"\n",
    "    if pd.isna(texto):\n",
    "        return texto\n",
    "    texto = str(texto)\n",
    "    nk = unicodedata.normalize('NFKD', texto)\n",
    "    return ''.join([c for c in nk if not unicodedata.combining(c)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4aefb8b-3e14-4917-9986-8b7f27033cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKENS_VALOR_FALTANTE = {\n",
    "    '', 'na', 'n/a', 'null', 'none', 'sin dato', 's/d', 'nd', '-', '--', '?', 'sin_dato', 'n/d'\n",
    "}\n",
    "\n",
    "def es_valor_faltante(valor):\n",
    "    \"\"\"\n",
    "    Determina si un valor debe considerarse faltante (True) usando tokens y NaN.\n",
    "    \"\"\"\n",
    "    if pd.isna(valor):\n",
    "        return True\n",
    "    s = str(valor).strip().lower()\n",
    "    s = sacar_acentos(s)\n",
    "    return s in TOKENS_VALOR_FALTANTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ddbaa5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Funciones de limpieza ----------\n",
    "def aplicar_regla_columna(serie, regla):\n",
    "    \"\"\"\n",
    "    Aplica una regla a una serie (columna).\n",
    "    Firma compatible con la versión anterior (reemplaza la implementación previa).\n",
    "    regla puede ser:\n",
    "      - 'strip','lower','upper','title','quitar_acentos','numeric','date'\n",
    "    o un tuple (tipo, opciones) con opciones:\n",
    "      - numeric: remove_non_digits (bool), remove_thousands (bool), as_int (bool), thousands_separator (',' o '.')\n",
    "      - date: formats (list), dayfirst (bool), format_output ('YYYY/MM/DD' para forzar cadena)\n",
    "      - texto: normalizar_acentos (bool)\n",
    "    Retorna la serie transformada (sin forzar dtype final).\n",
    "    \"\"\"\n",
    "    tipo, opts = regla if isinstance(regla, tuple) else (regla, {})\n",
    "    opts = opts or {}\n",
    "    s = serie.copy()\n",
    "\n",
    "    # -------- Texto y normalización de acentos opcional --------\n",
    "    if tipo == 'strip':\n",
    "        s = s.map(lambda x: str(x).strip() if not pd.isna(x) else x)\n",
    "    elif tipo == 'lower':\n",
    "        s = s.map(lambda x: str(x).strip().lower() if not pd.isna(x) else x)\n",
    "        if opts.get('normalizar_acentos'):\n",
    "            s = s.map(lambda x: sacar_acentos(x) if not pd.isna(x) else x)\n",
    "    elif tipo == 'upper':\n",
    "        s = s.map(lambda x: str(x).strip().upper() if not pd.isna(x) else x)\n",
    "        if opts.get('normalizar_acentos'):\n",
    "            s = s.map(lambda x: sacar_acentos(x) if not pd.isna(x) else x)\n",
    "    elif tipo == 'title':\n",
    "        s = s.map(lambda x: str(x).strip().title() if not pd.isna(x) else x)\n",
    "        if opts.get('normalizar_acentos'):\n",
    "            s = s.map(lambda x: sacar_acentos(x) if not pd.isna(x) else x)\n",
    "    elif tipo == 'quitar_acentos':\n",
    "        s = s.map(lambda x: sacar_acentos(x).strip() if not pd.isna(x) else x)\n",
    "\n",
    "    # -------- Numeric robusto --------\n",
    "    elif tipo == 'numeric':\n",
    "        def to_num(v):\n",
    "            if pd.isna(v):\n",
    "                return np.nan\n",
    "            t = str(v).strip()\n",
    "            t = t.replace('$', '')\n",
    "            if opts.get('remove_non_digits', False):\n",
    "                t = ''.join([c for c in t if c.isdigit() or c in '.-'])\n",
    "            if opts.get('remove_thousands', False):\n",
    "                sep = opts.get('thousands_separator', ',')\n",
    "                if sep == ',':\n",
    "                    # Quitar puntos mil y comas de decimales no soportadas -> suponer coma miles y punto decimales\n",
    "                    t = t.replace('.', '').replace(',', '')\n",
    "                else:\n",
    "                    t = t.replace(',', '').replace('.', '')   \n",
    "            try:\n",
    "                val = pd.to_numeric(t, errors='coerce')\n",
    "                if opts.get('as_int', False):\n",
    "                    if pd.isna(val):\n",
    "                        return pd.NA\n",
    "                    try:\n",
    "                        # intentar entero simple\n",
    "                        return int(val)\n",
    "                    except Exception:\n",
    "                        return pd.NA\n",
    "                return float(val) if not pd.isna(val) else np.nan\n",
    "            except Exception:\n",
    "                return np.nan\n",
    "        s = s.map(to_num)\n",
    "\n",
    "    # -------- Fecha robusta --------\n",
    "    elif tipo == 'date':\n",
    "        formatos = opts.get('formats', [])\n",
    "        dayfirst = opts.get('dayfirst', True)\n",
    "        def to_date(v):\n",
    "            if pd.isna(v):\n",
    "                return pd.NaT\n",
    "            t = str(v).strip()\n",
    "            # Probar formatos explícitos\n",
    "            for fmt in formatos:\n",
    "                try:\n",
    "                    return pd.to_datetime(datetime.strptime(t, fmt))\n",
    "                except Exception:\n",
    "                    continue\n",
    "            # Fallback: pandas con dayfirst\n",
    "            try:\n",
    "                return pd.to_datetime(t, dayfirst=dayfirst, errors='coerce')\n",
    "            except Exception:\n",
    "                return pd.NaT\n",
    "        s = s.map(to_date)\n",
    "\n",
    "    else:\n",
    "        # Default: trim y convertir tokens faltantes a NaN para texto\n",
    "        if s.dtype == object or pd.api.types.is_string_dtype(s):\n",
    "            s = s.map(lambda x: np.nan if es_valor_faltante(x) else (str(x).strip() if not pd.isna(x) else x))\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e185c054-2f13-4a34-be4d-67dbd546abc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertir_tipos_postprocesamiento(df, reglas_por_columna):\n",
    "    \"\"\"\n",
    "    Garantiza dtypes correctos:\n",
    "     - Para columnas numeric: pd.to_numeric(...) + conversión a Int64 nullable si as_int, o float.\n",
    "     - Para columnas date: intenta parsear según formatos; deja datetime64[ns] o, si 'format_output'=='YYYY/MM/DD', devuelve strings con ese formato.\n",
    "    \"\"\"\n",
    "    df2 = df.copy()\n",
    "    for col, regla in (reglas_por_columna or {}).items():\n",
    "        tipo = regla if not isinstance(regla, tuple) else regla[0]\n",
    "        opts = {} if not isinstance(regla, tuple) else regla[1] or {}\n",
    "        if tipo == 'numeric':\n",
    "            df2[col] = pd.to_numeric(df2[col], errors='coerce')\n",
    "            if opts.get('as_int', False):\n",
    "                # convertir a Int64 nullable\n",
    "                try:\n",
    "                    df2[col] = df2[col].astype('Int64')\n",
    "                except Exception:\n",
    "                    # fallback: mantener float si conversion falla\n",
    "                    df2[col] = pd.to_numeric(df2[col], errors='coerce')\n",
    "        elif tipo == 'date':\n",
    "            formatos = opts.get('formats', [])\n",
    "            dayfirst = opts.get('dayfirst', True)\n",
    "            parsed = pd.Series(pd.NaT, index=df2.index)\n",
    "            # probar formatos explícitos uno por uno\n",
    "            for fmt in formatos:\n",
    "                try:\n",
    "                    mask_necesita = parsed.isna()\n",
    "                    intent = pd.to_datetime(df2.loc[mask_necesita, col].astype(str), format=fmt, errors='coerce')\n",
    "                    parsed.loc[mask_necesita] = intent\n",
    "                except Exception:\n",
    "                    pass\n",
    "            # fallback general para los que quedaron NaT\n",
    "            still_na = parsed.isna()\n",
    "            if still_na.any():\n",
    "                parsed.loc[still_na] = pd.to_datetime(df2.loc[still_na, col].astype(str), dayfirst=dayfirst, errors='coerce')\n",
    "            df2[col] = parsed\n",
    "            if opts.get('format_output') == 'YYYY/MM/DD':\n",
    "                # convertir a string con formato pedido (mantener NaT como NaN)\n",
    "                df2[col] = df2[col].dt.strftime('%Y/%m/%d')\n",
    "    for col in df2.select_dtypes(include=['object']).columns:\n",
    "        df2[col] = df2[col].map(sacar_acentos)\n",
    "    return df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "337bd9f4-5291-4b9d-af66-23a8e3086c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def limpiar_dataframe(df, reglas_por_columna=None):\n",
    "    \"\"\"\n",
    "    Limpieza principal (misma firma que antes):\n",
    "     1) Aplica aplicar_regla_columna por cada columna según reglas_por_columna\n",
    "     2) Para columnas texto por defecto: strip + tokens faltantes -> NaN\n",
    "     3) Elimina duplicados exactos\n",
    "     4) Convierte tipos numéricos y fechas con convertir_tipos_postprocesamiento\n",
    "    Retorna df limpio con dtypes corregidos.\n",
    "\n",
    "    Aplica reglas de limpieza columna por columna.\n",
    "    Si una columna no existe en el DataFrame, se omite con aviso educativo.\n",
    "    \"\"\"\n",
    "    #reglas_por_columna = reglas_por_columna or {}\n",
    "\n",
    "    reglas_por_columna = reglas_por_columna or {}\n",
    "    df2 = df.copy()\n",
    "    df2.columns = [str(c).strip() for c in df2.columns]\n",
    "\n",
    "    for col in df2.columns:\n",
    "        if col in reglas_por_columna:\n",
    "            # usar la función aplicar_regla_columna existente en el notebook\n",
    "            df2[col] = aplicar_regla_columna(df2[col], reglas_por_columna[col])\n",
    "        else:\n",
    "            if df2[col].dtype == object or pd.api.types.is_string_dtype(df2[col]):\n",
    "                df2[col] = df2[col].map(lambda x: np.nan if es_valor_faltante(x) else (str(x).strip() if not pd.isna(x) else x))\n",
    "\n",
    "    # eliminar duplicados exactos\n",
    "    df2 = df2.drop_duplicates(keep='first').reset_index(drop=True)\n",
    "\n",
    "    # intentos de post-conversión sencillos para numeric/date según reglas:\n",
    "    for col, regla in (reglas_por_columna or {}).items():\n",
    "        tipo = regla if not isinstance(regla, tuple) else regla[0]\n",
    "        opts = {} if not isinstance(regla, tuple) else regla[1] or {}\n",
    "        if tipo == 'numeric':\n",
    "            df2[col] = pd.to_numeric(df2[col], errors='coerce')\n",
    "            if opts.get('as_int', False):\n",
    "                try:\n",
    "                    df2[col] = df2[col].astype('Int64')\n",
    "                except Exception:\n",
    "                    pass\n",
    "        elif tipo == 'date':\n",
    "            formatos = opts.get('formats', [])\n",
    "            dayfirst = opts.get('dayfirst', True)\n",
    "            parsed = pd.Series(pd.NaT, index=df2.index)\n",
    "            for fmt in formatos:\n",
    "                try:\n",
    "                    mask = parsed.isna()\n",
    "                    parsed.loc[mask] = pd.to_datetime(df2.loc[mask, col].astype(str), format=fmt, errors='coerce')\n",
    "                except Exception:\n",
    "                    pass\n",
    "            still_na = parsed.isna()\n",
    "            if still_na.any():\n",
    "                parsed.loc[still_na] = pd.to_datetime(df2.loc[still_na, col].astype(str), dayfirst=dayfirst, errors='coerce')\n",
    "            # si se pidió format_output, devolver cadena con YYYY/MM/DD\n",
    "            if opts.get('format_output') == 'YYYY/MM/DD':\n",
    "                df2[col] = parsed.dt.strftime('%Y/%m/%d')\n",
    "            else:\n",
    "                df2[col] = parsed\n",
    "\n",
    "    return df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4634aeae-c21a-47dc-9bb9-cffdeafcbe54",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Detección de outliers (IQR) - función corregida y robusta\n",
    "def mascara_valores_atipicos_rango_intercuartil(serie_datos):\n",
    "    \"\"\"\n",
    "    Devuelve una tupla: (mascara_bool_series, cantidad_outliers, (limite_inferior, limite_superior))\n",
    "    - serie_datos: pd.Series (acepta valores no numéricos, se intentará convertir)\n",
    "    - La máscara tiene la misma indexación que la serie original (NaNs -> False)\n",
    "    \"\"\"\n",
    "    # Intentar convertir a numérico (coerce -> NaN para no numéricos)\n",
    "    serie_numerica = pd.to_numeric(serie_datos, errors='coerce')\n",
    "    # Serie limpia para cálculos de cuartiles (sin NaN)\n",
    "    serie_limpia = serie_numerica.dropna().astype(float)\n",
    "    if serie_limpia.shape[0] < 4:\n",
    "        # No hay suficientes datos para IQR: devolver máscara False de la misma longitud\n",
    "        mascara = pd.Series([False] * len(serie_datos), index=serie_datos.index)\n",
    "        return mascara, int(mascara.sum()), (None, None)\n",
    "    cuartil_1 = float(serie_limpia.quantile(0.25))\n",
    "    cuartil_3 = float(serie_limpia.quantile(0.75))\n",
    "    rango_intercuartil = cuartil_3 - cuartil_1\n",
    "    limite_inferior = cuartil_1 - 1.5 * rango_intercuartil\n",
    "    limite_superior = cuartil_3 + 1.5 * rango_intercuartil\n",
    "    # Crear máscara sobre la serie numérica original (alineada con el index original)\n",
    "    mascara = (serie_numerica < limite_inferior) | (serie_numerica > limite_superior)\n",
    "    mascara = mascara.fillna(False).astype(bool)\n",
    "    return mascara, int(mascara.sum()), (limite_inferior, limite_superior)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4c15444c-3df6-409e-a932-c08afaebfd51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detección de outliers (Z-score)\n",
    "def mascara_valores_atipicos_zscore(serie_datos, umbral=3.0):\n",
    "    \"\"\"\n",
    "    Devuelve máscara booleana (True = outlier) según Z-score.\n",
    "    \"\"\"\n",
    "    serie_limpia = serie_datos.dropna().astype(float)\n",
    "    if serie_limpia.shape[0] < 4 or serie_limpia.std() == 0:\n",
    "        return pd.Series([False] * len(serie_datos), index=serie_datos.index)\n",
    "    puntaje_z = (serie_datos - serie_limpia.mean()) / serie_limpia.std()\n",
    "    return puntaje_z.abs() > umbral    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "32837ebb-e71d-4c31-bcfc-9e747390519e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Funciones utilitarias definidas.\n"
     ]
    }
   ],
   "source": [
    "print('Funciones utilitarias definidas.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f411cb90-17af-45f2-9dfb-9fe7534bacbb",
   "metadata": {},
   "source": [
    "# limpieza y normalización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fe131403",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Función detectar_problemas_en_dataframe cargada.\n"
     ]
    }
   ],
   "source": [
    "# ---------- Detección de problemas en un DataFrame ----------\n",
    "def detectar_problemas_en_dataframe(df: pd.DataFrame):\n",
    "    \n",
    "    resumen = {}\n",
    "    resumen['filas'] = df.shape[0]\n",
    "    resumen['columnas'] = df.shape[1]\n",
    "    resumen['nulos_por_columna'] = df.isna().sum().to_dict()\n",
    "    dup_mask = df.duplicated(keep=False)\n",
    "    resumen['duplicados_exactos'] = int(dup_mask.sum())\n",
    "\n",
    "    chequeos_por_columna = {}\n",
    "    for col in df.columns:\n",
    "        serie = df[col]\n",
    "        info = {'dtype': str(serie.dtype), 'nulos': int(serie.isna().sum())}\n",
    "        # texto\n",
    "        if serie.dtype == object or pd.api.types.is_string_dtype(serie):\n",
    "            s = serie.astype(str)\n",
    "            info['espacios_inicio'] = int(s.str.match(r'^\\s+').sum())\n",
    "            info['espacios_final'] = int(s.str.match(r'\\s+$').sum())\n",
    "            try:\n",
    "                unique_original = set(s.dropna().unique())\n",
    "                unique_lower = set(s.dropna().str.lower().unique())\n",
    "                info['unique_original'] = len(unique_original)\n",
    "                info['unique_lower'] = len(unique_lower)\n",
    "                info['variantes_mayusculas'] = len(unique_lower) < len(unique_original)\n",
    "            except Exception:\n",
    "                info['unique_original'] = serie.nunique(dropna=True)\n",
    "                info['unique_lower'] = None\n",
    "                info['variantes_mayusculas'] = None\n",
    "            try:\n",
    "                unaccented = s.dropna().map(lambda x: sacar_acentos(x).lower())\n",
    "                groups = unaccented.groupby(unaccented).size()\n",
    "                conflicts = groups[groups > 1]\n",
    "                info['grupos_variantes_acentos'] = int(conflicts.shape[0])\n",
    "                ejemplos = {}\n",
    "                if not conflicts.empty:\n",
    "                    for val in conflicts.index[:5]:\n",
    "                        originales = sorted(list(s[unaccented == val].unique())[:10])\n",
    "                        ejemplos[val] = originales\n",
    "                info['ejemplos_variantes_acentos'] = ejemplos\n",
    "            except Exception:\n",
    "                info['grupos_variantes_acentos'] = None\n",
    "                info['ejemplos_variantes_acentos'] = {}\n",
    "            info['tokens_aparente_faltante'] = int(\n",
    "                s.map(lambda x: str(x).strip().lower()).map(lambda v: sacar_acentos(v) in TOKENS_VALOR_FALTANTE).sum()\n",
    "            )\n",
    "            info['muestras'] = list(s.dropna().unique()[:10])\n",
    "        else:\n",
    "            # numeric\n",
    "            if pd.api.types.is_numeric_dtype(serie) or (serie.dropna().astype(str).str.replace('.','',1).str.isnumeric().all() if len(serie.dropna())>0 else False):\n",
    "                try:\n",
    "                    serie_numerica = serie.dropna().astype(float)\n",
    "                except Exception:\n",
    "                    serie_numerica = pd.to_numeric(serie, errors='coerce').dropna().astype(float)\n",
    "                info['media'] = float(serie_numerica.mean()) if not serie_numerica.empty else None\n",
    "                info['std'] = float(serie_numerica.std()) if not serie_numerica.empty else None\n",
    "                info['min'] = float(serie_numerica.min()) if not serie_numerica.empty else None\n",
    "                info['max'] = float(serie_numerica.max()) if not serie_numerica.empty else None\n",
    "               \n",
    "                if len(serie_numerica) >= 4:\n",
    "                    cuartil_1 = serie_numerica.quantile(0.25)\n",
    "                    cuartil_3 = serie_numerica.quantile(0.75)\n",
    "                    rango_intercuartil = cuartil_3 - cuartil_1\n",
    "                    limite_inferior = cuartil_1 - 1.5 * rango_intercuartil\n",
    "                    limite_superior = cuartil_3 + 1.5 * rango_intercuartil\n",
    "                    mascara_outliers_iqr,info['outliers_iqr'] ,info['limites_iqr'] =mascara_valores_atipicos_rango_intercuartil(serie)\n",
    "                    \n",
    "                else:\n",
    "                    info['outliers_iqr'] = None\n",
    "                    info['limites_iqr'] = None\n",
    "                if len(serie_numerica) >= 4 and serie_numerica.std() != 0:\n",
    "                    z = (serie_numerica - serie_numerica.mean()) / serie_numerica.std()\n",
    "                    info['outliers_z'] = int((z.abs() > 3).sum())\n",
    "                else:\n",
    "                    info['outliers_z'] = None\n",
    "            else:\n",
    "                # fechas intento parseo\n",
    "                parsed = pd.to_datetime(serie, errors='coerce', dayfirst=True)\n",
    "                info['fechas_parseables'] = int(parsed.notna().sum())\n",
    "                info['muestras'] = list(serie.dropna().unique()[:10])\n",
    "        chequeos_por_columna[col] = info\n",
    "\n",
    "    filas_problemas = []\n",
    "    for idx, fila in df.iterrows():\n",
    "        lista_problemas = []\n",
    "        if dup_mask.loc[idx]:\n",
    "            lista_problemas.append('duplicado_exacto')\n",
    "        for col in df.columns:\n",
    "            val = fila[col]\n",
    "            # heurísticas textuales\n",
    "            if pd.api.types.is_string_dtype(type(val)) or isinstance(val, str) or (\n",
    "                not pd.isna(val) and not pd.api.types.is_numeric_dtype(type(val)) and str(chequeos_por_columna[col].get('dtype','')).startswith('object')\n",
    "            ):\n",
    "                s = str(val)\n",
    "                if s != s.strip():\n",
    "                    lista_problemas.append(f'espacios_en_columna_{col}')\n",
    "                if chequeos_por_columna[col].get('variantes_mayusculas'):\n",
    "                    if s and s != s.lower() and s.lower() in [str(x).lower() for x in df[col].dropna().unique()]:\n",
    "                        lista_problemas.append(f'inconsistencia_mayusculas_columna_{col}')\n",
    "                if chequeos_por_columna[col].get('grupos_variantes_acentos') and chequeos_por_columna[col]['grupos_variantes_acentos'] > 0:\n",
    "                    try:\n",
    "                        un = sacar_acentos(s).lower()\n",
    "                        group_vals = [x for x in chequeos_por_columna[col].get('muestras', []) if sacar_acentos(str(x)).lower() == un]\n",
    "                        if group_vals and any(sacar_acentos(str(x)).lower() != sacar_acentos(s).lower() for x in group_vals):\n",
    "                            lista_problemas.append(f'variantes_acentos_columna_{col}')\n",
    "                    except Exception:\n",
    "                        pass\n",
    "                if es_valor_faltante(s):\n",
    "                    lista_problemas.append(f'token_faltante_columna_{col}')\n",
    "            else:\n",
    "                # heurísticas numéricas\n",
    "                try:\n",
    "                    fval = float(val)\n",
    "                    info_col = chequeos_por_columna[col]\n",
    "                    limites = info_col.get('limites_iqr')\n",
    "                    if limites and (fval < limites[0] or fval > limites[1]):\n",
    "                        lista_problemas.append(f'outlier_iqr_columna_{col}')\n",
    "                    if info_col.get('std') not in (None, 0):\n",
    "                        mean = info_col.get('media')\n",
    "                        std = info_col.get('std')\n",
    "                        if std and abs((fval - mean) / std) > 3:\n",
    "                            lista_problemas.append(f'outlier_z_columna_{col}')\n",
    "                except Exception:\n",
    "                    pass\n",
    "        if lista_problemas:\n",
    "            filas_problemas.append({\n",
    "                'row_index': idx,\n",
    "                'problemas': ';'.join(sorted(set(lista_problemas))),\n",
    "                'muestra': json.dumps({str(c): str(fila[c]) for c in df.columns[:8]})\n",
    "            })\n",
    "\n",
    "    df_problemas = pd.DataFrame(filas_problemas)\n",
    "    return resumen, chequeos_por_columna, df_problemas\n",
    "\n",
    "print('Función detectar_problemas_en_dataframe cargada.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6e42599a-abe2-4447-b8e6-6c1024f0d651",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función auxiliar para guardar CSVs\n",
    "def guardar_csv(df, ruta):\n",
    "    \"\"\"\n",
    "    Guarda df en ruta (string o Path). Crea directorio padre si no existe.\n",
    "    \"\"\"\n",
    "    ruta = Path(ruta)\n",
    "    ruta.parent.mkdir(parents=True, exist_ok=True)\n",
    "    df.to_csv(ruta, index=False, encoding='utf-8')\n",
    "    return ruta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ccc0f0c3-0e31-4f27-9661-3215c9185f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_frames = {\n",
    "    ruta_ventas     : df_ventas,\n",
    "    ruta_clientes   : df_clientes,\n",
    "    ruta_marketing  : df_marketing\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "895c63d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Proceso principal para los 3 CSV ----------\n",
    "#id_campanha,producto,canal,costo,fecha_inicio,fecha_fin\n",
    "reglas_marketing = {\n",
    "                        'producto': ('lower', {'normalizar_acentos': True}),\n",
    "                        'canal': ('lower', {'normalizar_acentos': True}),\n",
    "                        'costo': ('numeric', {'remove_thousands': True, 'as_int': False}),\n",
    "                        'fecha_inicio': ('date', {'dayfirst': True, 'formats': ['%d/%m/%Y', '%Y-%m-%d']}),\n",
    "                        'fecha_fin': ('date', {'dayfirst': True, 'formats': ['%d/%m/%Y', '%Y-%m-%d']})\n",
    "}\n",
    "# id_venta,producto,precio,cantidad,fecha_venta,categoria\n",
    "reglas_ventas = {\n",
    "                        'producto': ('lower', {'normalizar_acentos': True}),\n",
    "                        'precio': ('numeric', {'remove_thousands': True, 'as_int': False}),\n",
    "                        'cantidad': ('numeric', {'remove_thousands': True, 'as_int': False}),\n",
    "                        'fecha_venta': ('date', {'dayfirst': True, 'formats': ['%d/%m/%Y', '%Y-%m-%d']}),\n",
    "                        'categoria': ('lower', {'normalizar_acentos': True})\n",
    "}\n",
    "#id_cliente,nombre,edad,ciudad,ingresos\n",
    "reglas_clientes = {\n",
    "                        'nombre': ('title', {'normalizar_acentos': True}),\n",
    "                        'edad': ('numeric', {'remove_thousands': True, 'as_int': True}),\n",
    "                        'ciudad': ('title', {'normalizar_acentos': True}),\n",
    "                        'ingresos': ('numeric', {'remove_thousands': True, 'as_int': False})\n",
    "}\n",
    "\n",
    "reglas_por_archivo = {\n",
    "    'marketing.csv': reglas_marketing,\n",
    "    'ventas.csv'   : reglas_ventas,\n",
    "    'clientes.csv' : reglas_clientes\n",
    "}\n",
    "reportes_creados = []\n",
    "zip_path = carpeta_reportes.parent / 'reports_dataset_tpi_v2.zip'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "32235fb9-1e09-422e-931b-3471d6fbf123",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Bucle/menu principal (usa dic_frames) ----------\n",
    "def menu_procesar_diccionario(dic_frames, reglas_por_archivo):\n",
    "    \"\"\"\n",
    "    Recorre dic_frames: clave = nombre_archivo (ej. 'marketing.csv'), valor = DataFrame.\n",
    "    Ejecuta: detectar_problemas_en_dataframe antes, limpiar_dataframe, detectar_problemas_en_dataframe despues,\n",
    "    imprime resúmenes y guarda cleaned en carpeta_limpios con sufijo ' limpio.csv'.\n",
    "    También sobreescribe variables en RAM (df_marketing, df_ventas, df_clientes) si se encuentran en el nombre.\n",
    "    \"\"\"\n",
    "    # trabajamos sobre una copia para evitar modificar dict original por error\n",
    "    for nombre_archivo, df_actual in dic_frames.items():\n",
    "        resumen_antes, chequeos_antes, problemas_antes = detectar_problemas_en_dataframe(df_actual)\n",
    "        print(f\"--- RESUMEN ANTES: {nombre_archivo} ---\")\n",
    "        print(resumen_antes)\n",
    "        # Para no volcar objetos muy grandes, mostramos el head del DataFrame de problemas (si existe)\n",
    "        print('Muestras de problemas antes (primeras 5 filas):')\n",
    "        display(problemas_antes.head(5) if not problemas_antes.empty else 'No se detectaron filas con problemas.')\n",
    "\n",
    "        reglas = reglas_por_archivo.get(nombre_archivo, {})\n",
    "        df_limpio = limpiar_dataframe(df_actual, reglas_por_columna=reglas)\n",
    "\n",
    "        resumen_despues, chequeos_despues, problemas_despues = detectar_problemas_en_dataframe(df_limpio)\n",
    "        print(f\"n--- RESUMEN DESPUÉS: {nombre_archivo} ---\")\n",
    "        print(resumen_despues)\n",
    "        print('Muestras de problemas después (primeras 5 filas):')\n",
    "        display(problemas_despues.head(5) if not problemas_despues.empty else 'No se detectaron filas con problemas tras la limpieza.')\n",
    "\n",
    "        # mostrar separadores y tipo-nombre\n",
    "        print('-'*100)\n",
    "        print(f'nombre_archivo = {nombre_archivo}')\n",
    "        print(f'type(nombre_archivo) = {type(nombre_archivo)}')\n",
    "        print('-'*100)\n",
    "\n",
    "        ruta_nombre_limpio = nombre_archivo[:-4] + '_limpio.csv' if nombre_archivo.lower().endswith('.csv') else nombre_archivo + ' limpio.csv'\n",
    "        print(f'ruta_nombre_limpio = {ruta_nombre_limpio}')\n",
    "\n",
    "        # guardar cleaned\n",
    "        ruta_guardado = carpeta_limpios / ruta_nombre_limpio\n",
    "        guardar_csv(df_limpio, ruta_guardado)\n",
    "        print(f'Guardado cleaned en: {ruta_guardado}')\n",
    "\n",
    "        # sobreescribir en RAM según el nombre\n",
    "        # (nota: usar globals() para actualizar variables en el entorno global del notebook)\n",
    "        if 'marketing' in nombre_archivo.lower():\n",
    "            globals()['df_marketing'] = df_limpio\n",
    "        elif 'ventas' in nombre_archivo.lower():\n",
    "            globals()['df_ventas'] = df_limpio\n",
    "        elif 'clientes' in nombre_archivo.lower():\n",
    "            globals()['df_clientes'] = df_limpio\n",
    "\n",
    "    print('Proceso completo del diccionario de DataFrames.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4a42ea6e-6086-4097-9e03-34c1c3cebe3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- RESUMEN ANTES: ventas.csv ---\n",
      "{'filas': 3035, 'columnas': 6, 'nulos_por_columna': {'id_venta': 0, 'producto': 0, 'precio': 2, 'cantidad': 2, 'fecha_venta': 0, 'categoria': 0}, 'duplicados_exactos': 70}\n",
      "Muestras de problemas antes (primeras 5 filas):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_index</th>\n",
       "      <th>problemas</th>\n",
       "      <th>muestra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>820</td>\n",
       "      <td>duplicado_exacto</td>\n",
       "      <td>{\"id_venta\": \"56\", \"producto\": \"Cortinas\", \"pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>821</td>\n",
       "      <td>duplicado_exacto</td>\n",
       "      <td>{\"id_venta\": \"421\", \"producto\": \"L\\u00e1mpara ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>822</td>\n",
       "      <td>duplicado_exacto</td>\n",
       "      <td>{\"id_venta\": \"424\", \"producto\": \"Jarr\\u00f3n d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>823</td>\n",
       "      <td>duplicado_exacto</td>\n",
       "      <td>{\"id_venta\": \"1868\", \"producto\": \"Cafetera\", \"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>824</td>\n",
       "      <td>duplicado_exacto</td>\n",
       "      <td>{\"id_venta\": \"2545\", \"producto\": \"Auriculares\"...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   row_index         problemas  \\\n",
       "0        820  duplicado_exacto   \n",
       "1        821  duplicado_exacto   \n",
       "2        822  duplicado_exacto   \n",
       "3        823  duplicado_exacto   \n",
       "4        824  duplicado_exacto   \n",
       "\n",
       "                                             muestra  \n",
       "0  {\"id_venta\": \"56\", \"producto\": \"Cortinas\", \"pr...  \n",
       "1  {\"id_venta\": \"421\", \"producto\": \"L\\u00e1mpara ...  \n",
       "2  {\"id_venta\": \"424\", \"producto\": \"Jarr\\u00f3n d...  \n",
       "3  {\"id_venta\": \"1868\", \"producto\": \"Cafetera\", \"...  \n",
       "4  {\"id_venta\": \"2545\", \"producto\": \"Auriculares\"...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n--- RESUMEN DESPUÉS: ventas.csv ---\n",
      "{'filas': 3000, 'columnas': 6, 'nulos_por_columna': {'id_venta': 0, 'producto': 0, 'precio': 2, 'cantidad': 2, 'fecha_venta': 0, 'categoria': 0}, 'duplicados_exactos': 0}\n",
      "Muestras de problemas después (primeras 5 filas):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'No se detectaron filas con problemas tras la limpieza.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "nombre_archivo = ventas.csv\n",
      "type(nombre_archivo) = <class 'str'>\n",
      "----------------------------------------------------------------------------------------------------\n",
      "ruta_nombre_limpio = ventas_limpio.csv\n",
      "Guardado cleaned en: limpios\\ventas_limpio.csv\n",
      "--- RESUMEN ANTES: clientes.csv ---\n",
      "{'filas': 567, 'columnas': 5, 'nulos_por_columna': {'id_cliente': 0, 'nombre': 0, 'edad': 0, 'ciudad': 0, 'ingresos': 0}, 'duplicados_exactos': 0}\n",
      "Muestras de problemas antes (primeras 5 filas):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_index</th>\n",
       "      <th>problemas</th>\n",
       "      <th>muestra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>outlier_iqr_columna_edad;outlier_z_columna_edad</td>\n",
       "      <td>{\"id_cliente\": \"11\", \"nombre\": \"Hans Strong\", ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90</td>\n",
       "      <td>outlier_iqr_columna_ingresos</td>\n",
       "      <td>{\"id_cliente\": \"91\", \"nombre\": \"Reynold Aspray...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>114</td>\n",
       "      <td>outlier_iqr_columna_edad</td>\n",
       "      <td>{\"id_cliente\": \"115\", \"nombre\": \"Diandra Longc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>127</td>\n",
       "      <td>outlier_iqr_columna_edad;outlier_z_columna_edad</td>\n",
       "      <td>{\"id_cliente\": \"128\", \"nombre\": \"Lacie Cline\",...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>157</td>\n",
       "      <td>outlier_iqr_columna_ingresos</td>\n",
       "      <td>{\"id_cliente\": \"158\", \"nombre\": \"Electra Shils...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   row_index                                        problemas  \\\n",
       "0         10  outlier_iqr_columna_edad;outlier_z_columna_edad   \n",
       "1         90                     outlier_iqr_columna_ingresos   \n",
       "2        114                         outlier_iqr_columna_edad   \n",
       "3        127  outlier_iqr_columna_edad;outlier_z_columna_edad   \n",
       "4        157                     outlier_iqr_columna_ingresos   \n",
       "\n",
       "                                             muestra  \n",
       "0  {\"id_cliente\": \"11\", \"nombre\": \"Hans Strong\", ...  \n",
       "1  {\"id_cliente\": \"91\", \"nombre\": \"Reynold Aspray...  \n",
       "2  {\"id_cliente\": \"115\", \"nombre\": \"Diandra Longc...  \n",
       "3  {\"id_cliente\": \"128\", \"nombre\": \"Lacie Cline\",...  \n",
       "4  {\"id_cliente\": \"158\", \"nombre\": \"Electra Shils...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n--- RESUMEN DESPUÉS: clientes.csv ---\n",
      "{'filas': 567, 'columnas': 5, 'nulos_por_columna': {'id_cliente': 0, 'nombre': 0, 'edad': 0, 'ciudad': 0, 'ingresos': 0}, 'duplicados_exactos': 0}\n",
      "Muestras de problemas después (primeras 5 filas):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_index</th>\n",
       "      <th>problemas</th>\n",
       "      <th>muestra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>outlier_iqr_columna_edad;outlier_z_columna_edad</td>\n",
       "      <td>{\"id_cliente\": \"11\", \"nombre\": \"Hans Strong\", ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>114</td>\n",
       "      <td>outlier_iqr_columna_edad</td>\n",
       "      <td>{\"id_cliente\": \"115\", \"nombre\": \"Diandra Longc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>127</td>\n",
       "      <td>outlier_iqr_columna_edad;outlier_z_columna_edad</td>\n",
       "      <td>{\"id_cliente\": \"128\", \"nombre\": \"Lacie Cline\",...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>171</td>\n",
       "      <td>outlier_iqr_columna_ingresos</td>\n",
       "      <td>{\"id_cliente\": \"172\", \"nombre\": \"Bent Isenor\",...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>177</td>\n",
       "      <td>outlier_iqr_columna_edad;outlier_z_columna_edad</td>\n",
       "      <td>{\"id_cliente\": \"178\", \"nombre\": \"Helenka Costi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   row_index                                        problemas  \\\n",
       "0         10  outlier_iqr_columna_edad;outlier_z_columna_edad   \n",
       "1        114                         outlier_iqr_columna_edad   \n",
       "2        127  outlier_iqr_columna_edad;outlier_z_columna_edad   \n",
       "3        171                     outlier_iqr_columna_ingresos   \n",
       "4        177  outlier_iqr_columna_edad;outlier_z_columna_edad   \n",
       "\n",
       "                                             muestra  \n",
       "0  {\"id_cliente\": \"11\", \"nombre\": \"Hans Strong\", ...  \n",
       "1  {\"id_cliente\": \"115\", \"nombre\": \"Diandra Longc...  \n",
       "2  {\"id_cliente\": \"128\", \"nombre\": \"Lacie Cline\",...  \n",
       "3  {\"id_cliente\": \"172\", \"nombre\": \"Bent Isenor\",...  \n",
       "4  {\"id_cliente\": \"178\", \"nombre\": \"Helenka Costi...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "nombre_archivo = clientes.csv\n",
      "type(nombre_archivo) = <class 'str'>\n",
      "----------------------------------------------------------------------------------------------------\n",
      "ruta_nombre_limpio = clientes_limpio.csv\n",
      "Guardado cleaned en: limpios\\clientes_limpio.csv\n",
      "--- RESUMEN ANTES: marketing.csv ---\n",
      "{'filas': 90, 'columnas': 6, 'nulos_por_columna': {'id_campanha': 0, 'producto': 0, 'canal': 0, 'costo': 0, 'fecha_inicio': 0, 'fecha_fin': 0}, 'duplicados_exactos': 0}\n",
      "Muestras de problemas antes (primeras 5 filas):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_index</th>\n",
       "      <th>problemas</th>\n",
       "      <th>muestra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41</td>\n",
       "      <td>outlier_iqr_columna_costo</td>\n",
       "      <td>{\"id_campanha\": \"88\", \"producto\": \"Alfombra\", ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   row_index                  problemas  \\\n",
       "0         41  outlier_iqr_columna_costo   \n",
       "\n",
       "                                             muestra  \n",
       "0  {\"id_campanha\": \"88\", \"producto\": \"Alfombra\", ...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n--- RESUMEN DESPUÉS: marketing.csv ---\n",
      "{'filas': 90, 'columnas': 6, 'nulos_por_columna': {'id_campanha': 0, 'producto': 0, 'canal': 0, 'costo': 0, 'fecha_inicio': 0, 'fecha_fin': 0}, 'duplicados_exactos': 0}\n",
      "Muestras de problemas después (primeras 5 filas):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_index</th>\n",
       "      <th>problemas</th>\n",
       "      <th>muestra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>outlier_iqr_columna_costo</td>\n",
       "      <td>{\"id_campanha\": \"12\", \"producto\": \"tablet\", \"c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13</td>\n",
       "      <td>outlier_iqr_columna_costo</td>\n",
       "      <td>{\"id_campanha\": \"34\", \"producto\": \"heladera\", ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>outlier_iqr_columna_costo</td>\n",
       "      <td>{\"id_campanha\": \"49\", \"producto\": \"cafetera\", ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32</td>\n",
       "      <td>outlier_iqr_columna_costo</td>\n",
       "      <td>{\"id_campanha\": \"72\", \"producto\": \"tablet\", \"c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>39</td>\n",
       "      <td>outlier_iqr_columna_costo</td>\n",
       "      <td>{\"id_campanha\": \"53\", \"producto\": \"espejo deco...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   row_index                  problemas  \\\n",
       "0          1  outlier_iqr_columna_costo   \n",
       "1         13  outlier_iqr_columna_costo   \n",
       "2         28  outlier_iqr_columna_costo   \n",
       "3         32  outlier_iqr_columna_costo   \n",
       "4         39  outlier_iqr_columna_costo   \n",
       "\n",
       "                                             muestra  \n",
       "0  {\"id_campanha\": \"12\", \"producto\": \"tablet\", \"c...  \n",
       "1  {\"id_campanha\": \"34\", \"producto\": \"heladera\", ...  \n",
       "2  {\"id_campanha\": \"49\", \"producto\": \"cafetera\", ...  \n",
       "3  {\"id_campanha\": \"72\", \"producto\": \"tablet\", \"c...  \n",
       "4  {\"id_campanha\": \"53\", \"producto\": \"espejo deco...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "nombre_archivo = marketing.csv\n",
      "type(nombre_archivo) = <class 'str'>\n",
      "----------------------------------------------------------------------------------------------------\n",
      "ruta_nombre_limpio = marketing_limpio.csv\n",
      "Guardado cleaned en: limpios\\marketing_limpio.csv\n",
      "Proceso completo del diccionario de DataFrames.\n"
     ]
    }
   ],
   "source": [
    "menu_procesar_diccionario(dic_frames, reglas_por_archivo)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "bf7d2207-957f-40dd-8336-fa3664d5fdd4",
   "metadata": {},
   "source": [
    "\n",
    "<div style=\"background-color:#CCCCCC; padding:10px; border-radius:6px;\">\n",
    "<h2 style=\"color:black; text-align:center;\">Notas pedagógicas y siguientes pasos</h2>\n",
    "\n",
    "<p style=\"color:black;\">- Revisa los archivos <code>reporte_antes_limpieza_<archivo>.csv</code> para ver ejemplos por fila y decidir reglas adicionales.</p>\n",
    "<p style=\"color:black;\">- Ajusta <code>reglas_por_archivo</code> según los nombres reales de las columnas en tus CSV.</p>\n",
    "<p style=\"color:black;\">- Si querés que ejecute el notebook aquí y muestre resultados, subí los 3 CSV a <code>./data_in/</code> o confirma que están en <code>/mnt/data/</code>.</p>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50338261-fcc2-4dda-85b8-d6c12320e8fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f895b5b-5c12-442f-abf1-4b7a9d3ac96d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "072ed9de",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'xlsxwriter'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 94\u001b[39m\n\u001b[32m     92\u001b[39m \u001b[38;5;66;03m# Guardar en un solo Excel con tres hojas\u001b[39;00m\n\u001b[32m     93\u001b[39m ruta_excel = carpeta_reportes / \u001b[33m'\u001b[39m\u001b[33mreporte_limpieza.xlsx\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m94\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mExcelWriter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mruta_excel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mxlsxwriter\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m writer:\n\u001b[32m     95\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     96\u001b[39m         df_duplicados_total.to_excel(writer, index=\u001b[38;5;28;01mFalse\u001b[39;00m, sheet_name=\u001b[33m'\u001b[39m\u001b[33mduplicados\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Python312\\Lib\\site-packages\\pandas\\io\\excel\\_xlsxwriter.py:197\u001b[39m, in \u001b[36mXlsxWriter.__init__\u001b[39m\u001b[34m(self, path, engine, date_format, datetime_format, mode, storage_options, if_sheet_exists, engine_kwargs, **kwargs)\u001b[39m\n\u001b[32m    184\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\n\u001b[32m    185\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    186\u001b[39m     path: FilePath | WriteExcelBuffer | ExcelWriter,\n\u001b[32m   (...)\u001b[39m\u001b[32m    195\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    196\u001b[39m     \u001b[38;5;66;03m# Use the xlsxwriter module as the Excel writer.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m197\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mxlsxwriter\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Workbook\n\u001b[32m    199\u001b[39m     engine_kwargs = combine_kwargs(engine_kwargs, kwargs)\n\u001b[32m    201\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m mode == \u001b[33m\"\u001b[39m\u001b[33ma\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'xlsxwriter'"
     ]
    }
   ],
   "source": [
    "\n",
    "# ======= Celda automática: generar reporte consolidado en Excel =======\n",
    "# Esta celda crea un archivo Excel en carpeta_reportes con hojas:\n",
    "# - duplicados\n",
    "# - outliers\n",
    "# - resumen_filtros\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Asegurarse que carpeta_reportes existe\n",
    "try:\n",
    "    carpeta_reportes.mkdir(parents=True, exist_ok=True)\n",
    "except Exception:\n",
    "    carpeta_reportes = Path('/mnt/data/reportes')\n",
    "    carpeta_reportes.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Intentar obtener DataFrames limpios desde el entorno; si no existen, cargar desde rutas\n",
    "dfs_por_origen = {}\n",
    "try:\n",
    "    dfs_por_origen['ventas'] = df_ventas\n",
    "except NameError:\n",
    "    try:\n",
    "        dfs_por_origen['ventas'] = pd.read_csv(ruta_ventas)\n",
    "    except Exception:\n",
    "        dfs_por_origen['ventas'] = pd.DataFrame()\n",
    "\n",
    "try:\n",
    "    dfs_por_origen['clientes'] = df_clientes\n",
    "except NameError:\n",
    "    try:\n",
    "        dfs_por_origen['clientes'] = pd.read_csv(ruta_clientes)\n",
    "    except Exception:\n",
    "        dfs_por_origen['clientes'] = pd.DataFrame()\n",
    "\n",
    "try:\n",
    "    dfs_por_origen['marketing'] = df_marketing\n",
    "except NameError:\n",
    "    try:\n",
    "        dfs_por_origen['marketing'] = pd.read_csv(ruta_marketing)\n",
    "    except Exception:\n",
    "        dfs_por_origen['marketing'] = pd.DataFrame()\n",
    "\n",
    "# Listas para consolidar\n",
    "lista_duplicados = []\n",
    "lista_outliers = []\n",
    "lista_resumen = []\n",
    "\n",
    "for nombre, df_actual in dfs_por_origen.items():\n",
    "    if df_actual is None or df_actual.empty:\n",
    "        lista_resumen.append({'dataset': nombre, 'filas_iniciales': 0, 'duplicados_encontrados': 0, 'outliers_encontrados': 0, 'filas_finales': 0})\n",
    "        continue\n",
    "\n",
    "    filas_iniciales = df_actual.shape[0]\n",
    "\n",
    "    # Duplicados por fila completa (keep=False)\n",
    "    duplicados_df = df_actual[df_actual.duplicated(keep=False)].copy()\n",
    "    if not duplicados_df.empty:\n",
    "        duplicados_df['dataset'] = nombre\n",
    "        lista_duplicados.append(duplicados_df)\n",
    "\n",
    "    # Outliers: aplicar IQR por cada columna numérica\n",
    "    outliers_encontrados_dataset = []\n",
    "    for columna in df_actual.columns:\n",
    "        try:\n",
    "            mascara, cantidad, limites = mascara_valores_atipicos_rango_intercuartil(df_actual[columna])\n",
    "            if cantidad > 0:\n",
    "                temp = df_actual[mascara].copy()\n",
    "                temp['columna_outlier'] = columna\n",
    "                temp['dataset'] = nombre\n",
    "                lista_outliers.append(temp)\n",
    "                outliers_encontrados_dataset.append((columna, cantidad))\n",
    "        except Exception:\n",
    "            # Si la detección falla en una columna, continuar con la siguiente\n",
    "            continue\n",
    "\n",
    "    # Filas finales (suponiendo que se eliminarían duplicados y outliers)\n",
    "    filas_sin_duplicados = df_actual.drop_duplicates().shape[0]\n",
    "    filas_finales_estimadas = max(0, filas_sin_duplicados - sum([c for _, c in outliers_encontrados_dataset]))\n",
    "\n",
    "    lista_resumen.append({\n",
    "        'dataset': nombre,\n",
    "        'filas_iniciales': int(filas_iniciales),\n",
    "        'duplicados_encontrados': int(duplicados_df.shape[0]) if not duplicados_df.empty else 0,\n",
    "        'outliers_encontrados': sum([c for _, c in outliers_encontrados_dataset]),\n",
    "        'filas_finales': int(filas_finales_estimadas)\n",
    "    })\n",
    "\n",
    "# Consolidar resultados\n",
    "df_duplicados_total = pd.concat(lista_duplicados, ignore_index=True) if lista_duplicados else pd.DataFrame()\n",
    "df_outliers_total = pd.concat(lista_outliers, ignore_index=True) if lista_outliers else pd.DataFrame()\n",
    "df_resumen = pd.DataFrame(lista_resumen)\n",
    "\n",
    "# Guardar en un solo Excel con tres hojas\n",
    "ruta_excel = carpeta_reportes / 'reporte_limpieza.xlsx'\n",
    "with pd.ExcelWriter(ruta_excel, engine='xlsxwriter') as writer:\n",
    "    try:\n",
    "        df_duplicados_total.to_excel(writer, index=False, sheet_name='duplicados')\n",
    "    except Exception:\n",
    "        pd.DataFrame().to_excel(writer, index=False, sheet_name='duplicados')\n",
    "    try:\n",
    "        df_outliers_total.to_excel(writer, index=False, sheet_name='outliers')\n",
    "    except Exception:\n",
    "        pd.DataFrame().to_excel(writer, index=False, sheet_name='outliers')\n",
    "    try:\n",
    "        df_resumen.to_excel(writer, index=False, sheet_name='resumen_filtros')\n",
    "    except Exception:\n",
    "        pd.DataFrame(lista_resumen).to_excel(writer, index=False, sheet_name='resumen_filtros')\n",
    "\n",
    "print(\"Archivo generado en:\", ruta_excel)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
