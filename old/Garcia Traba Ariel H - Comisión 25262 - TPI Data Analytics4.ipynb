{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cedbb1b4",
   "metadata": {},
   "source": [
    "\n",
    "<div style=\"background-color:#CCCCCC; padding:12px; border-radius:8px;\">\n",
    "<h1 style=\"color:#003366; text-align:center; margin:8px 0;\">Revisión y limpieza de 3 DataFrames (TPI - Data Analytics)</h1>\n",
    "<p style=\"text-align:center; color:#003366; margin:0;\"><em>Notebook docente en castellano — nombres descriptivos en snake_case — código y documentación</em></p>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c723b86a",
   "metadata": {},
   "source": [
    "\n",
    "<div style=\"background-color:#CCCCCC; padding:10px; border-radius:6px;\">\n",
    "<h2 style=\"color:black; text-align:center; margin-top:6px;\">Resumen</h2>\n",
    "\n",
    "<p style=\"color:black;\">\n",
    "Este notebook está diseñado con finalidades pedagógicas. Revisa, normaliza y valida tres datasets contenidos en CSV:\n",
    "</p>\n",
    "\n",
    "<ul style=\"color:black;\">\n",
    "<li><code>marketing.csv</code> → variable: <code>df_marketing</code></li>\n",
    "<li><code>ventas.csv</code>    → variable: <code>df_ventas</code></li>\n",
    "<li><code>clientes.csv</code>  → variable: <code>df_clientes</code></li>\n",
    "</ul>\n",
    "\n",
    "<p style=\"color:black;\">\n",
    "Coloca los CSV en <code>/content/drive/MyDrive/CABA/Garcia Traba Ariel H - Comisión 25262 - TPI Data Analytics/</code> \n",
    "    en <code>/datasets_entrada/</code>. El notebook busca primero en google drive y si no encuentra, usa <code>localhost (127.0.0.1)</code> (útil para entornos donde los archivos están pre-subidos).\n",
    "</p>\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be46fb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports y configuración inicial (nombres en castellano)\n",
    "import os, re, json, unicodedata\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from colorama import *\n",
    "from math import isnan\n",
    "import zipfile\n",
    "from collections import defaultdict\n",
    "import argparse\n",
    "import pandas as pd\n",
    "from pandas.api.types import is_numeric_dtype\n",
    "import numpy as np\n",
    "from typing import Dict, Any, Optional\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63edff5b-828e-4254-a4d7-4b0ef05ecea6",
   "metadata": {},
   "source": [
    "## 1. Crear un documento en Google Colaboratory y cargar los sets de datos como DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddfa535f-ef52-4f49-9d1b-e70dd8d5ad27",
   "metadata": {},
   "source": [
    "si se usa en disco local comentarla celda de debajo (JuPyteR , VSC, ATOM, Spider, Geany, etc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "144444b3-1dc1-4f3f-a621-025d1cdb6465",
   "metadata": {},
   "source": [
    "# 1ra parte Definición de ETL\n",
    "ETL es un conjunto de procedimientos que permiten mover datos desde sistemas de origen, que pueden ser bases de datos, archivos o fuentes en la nube, hasta un sistema de destino como un data warehouse o data lake, realizando previamente procesos de limpieza, estructuración y organización de los datos para hacerlos aptos para análisis.​\n",
    "\n",
    "## Fases del proceso ETL\n",
    "Extracción: Consiste en recopilar datos relevantes de diferentes fuentes, asegurando que el impacto en los sistemas origen sea mínimo. Los datos pueden extraerse mediante diversos métodos como consultas SQL o servicios web.​\n",
    "\n",
    "Transformación: En esta etapa, los datos se limpian y se ajustan para garantizar coherencia y calidad, incluyendo la eliminación de valores nulos, normalización y conversión a formatos consistentes, además de aplicar reglas específicas de negocio.\n",
    "\n",
    "Carga: Finalmente, los datos transformados se cargan en el sistema de destino, donde estarán disponibles para análisis, informes o modelado de datos.\n",
    "\n",
    "## Importancia del ETL\n",
    "Es crucial en la minería de datos porque preparar los datos brutos para que puedan ser utilizados en análisis estadísticos, modelados predictivos o técnicas de aprendizaje automático, asegurando la calidad, coherencia y accesibilidad de la información."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c8f6200-1ad0-4fa8-9cf1-aa1df22c4b3b",
   "metadata": {},
   "source": [
    "### 1.1 Crear estructura de directorios segun modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "605182b8-9652-410e-8c79-13b10a33e692",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rutas: \n",
    "def carga_rutas():\n",
    "    global carpeta_entrada,carpeta_datasets_salida,carpeta_reportes,carpeta_limpios\n",
    "    #archivo_ventas,archivo_clientes,archivo_marketing\n",
    "    carpeta_entrada    = Path(ruta_base)\n",
    "    carpeta_datasets_entrada   = carpeta_entrada / 'datasets_entrada'\n",
    "        \n",
    "    carpeta_datasets_salida   = carpeta_entrada / 'datasets_salida'\n",
    "    carpeta_datasets_salida.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    carpeta_reportes   = carpeta_datasets_salida / 'reportes'\n",
    "    carpeta_reportes.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    carpeta_limpios    = carpeta_datasets_salida / 'limpios'\n",
    "    carpeta_limpios.mkdir(parents=True, exist_ok=True)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b65281a-0cd0-43a6-8a84-ed2692ae60b2",
   "metadata": {},
   "source": [
    "### 1.2 rutas y carga de los dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "052e6d76-d227-4749-af2c-f065eabf82f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def carga_de_datos():\n",
    "    global dic_dfs\n",
    "    print(\"Cargando datasets del curso...\")\n",
    "    try:\n",
    "        ruta_ventas     = os.path.join(carpeta_datasets_entrada, archivo_ventas)\n",
    "        ruta_clientes   = os.path.join(carpeta_datasets_entrada, archivo_clientes)\n",
    "        ruta_marketing  = os.path.join(carpeta_datasets_entrada, archivo_marketing)\n",
    "        \n",
    "        df_ventas       = pd.read_csv(f\"{ruta_ventas}\")\n",
    "        df_clientes     = pd.read_csv(f\"{ruta_clientes}\")\n",
    "        df_marketing    = pd.read_csv(f\"{ruta_marketing}\")\n",
    "        dic_dfs = { \"df_ventas\"   : df_ventas,\n",
    "                    \"df_clientes\" : df_clientes,\n",
    "                    \"df_marketing\": df_marketing}\n",
    "        print (\"...Arhivos cargados con exito!!!\")\n",
    "    except FileNotFoundError:\n",
    "        print(\"Archivos no encontrados en:\", carpeta_datasets_entrada)\n",
    "        sys.exit(1)\n",
    "    except pd.errors.EmptyDataError:\n",
    "        print(\"Archivo vacío detectado\")\n",
    "        sys.exit(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4225f2e7-fccf-4a13-86a6-92acee434aa7",
   "metadata": {},
   "source": [
    "## desde python sin librerias pandas / polars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d2a3b1cb-f541-4001-87e5-bbf37d74e0f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[37m\u001b[44m\n",
      "╔═════════════════════════════════════════════════════════════════════════════╗\n",
      "║                      Datos en ámbito Google Drive                           ║\n",
      "╚═════════════════════════════════════════════════════════════════════════════╝\u001b[0m\n",
      "Requirement already satisfied: google in c:\\python312\\lib\\site-packages (3.0.0)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\python312\\lib\\site-packages (from google) (4.13.5)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\python312\\lib\\site-packages (from beautifulsoup4->google) (2.8)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in c:\\python312\\lib\\site-packages (from beautifulsoup4->google) (4.15.0)\n",
      "\u001b[37m\u001b[41m\n",
      "╔═════════════════════════════════════════════════════════════════════════════╗\n",
      "║                          Google Drive NO cargado                            ║\n",
      "╚═════════════════════════════════════════════════════════════════════════════╝\u001b[0m\n",
      "\u001b[37m\u001b[44m\n",
      "╔═════════════════════════════════════════════════════════════════════════════╗\n",
      "║                          Datos en ámbito local                              ║\n",
      "╚═════════════════════════════════════════════════════════════════════════════╝\u001b[0m\n",
      "\u001b[37m\u001b[42m\n",
      "╔═════════════════════════════════════════════════════════════════════════════╗\n",
      "║                        ámbito local cargado con exito                       ║\n",
      "╚═════════════════════════════════════════════════════════════════════════════╝\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "def carga_fuente_de_datos():\n",
    "    global ruta_base, archivo_ventas, archivo_clientes,archivo_marketing\n",
    "    archivo_ventas     = 'ventas.csv'\n",
    "    archivo_clientes   = 'clientes.csv'\n",
    "    archivo_marketing  = 'marketing.csv'\n",
    "    #################################################################################\n",
    "    try: \n",
    "        print(f\"\"\"{Fore.WHITE+Back.BLUE}\n",
    "╔═════════════════════════════════════════════════════════════════════════════╗\n",
    "║                      Datos en ámbito Google Drive                           ║\n",
    "╚═════════════════════════════════════════════════════════════════════════════╝{Style.RESET_ALL}\"\"\")\n",
    "        # --- Paso 1: Montar Google Drive ---\n",
    "        # Montar tu Google Drive\n",
    "        !pip install google\n",
    "        from google.colab import drive\n",
    "        drive.mount('/content/drive')\n",
    "        !ls \"/content/drive/MyDrive/CABA/Garcia Traba Ariel H - Comisión 25262 - TPI Data Analytics/\"\n",
    "        # Ruta del archivo (ajústala a la carpeta real en tu Drive)\n",
    "        ruta_base = \"/content/drive/MyDrive/CABA/Garcia Traba Ariel H - Comisión 25262 - TPI Data Analytics/\"\n",
    "        carga_rutas()\n",
    "        if not os.path.exists(ruta_base):\n",
    "            raise FileNotFoundError(f\"La carpeta especificada no existe: {ruta_base}\")\n",
    "        carga_de_datos()\n",
    "        print(f\"\"\"{Fore.WHITE+Back.BLUE}\n",
    "╔═════════════════════════════════════════════════════════════════════════════╗\n",
    "║                      Google Drive cargado con exito                         ║\n",
    "╚═════════════════════════════════════════════════════════════════════════════╝{Style.RESET_ALL}\"\"\")\n",
    "        return\n",
    "    except:\n",
    "        print(f\"\"\"{Fore.WHITE+Back.RED}\n",
    "╔═════════════════════════════════════════════════════════════════════════════╗\n",
    "║                          Google Drive NO cargado                            ║\n",
    "╚═════════════════════════════════════════════════════════════════════════════╝{Style.RESET_ALL}\"\"\")\n",
    "    #################################################################################\n",
    "    try:\n",
    "        print(f\"\"\"{Fore.WHITE+Back.BLUE}\n",
    "╔═════════════════════════════════════════════════════════════════════════════╗\n",
    "║                          Datos en ámbito local                              ║\n",
    "╚═════════════════════════════════════════════════════════════════════════════╝{Style.RESET_ALL}\"\"\")\n",
    "        ruta_base = \"/pepe/\"\n",
    "        print (f\"{ruta_base=}\")\n",
    "        carga_rutas()\n",
    "        print (f\"{carpeta_entrada=}\")\n",
    "        print (\"*\"*50)\n",
    "        if not os.path.exists(ruta_base):\n",
    "            raise FileNotFoundError(f\"La carpeta especificada no existe: {ruta_base}\")\n",
    "        carga_de_datos()\n",
    "        print(f\"\"\"{Fore.WHITE+Back.GREEN}\n",
    "╔═════════════════════════════════════════════════════════════════════════════╗\n",
    "║                        ámbito local cargado con exito                       ║\n",
    "╚═════════════════════════════════════════════════════════════════════════════╝{Style.RESET_ALL}\"\"\")\n",
    "        return\n",
    "    except:\n",
    "        print(f\"\"\"{Fore.WHITE+Back.RED}\n",
    "╔═════════════════════════════════════════════════════════════════════════════╗\n",
    "║                         ámbito local  NO cargado                            ║\n",
    "╚═════════════════════════════════════════════════════════════════════════════╝{Style.RESET_ALL}\"\"\")\n",
    "    #################################################################################\n",
    "    try:\n",
    "        print(f\"\"\"{Fore.WHITE+Back.BLUE}\n",
    "╔═════════════════════════════════════════════════════════════════════════════╗\n",
    "║                          Datos en ámbito github                             ║\n",
    "╚═════════════════════════════════════════════════════════════════════════════╝{Style.RESET_ALL}\"\"\")\n",
    "        ruta_base = \"https://github.com/CursosAGT/-GarciaTrabaArielH-Comisi-n25262-TPI_Data_Analytics/blob/main/\"\n",
    "        print(f\"\"\"{Fore.WHITE+Back.GREEN}\n",
    "╔═════════════════════════════════════════════════════════════════════════════╗\n",
    "║                        ámbito github cargado con exito                      ║\n",
    "╚═════════════════════════════════════════════════════════════════════════════╝{Style.RESET_ALL}\"\"\")\n",
    "        carga_rutas()\n",
    "        if not os.path.exists(ruta_base):\n",
    "            raise FileNotFoundError(f\"La carpeta especificada no existe: {ruta_base}\")\n",
    "        carga_de_datos()       \n",
    "        return\n",
    "    except:\n",
    "        print(f\"\"\"{Fore.WHITE+Back.RED}\n",
    "╔═════════════════════════════════════════════════════════════════════════════╗\n",
    "║                         ámbito github NO cargado                            ║\n",
    "╚═════════════════════════════════════════════════════════════════════════════╝{Style.RESET_ALL}\"\"\")\n",
    "    #################################################################################\n",
    "    print(f\"\"\"{Fore.WHITE+Back.RED}\n",
    "╔═════════════════════════════════════════════════════════════════════════════╗\n",
    "║                  No se encontraron los datos básicos (CSV)                  ║\n",
    "║                  No se puede continuar                                      ║\n",
    "╚═════════════════════════════════════════════════════════════════════════════╝{Style.RESET_ALL}\"\"\")\n",
    "    exit()\n",
    "carga_datos()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86754f0-a78b-453c-9127-5abd20e1877d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876facae-5d32-47aa-8b55-d9b04deadb85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6e91d4ff-4465-4ec3-b5e1-29f5d4cc0277",
   "metadata": {},
   "source": [
    "### 1.3 Estructura de parámetros "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "895c63d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Proceso principal para los 3 CSV ----------\n",
    "desviacion_margen     = 1.5\n",
    "desviacion_umbral     = 3.0\n",
    "cantidad_duplicados   = 0\n",
    "reportes_creados      = []\n",
    "ruta_excel            = carpeta_reportes / 'reporte_limpieza.xlsx'\n",
    "guardado_ok           = False\n",
    "mensajes              = []\n",
    "TOKENS_VALOR_FALTANTE = {'na', 'n/a', 'null', 'none', 'sin dato', 's/d', 'nd', '-', '--', '?', 'sin_dato', 'n/d'}\n",
    "\n",
    "\n",
    "reglas= {\n",
    "            \"df_marketing\" : {\n",
    "                                'producto':     {'string' : {'tipo': 'lower', 'normalizar_acentos': True}},\n",
    "                                'canal':        {'string' : {'tipo': 'upper', 'normalizar_acentos': True}},\n",
    "                                'costo':        {'numeric': {'as_int': False}},\n",
    "                                'fecha_inicio': {'date'   : {'dayfirst': True, 'formats': ['%d/%m/%Y', '%Y-%m-%d']}},\n",
    "                                'fecha_fin':    {'date'   : {'dayfirst': True, 'formats': ['%d/%m/%Y', '%Y-%m-%d']}}\n",
    "                                },\n",
    "            # id_venta, producto, precio, cantidad, fecha_venta, categoria\n",
    "            \"df_ventas\" : {\n",
    "                                'producto':     {'string' : {'tipo': 'lower', 'normalizar_acentos': True}},\n",
    "                                'precio':       {'numeric': {'as_int': False}},\n",
    "                                'cantidad':     {'numeric': {'as_int': False}},\n",
    "                                'fecha_venta':  {'date'   : {'dayfirst': True, 'formats': ['%d/%m/%Y', '%Y-%m-%d']}},\n",
    "                                'categoria':    {'string' : {'tipo': 'lower', 'normalizar_acentos': True}}\n",
    "                            },\n",
    "            # id_cliente, nombre, edad, ciudad, ingresos\n",
    "            \"df_clientes\" : {\n",
    "                                'nombre':       {'string'  : {'tipo': 'title', 'normalizar_acentos': True}},\n",
    "                                'edad':         {'numeric' : {'as_int': True}},\n",
    "                                'ciudad':       {'string'  : {'tipo': 'title', 'normalizar_acentos': True}},\n",
    "                                'ingresos':     {'numeric' : {'as_int': False}}\n",
    "                            }\n",
    "    }\n",
    "reglas_por_archivo = {\n",
    "    'ventas.csv':    reglas[\"df_ventas\"],\n",
    "    'clientes.csv':  reglas[\"df_clientes\"],\n",
    "    'marketing.csv': reglas[\"df_marketing\"]\n",
    "}\n",
    "\n",
    "#zip_path = carpeta_reportes.parent / 'reports_dataset_tpi_v2.zip'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a06a6528-ba7e-4f2c-889a-5d428f5a1cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar el DataFrame\n",
    "def ver(df :pd.DataFrame,nombre_df =\"\"):\n",
    "    print(f\"\"\"{Fore.WHITE+Back.BLUE}\n",
    "╔═════════════════════════════════════════════════════════════════════════════╗\n",
    "║                            E.T.L.:  {nombre_df.center(20)}                    ║\n",
    "╚═════════════════════════════════════════════════════════════════════════════╝{Style.RESET_ALL}\n",
    "        Descripción preliminar:\n",
    "        {df.describe()}\n",
    "        Dimensiones:      { df.ndim}\n",
    "        Forma:            { df.shape}\n",
    "                filas:    {df.shape[0]}\n",
    "                Número de elementos:{ df.size}\n",
    "                Nombres de filas:{ df.index}\n",
    "                columnas: {df.shape[1]}\n",
    "                Nombres de columnas:{ df.columns}\n",
    "        Valores nulos:    {df.isna().sum().to_dict()}\n",
    "        Valores duplicados:{int(df.duplicated(keep=False).sum())}\n",
    "        Tipos de datos:\\n{ df.dtypes}\n",
    "        Primeras 7 filas:\\n{ df.head(7)}\n",
    "        Últimas 3 filas:\\n{ df.tail(3)}\n",
    "    {\"*\"*50}\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f4aefb8b-3e14-4917-9986-8b7f27033cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def es_valor_faltante(serie,nombre_serie,nombre_df):\n",
    "    \"\"\"\n",
    "    Determina si los valores de una serie deben considerarse faltantes.\n",
    "    \n",
    "    Parámetros:\n",
    "        serie (pd.Series): columna de pandas a evaluar.\n",
    "    \n",
    "    Retorna:\n",
    "        dict:\n",
    "            'mask' -> pd.Series booleana (True si el valor es faltante)\n",
    "            'valores_faltantes' -> lista de valores detectados como faltantes\n",
    "    \"\"\"\n",
    "    serie_limpia = serie.astype(str).str.strip().str.lower()\n",
    "    mask = serie.isna() | serie_limpia.isin(TOKENS_VALOR_FALTANTE)\n",
    "    \n",
    "    # Extraemos los valores faltantes con su índice\n",
    "    valores_detectados = serie[mask]\n",
    "    \n",
    "    if not valores_detectados.empty:\n",
    "        print(f\"\"\"{Fore.WHITE+Back.RED}\n",
    "╔═════════════════════════════════════════════════════════════════════════════╗\n",
    "║                             Valor NO VALIDO                                 ║\n",
    "╚═════════════════════════════════════════════════════════════════════════════╝{Style.RESET_ALL}\n",
    "{nombre_df=}      {nombre_serie=}\n",
    "Valores faltantes detectados con fila/índice:\\n, {valores_detectados}\"\"\")\n",
    "    return {'mask': mask, 'valores_faltantes': valores_detectados.unique().tolist()}#True si es NaN o está en los tokens de faltante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2dee86f8-86c5-45f5-98d7-ea56cd905395",
   "metadata": {},
   "outputs": [],
   "source": [
    "def series_en_dataframes(nombre_df, df_cada):\n",
    "    for nombre_serie, serie in df_cada.items():\n",
    "        resultado = es_valor_faltante(serie,nombre_serie,nombre_df)           \n",
    "        nombre_serie= nombre_serie.lower().replace(\" \",\"_\")\n",
    "        if nombre_serie.startswith(\"id_\"):\n",
    "            continue\n",
    "        regla =  next(iter(reglas[nombre_df][nombre_serie]))\n",
    "        '''\n",
    "        print (f\"\"\"\n",
    "        {nombre_serie=}\n",
    "        {serie=}\n",
    "        {regla=}\n",
    "        \"\"\")'''\n",
    "        s = serie.copy()\n",
    "        if regla == \"numeric\":\n",
    "            try:\n",
    "                s = s.astype(str).str.strip()\n",
    "                '''\n",
    "            ╔═════════════════════════════════════════════════════════════════════════════╗\n",
    "            ║                              Sacar simbolo $                                ║\n",
    "            ╚═════════════════════════════════════════════════════════════════════════════╝'''\n",
    "                s = s.str.replace('$', '')\n",
    "            except:\n",
    "                pass\n",
    "            '''\n",
    "            ╔═════════════════════════════════════════════════════════════════════════════╗\n",
    "            ║                              A numerico (float 32/4)                        ║\n",
    "            ╚═════════════════════════════════════════════════════════════════════════════╝'''\n",
    "            # difiere para windows vs mac-linuxs = pd.to_numeric(s, errors=\"coerce\").astype(np.float32)\n",
    "            s = pd.to_numeric(s, errors=\"coerce\", downcast='float')  # Intenta float32\n",
    "            if reglas[nombre_df][nombre_serie][\"numeric\"][\"as_int\"] :\n",
    "                s = s.replace('.', '').replace(',', '')\n",
    "                if not s.isna().any():\n",
    "                    '''\n",
    "            ╔═════════════════════════════════════════════════════════════════════════════╗\n",
    "            ║                              A numerico (int32/4)                           ║\n",
    "            ╚═════════════════════════════════════════════════════════════════════════════╝'''\n",
    "                    s = s.astype(np.int32)  # Garantizado int32\n",
    "        elif regla == \"string\":\n",
    "            '''\n",
    "            ╔═════════════════════════════════════════════════════════════════════════════╗\n",
    "            ║      Verdadero formato Python papa reemplazar mas de 2 espacios por 1       ║\n",
    "            ╚═════════════════════════════════════════════════════════════════════════════╝'''\n",
    "            s = s.astype(str).str.strip().replace(r'\\s+', ' ', regex=True)\n",
    "            match  reglas[nombre_df][nombre_serie][regla][\"tipo\"] :\n",
    "                case \"upper\":\n",
    "                    s = s.str.upper()\n",
    "                case \"title\":\n",
    "                    s = s.str.title()\n",
    "                case \"lower\":\n",
    "                    s = s.str.lower()\n",
    "            '''\n",
    "            ╔═════════════════════════════════════════════════════════════════════════════╗\n",
    "            ║                              Sacar acentos                                  ║\n",
    "            ╚═════════════════════════════════════════════════════════════════════════════╝'''\n",
    "            #texto_n = unicodedata.normalize(\"NFD\", entrada)\n",
    "            s= s.apply(  lambda x: ''.join( c for c in unicodedata.normalize('NFKD', str(x)) if not unicodedata.combining(c)  )  )\n",
    "            #''.join(c for c in unicodedata.normalize('NFKD', str(x))  if not unicodedata.combining(c))  for x in df[\"columna\"]\n",
    "            '''            \n",
    "            Modo\tSignificado\tQué hace\tCuándo usar\n",
    "            NFD\tNormalization Form Decomposition\tDescompone los caracteres Unicode en su forma básica y diacrítica. Ej: \"á\" → \"a\" + \" ́\"\tCuando solo querés separar acentos.\n",
    "            NFKD\tCompatibility Decomposition\tHace lo mismo más normaliza formas equivalentes \"compatibles\" (por ejemplo, “①” → “1”, “ﬂ” → “fl”)\tIdeal para limpieza más completa de texto.\n",
    "            '''\n",
    "        elif regla == \"date\":\n",
    "            '''\n",
    "            ╔═════════════════════════════════════════════════════════════════════════════╗\n",
    "            ║                   Formato de fecha ISO('%Y/%m/%d') YYYY/MM/DD               ║\n",
    "            ╚═════════════════════════════════════════════════════════════════════════════╝'''\n",
    "            s = pd.to_datetime(  s,  dayfirst=reglas[nombre_df][nombre_serie][regla][\"dayfirst\"],   errors=\"coerce\"  ) \n",
    "            #s = s.dt.strftime('%Y/%m/%d')\n",
    "        #elif regla == \"fillna\":\n",
    "            #s = s.fillna(0)\n",
    "        dic_dfs[nombre_df][nombre_serie] = s\n",
    "        '''\n",
    "        print (f\"\"\"\n",
    "        {\"*\"*50}\n",
    "        {regla=}\"\"\")'''\n",
    "         \n",
    "    return dic_dfs[nombre_df]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a93a9ef1-7c47-4115-a9ba-f3ae616f83c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[37m\u001b[41m\n",
      "╔═════════════════════════════════════════════════════════════════════════════╗\n",
      "║                             Valor NO VALIDO                                 ║\n",
      "╚═════════════════════════════════════════════════════════════════════════════╝\u001b[0m\n",
      "nombre_df='df_ventas'      nombre_serie='precio'\n",
      "Valores faltantes detectados con fila/índice:\n",
      ", 136    NaN\n",
      "139    NaN\n",
      "Name: precio, dtype: object\n",
      "\u001b[37m\u001b[41m\n",
      "╔═════════════════════════════════════════════════════════════════════════════╗\n",
      "║                             Valor NO VALIDO                                 ║\n",
      "╚═════════════════════════════════════════════════════════════════════════════╝\u001b[0m\n",
      "nombre_df='df_ventas'      nombre_serie='cantidad'\n",
      "Valores faltantes detectados con fila/índice:\n",
      ", 136   NaN\n",
      "139   NaN\n",
      "Name: cantidad, dtype: float64\n",
      "\u001b[37m\u001b[44m\n",
      "╔═════════════════════════════════════════════════════════════════════════════╗\n",
      "║                            E.T.L.:       df_ventas                          ║\n",
      "╚═════════════════════════════════════════════════════════════════════════════╝\u001b[0m\n",
      "        Descripción preliminar:\n",
      "                  id_venta       precio     cantidad                    fecha_venta\n",
      "count  3035.000000  3033.000000  3033.000000                           3035\n",
      "mean   1499.851400    75.289032     6.496538  2024-06-25 20:51:09.785832192\n",
      "min       1.000000    26.000000     1.000000            2024-01-02 00:00:00\n",
      "25%     748.500000    50.020000     3.000000            2024-03-28 00:00:00\n",
      "50%    1502.000000    75.269997     7.000000            2024-06-21 00:00:00\n",
      "75%    2249.500000   100.040001     9.000000            2024-09-25 00:00:00\n",
      "max    3000.000000   124.970001    12.000000            2024-12-30 00:00:00\n",
      "std     866.465379    28.734667     3.457250                            NaN\n",
      "        Dimensiones:      2\n",
      "        Forma:            (3035, 6)\n",
      "                filas:    3035\n",
      "                Número de elementos:18210\n",
      "                Nombres de filas:RangeIndex(start=0, stop=3035, step=1)\n",
      "                columnas: 6\n",
      "                Nombres de columnas:Index(['id_venta', 'producto', 'precio', 'cantidad', 'fecha_venta',\n",
      "       'categoria'],\n",
      "      dtype='object')\n",
      "        Valores nulos:    {'id_venta': 0, 'producto': 0, 'precio': 2, 'cantidad': 2, 'fecha_venta': 0, 'categoria': 0}\n",
      "        Valores duplicados:70\n",
      "        Tipos de datos:\n",
      "id_venta                int64\n",
      "producto               object\n",
      "precio                float32\n",
      "cantidad              float32\n",
      "fecha_venta    datetime64[ns]\n",
      "categoria              object\n",
      "dtype: object\n",
      "        Primeras 7 filas:\n",
      "   id_venta           producto      precio  cantidad fecha_venta  \\\n",
      "0       792  cuadro decorativo   69.940002       5.0  2024-01-02   \n",
      "1       811    lampara de mesa  105.099998       5.0  2024-01-02   \n",
      "2      1156           secadora   97.959999       3.0  2024-01-02   \n",
      "3      1372           heladera  114.349998       8.0  2024-01-02   \n",
      "4      1546           secadora  106.209999       4.0  2024-01-02   \n",
      "5      1697    horno electrico   35.349998       9.0  2024-01-02   \n",
      "6      1710   plancha de vapor   65.430000       2.0  2024-01-02   \n",
      "\n",
      "           categoria  \n",
      "0         decoracion  \n",
      "1         decoracion  \n",
      "2  electrodomesticos  \n",
      "3  electrodomesticos  \n",
      "4  electrodomesticos  \n",
      "5  electrodomesticos  \n",
      "6  electrodomesticos  \n",
      "        Últimas 3 filas:\n",
      "      id_venta                producto      precio  cantidad fecha_venta  \\\n",
      "3032      2696                  laptop  107.809998       4.0  2024-12-30   \n",
      "3033      2913              smartphone   99.849998       7.0  2024-12-30   \n",
      "3034      2930  consola de videojuegos   55.470001       6.0  2024-12-30   \n",
      "\n",
      "        categoria  \n",
      "3032  electronica  \n",
      "3033  electronica  \n",
      "3034  electronica  \n",
      "    **************************************************\n",
      "    \n",
      "\u001b[37m\u001b[44m\n",
      "╔═════════════════════════════════════════════════════════════════════════════╗\n",
      "║                            E.T.L.:      df_clientes                         ║\n",
      "╚═════════════════════════════════════════════════════════════════════════════╝\u001b[0m\n",
      "        Descripción preliminar:\n",
      "               id_cliente        edad      ingresos\n",
      "count  578.000000  578.000000    578.000000\n",
      "mean   289.500000   37.968858  34755.977266\n",
      "std    166.998503   10.253244  12989.576812\n",
      "min      1.000000   20.000000    170.290000\n",
      "25%    145.250000   30.000000  26119.060000\n",
      "50%    289.500000   37.000000  35102.285000\n",
      "75%    433.750000   43.000000  42600.435000\n",
      "max    578.000000   81.000000  88053.010000\n",
      "        Dimensiones:      2\n",
      "        Forma:            (578, 5)\n",
      "                filas:    578\n",
      "                Número de elementos:2890\n",
      "                Nombres de filas:RangeIndex(start=0, stop=578, step=1)\n",
      "                columnas: 5\n",
      "                Nombres de columnas:Index(['id_cliente', 'nombre', 'edad', 'ciudad', 'ingresos'], dtype='object')\n",
      "        Valores nulos:    {'id_cliente': 0, 'nombre': 0, 'edad': 0, 'ciudad': 0, 'ingresos': 0}\n",
      "        Valores duplicados:0\n",
      "        Tipos de datos:\n",
      "id_cliente      int64\n",
      "nombre         object\n",
      "edad            int32\n",
      "ciudad         object\n",
      "ingresos      float64\n",
      "dtype: object\n",
      "        Primeras 7 filas:\n",
      "   id_cliente               nombre  edad                 ciudad  ingresos\n",
      "0           1      Aloysia Screase    44          Mar Del Plata  42294.68\n",
      "1           2  Kristina Scaplehorn    25                Posadas  24735.04\n",
      "2           3       Filip Castagne    50            Resistencia  35744.85\n",
      "3           4          Liuka Luard    39           Bahia Blanca  27647.96\n",
      "4           5        Dore Cockshtt    28                Rosario  28245.65\n",
      "5           6        Patrick Earle    34  San Miguel De Tucuman  62763.31\n",
      "6           7           Etan Deeth    35            Resistencia  37489.71\n",
      "        Últimas 3 filas:\n",
      "     id_cliente           nombre  edad         ciudad  ingresos\n",
      "575         576  Cari Marzellano    38  Mar Del Plata  53114.05\n",
      "576         577   Magdalene Pegg    34        Cordoba  49849.42\n",
      "577         578    Lorry Santori    47     Corrientes  42000.81\n",
      "    **************************************************\n",
      "    \n",
      "\u001b[37m\u001b[44m\n",
      "╔═════════════════════════════════════════════════════════════════════════════╗\n",
      "║                            E.T.L.:      df_marketing                        ║\n",
      "╚═════════════════════════════════════════════════════════════════════════════╝\u001b[0m\n",
      "        Descripción preliminar:\n",
      "               id_campanha      costo         fecha_inicio            fecha_fin\n",
      "count    90.000000  90.000000                   90                   90\n",
      "mean     45.500000   4.928666  2024-08-03 16:48:00  2024-09-10 09:04:00\n",
      "min       1.000000   2.950000  2024-03-20 00:00:00  2024-04-20 00:00:00\n",
      "25%      23.250000   4.372500  2024-05-31 00:00:00  2024-07-12 18:00:00\n",
      "50%      45.500000   4.900000  2024-08-02 12:00:00  2024-09-12 12:00:00\n",
      "75%      67.750000   5.562500  2024-10-02 12:00:00  2024-11-11 18:00:00\n",
      "max      90.000000   7.390000  2024-12-29 00:00:00  2025-02-14 00:00:00\n",
      "std      26.124701   0.947750                  NaN                  NaN\n",
      "        Dimensiones:      2\n",
      "        Forma:            (90, 6)\n",
      "                filas:    90\n",
      "                Número de elementos:540\n",
      "                Nombres de filas:RangeIndex(start=0, stop=90, step=1)\n",
      "                columnas: 6\n",
      "                Nombres de columnas:Index(['id_campanha', 'producto', 'canal', 'costo', 'fecha_inicio',\n",
      "       'fecha_fin'],\n",
      "      dtype='object')\n",
      "        Valores nulos:    {'id_campanha': 0, 'producto': 0, 'canal': 0, 'costo': 0, 'fecha_inicio': 0, 'fecha_fin': 0}\n",
      "        Valores duplicados:0\n",
      "        Tipos de datos:\n",
      "id_campanha              int64\n",
      "producto                object\n",
      "canal                   object\n",
      "costo                  float32\n",
      "fecha_inicio    datetime64[ns]\n",
      "fecha_fin       datetime64[ns]\n",
      "dtype: object\n",
      "        Primeras 7 filas:\n",
      "   id_campanha          producto  canal  costo fecha_inicio  fecha_fin\n",
      "0           74   adorno de pared     TV   4.81   2024-03-20 2024-05-03\n",
      "1           12            tablet   RRSS   3.40   2024-03-26 2024-05-13\n",
      "2           32   lampara de mesa  EMAIL   5.54   2024-03-28 2024-04-20\n",
      "3           21        smartphone   RRSS   6.37   2024-03-29 2024-05-16\n",
      "4           58          alfombra  EMAIL   4.25   2024-03-31 2024-05-05\n",
      "5           85        smartwatch     TV   5.07   2024-04-01 2024-05-05\n",
      "6           36  plancha de vapor  EMAIL   5.41   2024-04-02 2024-06-01\n",
      "        Últimas 3 filas:\n",
      "    id_campanha            producto  canal  costo fecha_inicio  fecha_fin\n",
      "87           68   rincon de plantas     TV   5.81   2024-12-17 2025-02-14\n",
      "88           33            secadora  EMAIL   3.80   2024-12-20 2025-01-07\n",
      "89           11  freidora electrica   RRSS   5.27   2024-12-29 2025-01-21\n",
      "    **************************************************\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "def dataframes_en_diccionario():\n",
    "    \"\"\"\n",
    "    Limpia el DataFrame aplicando reglas_por_columna = {\"col\": (\"regla\", parametros)...}\n",
    "    Las reglas se asignan automáticamente según el tipo o formato:\n",
    "      - Columnas numéricas o con símbolos ($, %, dígitos) → 'numeric'\n",
    "      - Columnas que parecen fechas → 'date'\n",
    "      - Otras columnas → 'string'\n",
    "    \"\"\"\n",
    "    for nombre_df, df_cada in dic_dfs.items():           \n",
    "        dic_dfs[nombre_df] = series_en_dataframes(nombre_df, df_cada)\n",
    "        #print (dic_dfs[nombre_df].head(40))\n",
    "        ver( dic_dfs[nombre_df],nombre_df)\n",
    "dataframes_en_diccionario()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e10404-a8a3-4ea9-ab38-c8c49fa8cbcb",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#7FFFD4; padding:10px; border-radius:6px;\">\n",
    "    <h2 style=\"color:black; text-align:center; margin-top:6px;\">Decisión</h2>\n",
    "    <p style=\"color:black;\">\n",
    "    Resolución del analista de datos\n",
    "    </p>\n",
    "    <p style=\"color:black;\">Se encontraron 2 registros NaN</p>\n",
    "        <ul style=\"color:black;\">\n",
    "            <li>Cada registro tiene dos valores faltantes (cantidad y precio)</li>\n",
    "            <li>Los precios se pueden evaluar buscando el mismo producto con fecha similar (inflación)</li>\n",
    "            <li>Las cantidades no se pueden inventar, aunque si el DF fuese más grande y el cliente tuviese varias compras se evaluaría un promedio de las anteriores</li>\n",
    "        </ul>\n",
    "    <p style=\"color:#0000ff;\">En base a esto se procede a borrar los registros con datos nulos o faltantes</p>\n",
    "</div>\n",
    "<!-- si amo la tabulacion/identación -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3eee5bfa-299f-46e6-ad02-e0d2d1f1ec09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Antes:  (3035, 6)\n",
      "Después: (3033, 6)\n",
      "\n",
      "    Se eliminaron '2' registros donde la cantidad estaba en null o NaN\n",
      "    \n",
      "\n",
      "================================================================================\n",
      "REGISTROS ELIMINADOS ACUMULADOS:\n",
      "================================================================================\n",
      "     id_venta               producto  precio  cantidad fecha_venta  \\\n",
      "136       627  elementos de ceramica     NaN       NaN  2024-01-17   \n",
      "139      2171    parlantes bluetooth     NaN       NaN  2024-01-17   \n",
      "\n",
      "       categoria motivo_eliminacion dataframe_origen columna_problema  \n",
      "136   decoracion    NaN en cantidad        df_ventas         cantidad  \n",
      "139  electronica    NaN en cantidad        df_ventas         cantidad  \n",
      "\n",
      "Total de registros eliminados: 2\n"
     ]
    }
   ],
   "source": [
    "def eliminar_registros():\n",
    "    global n_registros_eliminados, df_registros_eliminados\n",
    "    \n",
    "    print(f\"Antes:  {dic_dfs['df_ventas'].shape}\")\n",
    "    \n",
    "    # Guardar cantidad inicial\n",
    "    n_inicial = len(dic_dfs['df_ventas'])\n",
    "    \n",
    "    # Identificar registros con NaN en 'cantidad'\n",
    "    mascara_nulos = dic_dfs['df_ventas']['cantidad'].isna()\n",
    "    registros_a_eliminar = dic_dfs['df_ventas'][mascara_nulos].copy()\n",
    "    \n",
    "    # Agregar información sobre el motivo de eliminación\n",
    "    if not registros_a_eliminar.empty:\n",
    "        registros_a_eliminar['motivo_eliminacion'] = 'NaN en cantidad'\n",
    "        registros_a_eliminar['dataframe_origen'] = 'df_ventas'\n",
    "        registros_a_eliminar['columna_problema'] = 'cantidad'\n",
    "        \n",
    "        # Acumular en el DataFrame global\n",
    "        if 'df_registros_eliminados' not in globals() or df_registros_eliminados is None:\n",
    "            df_registros_eliminados = registros_a_eliminar\n",
    "        else:\n",
    "            df_registros_eliminados = pd.concat([df_registros_eliminados, registros_a_eliminar], ignore_index=True)\n",
    "    \n",
    "    # Eliminar registros con NaN en 'cantidad'\n",
    "    dic_dfs['df_ventas'] = dic_dfs['df_ventas'].dropna(subset=['cantidad'])\n",
    "    \n",
    "    # Calcular registros eliminados\n",
    "    n_final = len(dic_dfs['df_ventas'])\n",
    "    n_registros_eliminados = n_inicial - n_final\n",
    "    \n",
    "    print(f\"Después: {dic_dfs['df_ventas'].shape}\")\n",
    "    print(f\"\"\"\n",
    "    Se eliminaron '{n_registros_eliminados}' registros donde la cantidad estaba en null o NaN\n",
    "    \"\"\")\n",
    "    \n",
    "    return n_registros_eliminados\n",
    "\n",
    "# Inicializar el DataFrame global\n",
    "df_registros_eliminados = None\n",
    "\n",
    "# Ejecutar\n",
    "eliminar_registros()\n",
    "\n",
    "# Ver los registros eliminados\n",
    "if df_registros_eliminados is not None:\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"REGISTROS ELIMINADOS ACUMULADOS:\")\n",
    "    print(\"=\"*80)\n",
    "    print(df_registros_eliminados)\n",
    "    print(f\"\\nTotal de registros eliminados: {len(df_registros_eliminados)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "867ebfb2-e1ce-4153-b2bf-74948055eb52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[30m\u001b[43m [df_ventas] Se encontraron 70 duplicados exactos \u001b[0m\n",
      "\u001b[30m\u001b[44m         [df_clientes] No hay duplicados          \u001b[0m\n",
      "\u001b[30m\u001b[44m         [df_marketing] No hay duplicados         \u001b[0m\n",
      "\n",
      "     id_venta            producto      precio  cantidad fecha_venta  \\\n",
      "820        56            cortinas   66.239998       5.0  2024-04-05   \n",
      "821       421     lampara de mesa  114.830002       9.0  2024-04-05   \n",
      "822       424   jarron decorativo   87.940002       2.0  2024-04-05   \n",
      "823      1868            cafetera   62.230000       1.0  2024-04-05   \n",
      "824      2545         auriculares   32.810001      11.0  2024-04-05   \n",
      "..        ...                 ...         ...       ...         ...   \n",
      "885      1381  freidora electrica   38.119999       2.0  2024-04-08   \n",
      "886      2365         auriculares   92.910004      11.0  2024-04-08   \n",
      "887      2486              laptop  124.949997      11.0  2024-04-08   \n",
      "888      2506              laptop   34.740002       1.0  2024-04-08   \n",
      "889      2705         auriculares   87.290001       2.0  2024-04-08   \n",
      "\n",
      "             categoria  origen_df  \n",
      "820         decoracion  df_ventas  \n",
      "821         decoracion  df_ventas  \n",
      "822         decoracion  df_ventas  \n",
      "823  electrodomesticos  df_ventas  \n",
      "824        electronica  df_ventas  \n",
      "..                 ...        ...  \n",
      "885  electrodomesticos  df_ventas  \n",
      "886        electronica  df_ventas  \n",
      "887        electronica  df_ventas  \n",
      "888        electronica  df_ventas  \n",
      "889        electronica  df_ventas  \n",
      "\n",
      "[70 rows x 7 columns]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def buscar_y_eliminar_duplicados_exactos(nombre_df, df: pd.DataFrame, keep='first', inplace=False) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Elimina duplicados exactos.\n",
    "    \n",
    "    Parámetros:\n",
    "    -----------\n",
    "    nombre_df : str\n",
    "        Nombre del DataFrame\n",
    "    df : DataFrame\n",
    "        DataFrame a procesar\n",
    "    keep : str, default 'first'\n",
    "        - 'first': mantiene la primera ocurrencia\n",
    "        - 'last': mantiene la última ocurrencia\n",
    "        - False: elimina todas las ocurrencias\n",
    "    inplace : bool, default False\n",
    "        Si True, modifica el DataFrame original\n",
    "    \n",
    "    Retorna:\n",
    "    --------\n",
    "    DataFrame sin duplicados (o None si inplace=True)\n",
    "    \"\"\"\n",
    "    global df_duplicados_total\n",
    "    global n_duplicados\n",
    "    # Obtener máscara de duplicados\n",
    "    mascara_duplicados = df.duplicated(keep=False)#(keep=keep)\n",
    "    n_duplicados = mascara_duplicados.sum()\n",
    "    \n",
    "    # Guardar duplicados encontrados\n",
    "    if n_duplicados > 0:\n",
    "        duplicados = df[df.duplicated(keep=False)]  # Todos los duplicados (incluyendo primera ocurrencia)\n",
    "        \n",
    "        # Inicializar o concatenar al DataFrame global\n",
    "        if 'df_duplicados_total' not in globals() or df_duplicados_total is None:\n",
    "            df_duplicados_total = duplicados.copy()\n",
    "            df_duplicados_total['origen_df'] = nombre_df\n",
    "        else:\n",
    "            duplicados_temp = duplicados.copy()\n",
    "            duplicados_temp['origen_df'] = nombre_df\n",
    "            df_duplicados_total = pd.concat([df_duplicados_total, duplicados_temp], ignore_index=True)\n",
    "        print(f\"\"\"{Fore.BLACK+Back.YELLOW}{f\"[{nombre_df}] Se encontraron {n_duplicados} duplicados exactos\".center(50)}{Style.RESET_ALL}\"\"\")\n",
    "        # Eliminar duplicados\n",
    "        if inplace:\n",
    "            df.drop_duplicates(keep=keep, inplace=True)\n",
    "            dic_dfs[nombre_df] = df\n",
    "            return None\n",
    "        else:\n",
    "            df_limpio = df.drop_duplicates(keep=keep)\n",
    "            dic_dfs[nombre_df] = df_limpio\n",
    "            return df_limpio\n",
    "    else:\n",
    "        print(f\"\"\"{Fore.BLACK+Back.BLUE}{f\"[{nombre_df}] No hay duplicados\".center(50)}{Style.RESET_ALL}\"\"\")\n",
    "        if inplace:\n",
    "            return None\n",
    "        else:\n",
    "            return df\n",
    "\n",
    "df_duplicados_total = None\n",
    "\n",
    "# Procesar todos los DataFrames\n",
    "for nombre_df, df_cada in dic_dfs.items():           \n",
    "    buscar_y_eliminar_duplicados_exactos(nombre_df, df_cada)\n",
    "print (f\"\"\"\n",
    "{df_duplicados_total}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6e0227e6-e3da-4d48-bb8b-917e01167f16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Funciones utilitarias definidas.\n"
     ]
    }
   ],
   "source": [
    "def buscar_valores_atipicos_zscore(serie):\n",
    "    \"\"\"\n",
    "    Devuelve máscara booleana (True = outlier) según Z-score.\n",
    "    \"\"\"\n",
    "    serie_limpia = serie.dropna().astype(float)\n",
    "    if serie_limpia.shape[0] < 4 or serie_limpia.std() == 0:\n",
    "        return pd.Series([False] * len(serie), index=serie.index)\n",
    "    puntaje_z = (serie - serie_limpia.mean()) / serie_limpia.std()\n",
    "    return puntaje_z.abs() > desviacion_umbral  \n",
    "print('Funciones utilitarias definidas.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "55788567-c11e-48eb-8e28-45ab210962a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def buscar_valores_atipicos_rango_intercuartil(serie):# Detección de outliers (IQR) - función corregida y robusta\n",
    "    \"\"\"\n",
    "    Devuelve una tupla: (mascara_bool_series, cantidad_outliers, (limite_inferior, limite_superior))\n",
    "    \"\"\"\n",
    "    serie = pd.to_numeric(serie, errors='coerce')\n",
    "    serie_limpia = serie.dropna().astype(float)\n",
    "    \n",
    "    if serie_limpia.shape[0] < 4:\n",
    "        mascara = pd.Series([False] * len(serie), index=serie.index)\n",
    "        return mascara, int(mascara.sum()), (None, None)\n",
    "    \n",
    "    cuartil_1 = float(serie_limpia.quantile(0.25))\n",
    "    cuartil_3 = float(serie_limpia.quantile(0.75))\n",
    "    rango_intercuartil = cuartil_3 - cuartil_1\n",
    "    limite_inferior = cuartil_1 - desviacion_margen * rango_intercuartil\n",
    "    limite_superior = cuartil_3 + desviacion_margen * rango_intercuartil\n",
    "    \n",
    "    mascara = (serie < limite_inferior) | (serie > limite_superior)\n",
    "    mascara = mascara.fillna(False).astype(bool)\n",
    "    \n",
    "    return mascara, int(mascara.sum()), (limite_inferior, limite_superior)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e77b5f-a069-4dd7-b831-56e141c7adcc",
   "metadata": {},
   "source": [
    "## Guardar valores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6e42599a-abe2-4447-b8e6-6c1024f0d651",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nombre_limpio = ventas_limpio.csv\n",
      "Guardado cleaned en: datasets_salida\\limpios\\ventas_limpio.csv\n",
      "nombre_limpio = clientes_limpio.csv\n",
      "Guardado cleaned en: datasets_salida\\limpios\\clientes_limpio.csv\n",
      "nombre_limpio = marketing_limpio.csv\n",
      "Guardado cleaned en: datasets_salida\\limpios\\marketing_limpio.csv\n"
     ]
    }
   ],
   "source": [
    "def guardar_csv(df, ruta):# Función auxiliar para guardar CSVs\n",
    "    \"\"\"\n",
    "    Guarda df en ruta (string o Path). Crea directorio padre si no existe.\n",
    "    \"\"\"\n",
    "    ruta = Path(ruta)\n",
    "    ruta.parent.mkdir(parents=True, exist_ok=True)\n",
    "    df.to_csv(ruta, index=False, encoding='utf-8')\n",
    "    return ruta\n",
    "\n",
    "for [path_archivo, df_actual],[nombre_archivo,_] in zip( dic_dfs.items() , reglas_por_archivo.items() ):\n",
    "\n",
    "    nombre_limpio = nombre_archivo[:-4] + '_limpio.csv' if nombre_archivo.lower().endswith('.csv') else nombre_archivo + ' limpio.csv'\n",
    "    print(f'nombre_limpio = {nombre_limpio}')\n",
    "    # guardar cleaned\n",
    "    ruta_guardado = carpeta_limpios / nombre_limpio\n",
    "    guardar_csv(df_actual, ruta_guardado)\n",
    "    print(f'Guardado cleaned en: {ruta_guardado}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "10bdb094-3598-45a3-9958-6b98c36bf76f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[37m\u001b[44m\n",
      "\n",
      "╔═════════════════════════════════════════════════════════════════════════════╗\n",
      "║                              REPORTE EXCEL GUARDADO                         ║\n",
      "║                     Ruta:    datasets_salida\\reportes\\reporte_limpieza.xlsx ║\n",
      "║                     Estado:          True                                   ║\n",
      "║                                    EXITOSO                                  ║\n",
      "║    Detalle por hoja:                                                        ║\n",
      "╠═════════════════════════════════════════════════════════════════════════════╣\n",
      "║                     Aplico reglas según columna específica                  ║\n",
      "║                     Estado:  Hoja \"outliers\": vacía                         ║\n",
      "║                     Estado:  Hoja \"duplicados\": 70 registros                ║\n",
      "║                     Estado:  Hoja \"eliminados\": 2 registros                 ║\n",
      "╚═════════════════════════════════════════════════════════════════════════════╝\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def guardar_excel():\n",
    "    \"\"\"\n",
    "    Guarda los DataFrames de análisis en un archivo Excel con múltiples hojas.\n",
    "    \n",
    "    Hojas:\n",
    "    - outliers: Valores atípicos detectados\n",
    "    - duplicados: Registros duplicados encontrados\n",
    "    - eliminados: Registros eliminados por NaN u otros motivos\n",
    "    \"\"\"\n",
    "    global df_outliers, df_duplicados_total, df_registros_eliminados\n",
    "    mensajes = []\n",
    "    guardado_ok = False\n",
    "        \n",
    "    try:\n",
    "        with pd.ExcelWriter(ruta_excel, engine='openpyxl') as writer:\n",
    "            \n",
    "            # Hoja 1: Outliers\n",
    "            try:\n",
    "                if 'df_outliers' in globals() and df_outliers is not None and not df_outliers.empty:\n",
    "                    df_outliers.to_excel(writer, index=False, sheet_name='outliers')\n",
    "                    mensajes.append(f'Hoja \"outliers\": {len(df_outliers)} registros')\n",
    "                else:\n",
    "                    pd.DataFrame({'mensaje': ['No se detectaron outliers']}).to_excel(writer, index=False, sheet_name='outliers')\n",
    "                    mensajes.append('Hoja \"outliers\": vacía')\n",
    "            except Exception as e:\n",
    "                pd.DataFrame({'error': [str(e)]}).to_excel(writer, index=False, sheet_name='outliers')\n",
    "                mensajes.append(f'Error en hoja \"outliers\": {str(e)}')\n",
    "            \n",
    "            # Hoja 2: Duplicados\n",
    "            try:\n",
    "                if 'df_duplicados_total' in globals() and df_duplicados_total is not None and not df_duplicados_total.empty:\n",
    "                    df_duplicados_total.to_excel(writer, index=False, sheet_name='duplicados')\n",
    "                    mensajes.append(f'Hoja \"duplicados\": {len(df_duplicados_total)} registros')\n",
    "                else:\n",
    "                    pd.DataFrame({'mensaje': ['No se encontraron duplicados']}).to_excel(writer, index=False, sheet_name='duplicados')\n",
    "                    mensajes.append('Hoja \"duplicados\": vacía')\n",
    "            except Exception as e:\n",
    "                pd.DataFrame({'error': [str(e)]}).to_excel(writer, index=False, sheet_name='duplicados')\n",
    "                mensajes.append(f'Error en hoja \"duplicados\": {str(e)}')\n",
    "            \n",
    "            # Hoja 3: Registros eliminados\n",
    "            try:\n",
    "                if 'df_registros_eliminados' in globals() and df_registros_eliminados is not None and not df_registros_eliminados.empty:\n",
    "                    df_registros_eliminados.to_excel(writer, index=False, sheet_name='eliminados')\n",
    "                    mensajes.append(f'Hoja \"eliminados\": {len(df_registros_eliminados)} registros')\n",
    "                else:\n",
    "                    pd.DataFrame({'mensaje': ['No se eliminaron registros']}).to_excel(writer, index=False, sheet_name='eliminados')\n",
    "                    mensajes.append('Hoja \"eliminados\": vacía')\n",
    "            except Exception as e:\n",
    "                pd.DataFrame({'error': [str(e)]}).to_excel(writer, index=False, sheet_name='eliminados')\n",
    "                mensajes.append(f'Error en hoja \"eliminados\": {str(e)}')\n",
    "        \n",
    "        guardado_ok = True\n",
    "        \n",
    "    except Exception as e_openpyxl:\n",
    "        mensajes.append(f'Error usando openpyxl: {str(e_openpyxl)}')\n",
    "        guardado_ok = False\n",
    "    print(f\"\"\"{Fore.WHITE+Back.BLUE}\\n\n",
    "╔═════════════════════════════════════════════════════════════════════════════╗\n",
    "║                              REPORTE EXCEL GUARDADO                         ║\n",
    "║                     Ruta:    {str(ruta_excel).center(40)} ║\n",
    "║                     Estado:  {str(guardado_ok).center(20)}                           ║\n",
    "║                              {\"EXITOSO\".center(20) if guardado_ok else \"FALLIDO\".center(20)}                           ║\n",
    "║    Detalle por hoja:                                                        ║\n",
    "╠═════════════════════════════════════════════════════════════════════════════╣\n",
    "║                     Aplico reglas según columna específica                  ║\"\"\")\n",
    "    for m in mensajes:\n",
    "        print (f\"\"\"║                     Estado:  {m.ljust(40)}       ║\"\"\")\n",
    "    print (f\"\"\"╚═════════════════════════════════════════════════════════════════════════════╝{Style.RESET_ALL}\"\"\")\n",
    "   \n",
    "    return guardado_ok"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f411cb90-17af-45f2-9dfb-9fe7534bacbb",
   "metadata": {},
   "source": [
    "# limpieza y normalización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "32235fb9-1e09-422e-931b-3471d6fbf123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "\u001b[37m\u001b[44m\n",
      "\n",
      "╔═════════════════════════════════════════════════════════════════════════════╗\n",
      "║                              Valores Modificado                             ║\n",
      "╠═════════════════════════════════════════════════════════════════════════════╣\n",
      "║     Afecta                                                                  ║\n",
      "║         Elimina espacios iniciales y finales.                               ║\n",
      "║         Borra Na                                                            ║\n",
      "║         Borra duplicados                                                    ║\n",
      "╠═════════════════════════════════════════════════════════════════════════════╣\n",
      "║                     Aplico reglas según columna específica                  ║\n",
      "╠═════════════════════════════════════════════════════════════════════════════╣\n",
      "║     Afecta                                                                  ║\n",
      "║             Numéricos (int/float)                                           ║\n",
      "║             fechas --> YYYY,MM,DD                                           ║\n",
      "╚═════════════════════════════════════════════════════════════════════════════╝\u001b[0m\n",
      "\u001b[37m\u001b[44m\n",
      "\n",
      "╔═════════════════════════════════════════════════════════════════════════════╗\n",
      "║                                   ventas.csv                                ║\n",
      "╚═════════════════════════════════════════════════════════════════════════════╝\u001b[0m\n",
      "\n",
      "╔═══════════════════════════════════════════════════════════════════════════╗\n",
      "║ DataFrame:                          ventas.csv                            ║\n",
      "║ Columna:                             id_venta                             ║\n",
      "╠═══════════════════════════════════════════════════════════════════════════╣\n",
      "║ Outliers por Z-score:                          0                          ║\n",
      "║ Outliers por IQR:                              0                          ║\n",
      "║ Total combinado:                               0                          ║\n",
      "║ Límites IQR:           [ -1498.0  ,   4500.0  ]                           ║\n",
      "╚═══════════════════════════════════════════════════════════════════════════╝\n",
      "\n",
      "\n",
      "╔═══════════════════════════════════════════════════════════════════════════╗\n",
      "║ DataFrame:                          ventas.csv                            ║\n",
      "║ Columna:                              precio                              ║\n",
      "╠═══════════════════════════════════════════════════════════════════════════╣\n",
      "║ Outliers por Z-score:                          0                          ║\n",
      "║ Outliers por IQR:                              0                          ║\n",
      "║ Total combinado:                               0                          ║\n",
      "║ Límites IQR:           [  -25.03  ,   175.12  ]                           ║\n",
      "╚═══════════════════════════════════════════════════════════════════════════╝\n",
      "\n",
      "\n",
      "╔═══════════════════════════════════════════════════════════════════════════╗\n",
      "║ DataFrame:                          ventas.csv                            ║\n",
      "║ Columna:                             cantidad                             ║\n",
      "╠═══════════════════════════════════════════════════════════════════════════╣\n",
      "║ Outliers por Z-score:                          0                          ║\n",
      "║ Outliers por IQR:                              0                          ║\n",
      "║ Total combinado:                               0                          ║\n",
      "║ Límites IQR:           [   -6.0   ,    18.0   ]                           ║\n",
      "╚═══════════════════════════════════════════════════════════════════════════╝\n",
      "\n",
      "\n",
      "================================================================================\n",
      "RESUMEN TOTAL DE OUTLIERS DETECTADOS: 0\n",
      "================================================================================\n",
      "\n",
      "\u001b[37m\u001b[44m\n",
      "\n",
      "╔═════════════════════════════════════════════════════════════════════════════╗\n",
      "║                                  clientes.csv                               ║\n",
      "╚═════════════════════════════════════════════════════════════════════════════╝\u001b[0m\n",
      "\n",
      "╔═══════════════════════════════════════════════════════════════════════════╗\n",
      "║ DataFrame:                         clientes.csv                           ║\n",
      "║ Columna:                            id_cliente                            ║\n",
      "╠═══════════════════════════════════════════════════════════════════════════╣\n",
      "║ Outliers por Z-score:                          0                          ║\n",
      "║ Outliers por IQR:                              0                          ║\n",
      "║ Total combinado:                               0                          ║\n",
      "║ Límites IQR:           [  -287.5  ,   866.5   ]                           ║\n",
      "╚═══════════════════════════════════════════════════════════════════════════╝\n",
      "\n",
      "\n",
      "╔═══════════════════════════════════════════════════════════════════════════╗\n",
      "║ DataFrame:                         clientes.csv                           ║\n",
      "║ Columna:                               edad                               ║\n",
      "╠═══════════════════════════════════════════════════════════════════════════╣\n",
      "║ Outliers por Z-score:                          9                          ║\n",
      "║ Outliers por IQR:                              17                         ║\n",
      "║ Total combinado:                               17                         ║\n",
      "║ Límites IQR:           [   10.5   ,    62.5   ]                           ║\n",
      "╚═══════════════════════════════════════════════════════════════════════════╝\n",
      "\n",
      "\n",
      "╔═══════════════════════════════════════════════════════════════════════════╗\n",
      "║ DataFrame:                         clientes.csv                           ║\n",
      "║ Columna:                             ingresos                             ║\n",
      "╠═══════════════════════════════════════════════════════════════════════════╣\n",
      "║ Outliers por Z-score:                          2                          ║\n",
      "║ Outliers por IQR:                              6                          ║\n",
      "║ Total combinado:                               6                          ║\n",
      "║ Límites IQR:           [  1397.0  ,  67322.5  ]                           ║\n",
      "╚═══════════════════════════════════════════════════════════════════════════╝\n",
      "\n",
      "\n",
      "================================================================================\n",
      "RESUMEN TOTAL DE OUTLIERS DETECTADOS: 23\n",
      "================================================================================\n",
      "\n",
      "      dataframe columna  indice  valor metodo_deteccion   z_score  \\\n",
      "0  clientes.csv    edad      10   69.0     Z-score, IQR  3.026471   \n",
      "1  clientes.csv    edad     114   65.0              IQR  2.636350   \n",
      "2  clientes.csv    edad     127   81.0     Z-score, IQR  4.196832   \n",
      "3  clientes.csv    edad     177   75.0     Z-score, IQR  3.611651   \n",
      "4  clientes.csv    edad     214   71.0     Z-score, IQR  3.221531   \n",
      "\n",
      "   limite_inf_iqr  limite_sup_iqr  media_serie  std_serie  \n",
      "0            10.5            62.5    37.968858  10.253244  \n",
      "1            10.5            62.5    37.968858  10.253244  \n",
      "2            10.5            62.5    37.968858  10.253244  \n",
      "3            10.5            62.5    37.968858  10.253244  \n",
      "4            10.5            62.5    37.968858  10.253244  \n",
      "\n",
      " Outliers guardados en: datasets_salida\\reportes\\outliers_detectados.csv\n",
      "\u001b[37m\u001b[44m\n",
      "\n",
      "╔═════════════════════════════════════════════════════════════════════════════╗\n",
      "║                                 marketing.csv                               ║\n",
      "╚═════════════════════════════════════════════════════════════════════════════╝\u001b[0m\n",
      "\n",
      "╔═══════════════════════════════════════════════════════════════════════════╗\n",
      "║ DataFrame:                        marketing.csv                           ║\n",
      "║ Columna:                           id_campanha                            ║\n",
      "╠═══════════════════════════════════════════════════════════════════════════╣\n",
      "║ Outliers por Z-score:                          0                          ║\n",
      "║ Outliers por IQR:                              0                          ║\n",
      "║ Total combinado:                               0                          ║\n",
      "║ Límites IQR:           [  -43.5   ,   134.5   ]                           ║\n",
      "╚═══════════════════════════════════════════════════════════════════════════╝\n",
      "\n",
      "\n",
      "╔═══════════════════════════════════════════════════════════════════════════╗\n",
      "║ DataFrame:                        marketing.csv                           ║\n",
      "║ Columna:                              costo                               ║\n",
      "╠═══════════════════════════════════════════════════════════════════════════╣\n",
      "║ Outliers por Z-score:                          0                          ║\n",
      "║ Outliers por IQR:                              1                          ║\n",
      "║ Total combinado:                               1                          ║\n",
      "║ Límites IQR:           [   2.59   ,    7.35   ]                           ║\n",
      "╚═══════════════════════════════════════════════════════════════════════════╝\n",
      "\n",
      "\n",
      "================================================================================\n",
      "RESUMEN TOTAL DE OUTLIERS DETECTADOS: 24\n",
      "================================================================================\n",
      "\n",
      "      dataframe columna  indice  valor metodo_deteccion   z_score  \\\n",
      "0  clientes.csv    edad      10   69.0     Z-score, IQR  3.026471   \n",
      "1  clientes.csv    edad     114   65.0              IQR  2.636350   \n",
      "2  clientes.csv    edad     127   81.0     Z-score, IQR  4.196832   \n",
      "3  clientes.csv    edad     177   75.0     Z-score, IQR  3.611651   \n",
      "4  clientes.csv    edad     214   71.0     Z-score, IQR  3.221531   \n",
      "\n",
      "   limite_inf_iqr  limite_sup_iqr  media_serie  std_serie  \n",
      "0            10.5            62.5    37.968858  10.253244  \n",
      "1            10.5            62.5    37.968858  10.253244  \n",
      "2            10.5            62.5    37.968858  10.253244  \n",
      "3            10.5            62.5    37.968858  10.253244  \n",
      "4            10.5            62.5    37.968858  10.253244  \n",
      "\n",
      " Outliers guardados en: datasets_salida\\reportes\\outliers_detectados.csv\n",
      "\u001b[37m\u001b[44m\n",
      "\n",
      "╔═════════════════════════════════════════════════════════════════════════════╗\n",
      "║                              REPORTE EXCEL GUARDADO                         ║\n",
      "║                     Ruta:    datasets_salida\\reportes\\reporte_limpieza.xlsx ║\n",
      "║                     Estado:          True                                   ║\n",
      "║                                    EXITOSO                                  ║\n",
      "║    Detalle por hoja:                                                        ║\n",
      "╠═════════════════════════════════════════════════════════════════════════════╣\n",
      "║                     Aplico reglas según columna específica                  ║\n",
      "║                     Estado:  Hoja \"outliers\": 24 registros                  ║\n",
      "║                     Estado:  Hoja \"duplicados\": 70 registros                ║\n",
      "║                     Estado:  Hoja \"eliminados\": 2 registros                 ║\n",
      "╚═════════════════════════════════════════════════════════════════════════════╝\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def menu_procesar_diccionario():\n",
    "    \"\"\"\n",
    "    Recorre dic_frames y detecta outliers, guardándolos en un DataFrame\n",
    "    \"\"\"\n",
    "    print(f\"\"\"{Fore.WHITE+Back.BLUE}\\n\n",
    "╔═════════════════════════════════════════════════════════════════════════════╗\n",
    "║                              Valores Modificado                             ║\n",
    "╠═════════════════════════════════════════════════════════════════════════════╣\n",
    "║     Afecta                                                                  ║\n",
    "║         Elimina espacios iniciales y finales.                               ║\n",
    "║         Borra Na                                                            ║\n",
    "║         Borra duplicados                                                    ║\n",
    "╠═════════════════════════════════════════════════════════════════════════════╣\n",
    "║                     Aplico reglas según columna específica                  ║\n",
    "╠═════════════════════════════════════════════════════════════════════════════╣\n",
    "║     Afecta                                                                  ║\n",
    "║             Numéricos (int/float)                                           ║\n",
    "║             fechas --> YYYY,MM,DD                                           ║\n",
    "╚═════════════════════════════════════════════════════════════════════════════╝{Style.RESET_ALL}\"\"\")\n",
    "    outliers_totales = [] \n",
    "    for [path_archivo, df_actual], [nombre_archivo, _] in zip(dic_dfs.items(), reglas_por_archivo.items()):\n",
    "        print(f\"\"\"{Fore.WHITE+Back.BLUE}\\n\n",
    "╔═════════════════════════════════════════════════════════════════════════════╗\n",
    "║                              {nombre_archivo.center(20)}                           ║\n",
    "╚═════════════════════════════════════════════════════════════════════════════╝{Style.RESET_ALL}\"\"\")\n",
    "        for columna in df_actual.columns:\n",
    "            serie = df_actual[columna]\n",
    "            \n",
    "            # Verificar si es numérica\n",
    "            if serie.dtype.kind not in ['i', 'f']:\n",
    "                continue\n",
    "\n",
    "            if len(serie) < 4:\n",
    "                continue\n",
    "            mascara_zscore = buscar_valores_atipicos_zscore(serie)\n",
    "            \n",
    "            # Detección por IQR\n",
    "            mascara_iqr, cant_iqr, (lim_inf, lim_sup) = buscar_valores_atipicos_rango_intercuartil(serie)\n",
    "            lim_inf=round(lim_inf,2)\n",
    "            lim_sup=round(lim_sup,2)\n",
    "            # Combinar métodos: outlier detectado por al menos un método\n",
    "            mascara_combinada = mascara_zscore | mascara_iqr\n",
    "            \n",
    "            # Si hay outliers, guardarlos\n",
    "            if mascara_combinada.sum() > 0:\n",
    "                # Obtener índices de outliers\n",
    "                indices_outliers = serie[mascara_combinada].index\n",
    "                \n",
    "                for idx in indices_outliers:\n",
    "                    valor = serie.loc[idx]\n",
    "                    \n",
    "                    # Determinar qué métodos lo detectaron\n",
    "                    metodos = []\n",
    "                    if mascara_zscore.loc[idx]:\n",
    "                        metodos.append('Z-score')\n",
    "                    if mascara_iqr.loc[idx]:\n",
    "                        metodos.append('IQR')\n",
    "                    \n",
    "                    # Calcular Z-score del valor\n",
    "                    if serie.std() != 0:\n",
    "                        z_valor = (valor - serie.mean()) / serie.std()\n",
    "                    else:\n",
    "                        z_valor = None\n",
    "                    \n",
    "                    outliers_totales.append({\n",
    "                        'dataframe': nombre_archivo,\n",
    "                        'columna': columna,\n",
    "                        'indice': idx,\n",
    "                        'valor': valor,\n",
    "                        'metodo_deteccion': ', '.join(metodos),\n",
    "                        'z_score': z_valor,\n",
    "                        'limite_inf_iqr': lim_inf,\n",
    "                        'limite_sup_iqr': lim_sup,\n",
    "                        'media_serie': serie.mean(),\n",
    "                        'std_serie': serie.std()\n",
    "                    })\n",
    "            \n",
    "            # Imprimir resumen\n",
    "            print(f\"\"\"\n",
    "╔═══════════════════════════════════════════════════════════════════════════╗\n",
    "║ DataFrame: {nombre_archivo.center(60)}   ║\n",
    "║ Columna: {columna.center(64)} ║\n",
    "╠═══════════════════════════════════════════════════════════════════════════╣\n",
    "║ Outliers por Z-score:  {str(mascara_zscore.sum()).center(50)} ║\n",
    "║ Outliers por IQR:      {str(cant_iqr).center(50)} ║\n",
    "║ Total combinado:       {str(mascara_combinada.sum()).center(50)} ║\n",
    "║ Límites IQR:           [{str(lim_inf).center(10)}, {str(lim_sup).center(10)}]                           ║\n",
    "╚═══════════════════════════════════════════════════════════════════════════╝\n",
    "\"\"\")\n",
    "        \n",
    "        # Crear DataFrame con todos los outliers\n",
    "        df_outliers = pd.DataFrame(outliers_totales)\n",
    "        \n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"RESUMEN TOTAL DE OUTLIERS DETECTADOS: {len(df_outliers)}\")\n",
    "        print(f\"{'='*80}\\n\")\n",
    "        \n",
    "        if not df_outliers.empty:\n",
    "            print(df_outliers.head(5))\n",
    "            ruta_outliers = carpeta_reportes / 'outliers_detectados.csv'\n",
    "            guardar_csv(df_outliers, ruta_outliers)\n",
    "            print(f\"\\n Outliers guardados en: {ruta_outliers}\")\n",
    "    return df_outliers\n",
    "print (\"*\"*50)\n",
    "df_outliers = menu_procesar_diccionario()\n",
    "guardar_excel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f4ffe5-0f8d-465e-be9e-6d180fa42789",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#CCCCCC; padding:10px; border-radius:6px;\">\n",
    "    <h2 style=\"color:black; text-align:center;\">Resultados de limpieza</h2>\n",
    "    <p style=\"color:black;\">- Revisados los 3 csv  pasados a DataFrames.</p>\n",
    "    <p style=\"color:blue;\">- DataFrames filtrados.</p>\n",
    "        <ul>\n",
    "            <li style=\"color:black;\">- Filtrado de Nulos.</li>\n",
    "            <li style=\"color:black;\">- Filtrado de duplicados.</li>\n",
    "            <li style=\"color:black;\">- Sin '', 'na', 'n/a', 'null', 'none', 'sin dato', 's/d', 'nd', '-', '--', '?', 'sin_dato', 'n/d'</li>    \n",
    "            <li style=\"color:black;\">- Normalisados Strings segun reglas. Estilo (lower,string.upper) unicodedata.normalize('NFKD')</li>\n",
    "            <li style=\"color:black;\">- Normalisados Strings segun reglas. sin acentos</li>\n",
    "            <li style=\"color:black;\">- Normalisados precios a float sin signo ($)</li>\n",
    "            <li style=\"color:black;\">- Normalisados Numericos a int o float segun regla</li>    \n",
    "            <li style=\"color:black;\">- Normalisados Fechas segun regla YYYY/MM/DD</li>    \n",
    "        </ul>\n",
    "    <p style=\"color:black;\">- Resguardo <code>datasets_salida/limpios/clientes_limpio.csv</code>.</p>\n",
    "    <p style=\"color:black;\">- Resguardo <code>datasets_salida/limpios/marketing_limpio.csv</code>.</p>\n",
    "    <p style=\"color:black;\">- Resguardo <code>datasets_salida/limpios/ventas_limpio.csv</code>.</p>\n",
    "    <p style=\"color:blue;\">- Registros filtrados eliminados</p>\n",
    "    <p style=\"color:black;\">- Resguardo <code>datasets_salida/reportes/reporte_limpieza.xlsx</code> con hojas (duplicados con igual id borrados, outliers, valores faltantes)</p>\n",
    "</div><!-- dios salve lña tabulacion :)-->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f43150b-eb7b-4ae8-a0a6-233f4b6ca5f1",
   "metadata": {},
   "source": [
    "ventas.csv  análisis de ventas, limpieza de datos y estadísticas descriptivas.\n",
    " \t\n",
    "clientes.csv  unirse a las ventas mediante el uso de funciones de combinación para analizar características de los clientes relacionados con sus \tcompras.\n",
    " \t\n",
    "marketing.csv analizar la efectividad de las campañas de marketing en las ventas y buscar correlaciones.\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4f5fcf9c-6140-4160-9ca0-ebf688f8c921",
   "metadata": {},
   "source": [
    "2) Claves candidatas para merge o concat\n",
    "\n",
    "Intersecciones observadas:\n",
    "\n",
    "ventas ∩ marketing → producto (clave natural para unir campañas con ventas por producto)\n",
    "\n",
    "ventas ∩ clientes → ninguna columna en común\n",
    "\n",
    "clientes ∩ marketing → ninguna columna en común\n",
    "\n",
    "Interpretación pedagógica:\n",
    "\n",
    "Puedes unir ventas con marketing por producto (p. ej. para ver qué canal promocionó qué producto y coste).\n",
    "\n",
    "No puedes unir directamente ventas con clientes porque ventas_limpio no contiene id_cliente ni email ni nombre_cliente. Para unir ventas↔clientes necesitas:\n",
    "\n",
    "que ventas_limpio tenga una columna id_cliente (recomendado), o\n",
    "\n",
    "un fichero/mapeo que vincule id_venta → id_cliente, o\n",
    "\n",
    "usar correspondencia por email/nombre (menos fiable) si esos campos existieran.\n",
    "\n",
    "3) Ejemplos de combinaciones útiles (casos prácticos)\n",
    "\n",
    "Ventas por canal de marketing (recomendado)\n",
    "\n",
    "Merge ventas_limpio ⟵ marketing_limpio por producto (left join): asignás a cada venta el canal y id_campanha. Luego agrupás por canal para métricas.\n",
    "\n",
    "Análisis de ticket promedio por categoría y canal\n",
    "\n",
    "Después del merge anterior, crear monto = precio * cantidad y agrupar por categoria y canal.\n",
    "\n",
    "Concatenación (vertical)\n",
    "\n",
    "Si tuvieras varios archivos de ventas de distintos periodos: pd.concat([ventas_periodo1, ventas_periodo2], axis=0).\n",
    "\n",
    "Unir clientes (si se dispone de id_cliente en ventas)\n",
    "\n",
    "ventas_limpio.merge(clientes_limpio, on='id_cliente', how='left') → permite segmentar ventas por edad, ciudad, ingresos.\n",
    "\n",
    "Si no hay id_cliente en ventas\n",
    "\n",
    "Crear un mapping table (archivo) que contenga id_venta → id_cliente y hacer merge por esa tabla.\n",
    "\n",
    "4) Código limpio en pandas (listo para ejecutar — adaptá nombres de columnas si quieres otro comportamiento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93885b49-e04a-401c-9c03-78439696cdbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 4) Crear columnas útiles\n",
    "ventas['monto'] = ventas['precio'] * ventas['cantidad']\n",
    "\n",
    "# 5) Merge ejemplo: ventas + marketing por 'producto' (asignar canal a cada venta)\n",
    "ventas_marketing = pd.merge(\n",
    "    ventas,\n",
    "    marketing[['producto', 'id_campanha', 'canal', 'costo', 'fecha_inicio', 'fecha_fin']],\n",
    "    on='producto',\n",
    "    how='left',   # left para conservar todas las ventas aunque no tengan campana asociada\n",
    "    validate='m:1'  # opcional: espera muchos registros ventas para 1 campaña por producto\n",
    ")\n",
    "\n",
    "# 6) Agregados: ventas por canal\n",
    "ventas_por_canal = (\n",
    "    ventas_marketing\n",
    "    .groupby('canal', dropna=False)\n",
    "    .agg(\n",
    "        total_monto=('monto', 'sum'),\n",
    "        cantidad_transacciones=('monto', 'count'),\n",
    "        ticket_promedio=('monto', 'mean')\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# 7) Agregado: ventas por categoria y canal\n",
    "ventas_categoria_canal = (\n",
    "    ventas_marketing\n",
    "    .groupby(['categoria', 'canal'], dropna=False)\n",
    "    .agg(\n",
    "        total_monto     = ('monto', 'sum'),\n",
    "        transacciones   = ('monto', 'count'),\n",
    "        ticket_promedio = ('monto', 'mean')\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# 8) Guardar resultados (opcional)\n",
    "ventas_por_canal.to_csv('/mnt/data/ventas_por_canal.csv', index=False)\n",
    "ventas_categoria_canal.to_csv('/mnt/data/ventas_categoria_canal.csv', index=False)\n",
    "\n",
    "# 9) ¿Y clientes? Si tienes id_cliente en ventas:\n",
    "# ventas_con_clientes = ventas.merge(clientes, on='id_cliente', how='left')\n",
    "\n",
    "# 10) Checks útiles\n",
    "# - Ver duplicados en claves: ventas['id_venta'].duplicated().sum()\n",
    "# - Ver clientes sin ventas: clientes[~clientes['id_cliente'].isin(ventas.get('id_cliente', []))]\n",
    "\n",
    "Recomendaciones prácticas (breves, accionables)\n",
    "\n",
    "Si querés unir ventas con clientes agregá id_cliente a ventas_limpio (registro en punto de venta o mapeo).\n",
    "\n",
    "Revisá duplicados en producto dentro de marketing (puede haber varias campañas por producto: decidir estrategia — por ejemplo filtrar la campaña activa por fecha).\n",
    "\n",
    "Elegí tipo de join con criterio pedagógico:\n",
    "\n",
    "left join para preservar todas las ventas (evitar perder datos).\n",
    "\n",
    "inner join si sólo te interesa el subset con campaña asociada.\n",
    "\n",
    "Creá fecha de periodo (día/semana/mes) para series temporales: ventas['mes'] = ventas['fecha_venta'].dt.to_period('M').\n",
    "\n",
    "Documentá supuestos: por qué usás how='left', cómo tratás ventas sin campaña, cómo imputás nulos en precio/cantidad.\n",
    "\n",
    "Ejemplo aplicado (interpretación cotidiana)\n",
    "\n",
    "Imaginá a Juan, vendedor en una pyme familiar con 2 hijos. Quiere saber si la campaña en Instagram está trayendo ventas: con el merge ventas + marketing por producto obtiene canal asignado a cada venta. Luego agrupa por canal y ve: “Instagram” tiene muchas visitas pero ticket promedio bajo — decisión: ajustar oferta o dirigir una campaña de cross-sell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac691bd-d59b-41cc-88d8-a3baf48602a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40448d5e-62bf-4d58-9c5c-28da021964b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "a mano\n",
    "ver que es lo que falta en drop na\n",
    "precios == 0 buscar en categoria el producto o promedo si no hay otro dato\n",
    "duplicate si el id es =\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21ab2c8-5a03-4fe6-9f02-60d2dc73d966",
   "metadata": {},
   "outputs": [],
   "source": [
    "productos mas vendidos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0737e69-7b61-4fa9-b678-3a178e09b62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ventas por mes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65774cce-e62e-4a81-826a-260f0f04fb0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ventas mayores al persentil 80 (alto rendimiento) de precio x cantidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d1d542-093a-49ad-b788-5e1b23af562d",
   "metadata": {},
   "outputs": [],
   "source": [
    "git remote set-url origin https://github.com/CursosAGT/nombre-nuevo.git\n",
    "git push -u origin main\n",
    "https://github.com/CursosAGT/-GarciaTrabaArielH-Comisi-n25262-TPI_Data_Analytics/blob/main/Garcia%20Traba%20Ariel%20H%20-%20Comisi%C3%B3n%2025262%20-%20TPI%20Data%20Analytics.ipynb\n",
    "Garcia Traba Ariel H - Comisión 25262 - TPI Data Analytics.ipynb\n",
    "https://github.com/CursosAGT/-GarciaTrabaArielH-Comisi-n25262-TPI_Data_Analytics/blob/main/datasets_entrada/clientes.csv\n",
    "https://github.com/CursosAGT/-GarciaTrabaArielH-Comisi-n25262-TPI_Data_Analytics/blob/main/datasets_entrada/marketing.csv\n",
    "https://github.com/CursosAGT/-GarciaTrabaArielH-Comisi-n25262-TPI_Data_Analytics/blob/main/datasets_entrada/ventas.csv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
