{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cedbb1b4",
   "metadata": {},
   "source": [
    "\n",
    "<div style=\"background-color:#CCCCCC; padding:12px; border-radius:8px;\">\n",
    "<h1 style=\"color:#003366; text-align:center; margin:8px 0;\">Revisión y limpieza de 3 DataFrames (TPI - Data Analytics)</h1>\n",
    "<p style=\"text-align:center; color:#003366; margin:0;\"><em>Notebook docente en castellano — nombres descriptivos en snake_case — código y documentación</em></p>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c723b86a",
   "metadata": {},
   "source": [
    "\n",
    "<div style=\"background-color:#CCCCCC; padding:10px; border-radius:6px;\">\n",
    "<h2 style=\"color:black; text-align:center; margin-top:6px;\">Resumen</h2>\n",
    "\n",
    "<p style=\"color:black;\">\n",
    "Este notebook está diseñado con finalidades pedagógicas. Revisa, normaliza y valida tres datasets contenidos en CSV:\n",
    "</p>\n",
    "\n",
    "<ul style=\"color:black;\">\n",
    "<li><code>marketing.csv</code> → variable: <code>df_marketing</code></li>\n",
    "<li><code>ventas.csv</code>    → variable: <code>df_ventas</code></li>\n",
    "<li><code>clientes.csv</code>  → variable: <code>df_clientes</code></li>\n",
    "</ul>\n",
    "\n",
    "<p style=\"color:black;\">\n",
    "Coloca los CSV en <code>./data_in/</code> o en <code>/mnt/data/</code>. El notebook busca primero en <code>./data_in/</code> y si no encuentra, usa <code>/mnt/data/</code> (útil para entornos donde los archivos están pre-subidos).\n",
    "</p>\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be46fb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports y configuración inicial (nombres en castellano)\n",
    "import os, re, json, unicodedata\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from math import isnan\n",
    "import zipfile\n",
    "from collections import defaultdict\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Dict, Any, Optional\n",
    "ruta_base = \"./\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63edff5b-828e-4254-a4d7-4b0ef05ecea6",
   "metadata": {},
   "source": [
    "## 1. Crear un documento en Google Colaboratory y cargar los sets de datos como DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddfa535f-ef52-4f49-9d1b-e70dd8d5ad27",
   "metadata": {},
   "source": [
    "si se usa en disco local comentarla celda de debajo (JuPyteR , VSC, ATOM, Spider, Geany, etc)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "00de9cf8-da0d-4d31-bed7-31a704a7274d",
   "metadata": {},
   "source": [
    "# --- Paso 1: Montar Google Drive ---\n",
    "# Montar tu Google Drive\n",
    "!pip install google\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "!ls \"/content/drive/MyDrive/CABA/Garcia Traba Ariel H - Comisión 25262 - TPI Data Analytics/\"\n",
    "# Ruta del archivo (ajústala a la carpeta real en tu Drive)\n",
    "ruta_base = \"/content/drive/MyDrive/CABA/Garcia Traba Ariel H - Comisión 25262 - TPI Data Analytics/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "144444b3-1dc1-4f3f-a621-025d1cdb6465",
   "metadata": {},
   "source": [
    "# 1ra parte Definición de ETL\n",
    "ETL es un conjunto de procedimientos que permiten mover datos desde sistemas de origen, que pueden ser bases de datos, archivos o fuentes en la nube, hasta un sistema de destino como un data warehouse o data lake, realizando previamente procesos de limpieza, estructuración y organización de los datos para hacerlos aptos para análisis.​\n",
    "\n",
    "## Fases del proceso ETL\n",
    "Extracción: Consiste en recopilar datos relevantes de diferentes fuentes, asegurando que el impacto en los sistemas origen sea mínimo. Los datos pueden extraerse mediante diversos métodos como consultas SQL o servicios web.​\n",
    "\n",
    "Transformación: En esta etapa, los datos se limpian y se ajustan para garantizar coherencia y calidad, incluyendo la eliminación de valores nulos, normalización y conversión a formatos consistentes, además de aplicar reglas específicas de negocio.\n",
    "\n",
    "Carga: Finalmente, los datos transformados se cargan en el sistema de destino, donde estarán disponibles para análisis, informes o modelado de datos.\n",
    "\n",
    "## Importancia del ETL\n",
    "Es crucial en la minería de datos porque preparar los datos brutos para que puedan ser utilizados en análisis estadísticos, modelados predictivos o técnicas de aprendizaje automático, asegurando la calidad, coherencia y accesibilidad de la información."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4225f2e7-fccf-4a13-86a6-92acee434aa7",
   "metadata": {},
   "source": [
    "## desde python sin librerias pandas / polars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86754f0-a78b-453c-9127-5abd20e1877d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876facae-5d32-47aa-8b55-d9b04deadb85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2c8f6200-1ad0-4fa8-9cf1-aa1df22c4b3b",
   "metadata": {},
   "source": [
    "### 1.1 Crear estructura de directorios segun modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "605182b8-9652-410e-8c79-13b10a33e692",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rutas: \n",
    "\n",
    "carpeta_entrada    = Path(ruta_base)\n",
    "#carpeta_entrada_mnt   = Path('/mnt/data')\n",
    "carpeta_datasets_entrada   = carpeta_entrada / 'datasets_entrada'\n",
    "carpeta_datasets_entrada.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "carpeta_datasets_salida   = carpeta_entrada / 'datasets_salida'\n",
    "carpeta_datasets_salida.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "carpeta_reportes   = carpeta_datasets_salida / 'reportes'\n",
    "carpeta_reportes.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "carpeta_limpios    = carpeta_datasets_salida / 'limpios'\n",
    "carpeta_limpios.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "# Nombres esperados de archivos\n",
    "archivo_ventas     = 'ventas.csv'\n",
    "archivo_clientes   = 'clientes.csv'\n",
    "archivo_marketing  = 'marketing.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b65281a-0cd0-43a6-8a84-ed2692ae60b2",
   "metadata": {},
   "source": [
    "### 1.2 rutas y carga de los dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "052e6d76-d227-4749-af2c-f065eabf82f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargando datasets del curso...\n",
      "...Arhivos cargados con exito!!!\n"
     ]
    }
   ],
   "source": [
    "# --- Paso 3: Cargar archivos del curso ---\n",
    "print(\"Cargando datasets del curso...\")\n",
    "try:\n",
    "    ruta_ventas     = os.path.join(carpeta_datasets_entrada, archivo_ventas)\n",
    "    ruta_clientes   = os.path.join(carpeta_datasets_entrada, archivo_clientes)\n",
    "    ruta_marketing  = os.path.join(carpeta_datasets_entrada, archivo_marketing)\n",
    "    \n",
    "    df_ventas       = pd.read_csv(f\"{ruta_ventas}\")\n",
    "    df_clientes     = pd.read_csv(f\"{ruta_clientes}\")\n",
    "    df_marketing    = pd.read_csv(f\"{ruta_marketing}\")\n",
    "    dic_dfs = { \"df_ventas\"   : df_ventas,\n",
    "                \"df_clientes\" : df_clientes,\n",
    "                \"df_marketing\": df_marketing}\n",
    "    print (\"...Arhivos cargados con exito!!!\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Archivos no encontrados en:\", carpeta_datasets_entrada)\n",
    "    sys.exit(1)\n",
    "except pd.errors.EmptyDataError:\n",
    "    print(\"Archivo vacío detectado\")\n",
    "    sys.exit(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e91d4ff-4465-4ec3-b5e1-29f5d4cc0277",
   "metadata": {},
   "source": [
    "### 1.3 Estructura de parámetros "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "895c63d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Proceso principal para los 3 CSV ----------\n",
    "desviacion_margen     = 1.5\n",
    "desviacion_umbral     = 3.0\n",
    "cantidad_duplicados   = 0\n",
    "reportes_creados      = []\n",
    "ruta_excel            = carpeta_reportes / 'reporte_limpieza.xlsx'\n",
    "guardado_ok           = False\n",
    "mensajes              = []\n",
    "TOKENS_VALOR_FALTANTE = {'na', 'n/a', 'null', 'none', 'sin dato', 's/d', 'nd', '-', '--', '?', 'sin_dato', 'n/d'}\n",
    "\n",
    "\n",
    "reglas= {\n",
    "            \"df_marketing\" : {\n",
    "                                'producto':     {'string' : {'tipo': 'lower', 'normalizar_acentos': True}},\n",
    "                                'canal':        {'string' : {'tipo': 'upper', 'normalizar_acentos': True}},\n",
    "                                'costo':        {'numeric': {'as_int': False}},\n",
    "                                'fecha_inicio': {'date'   : {'dayfirst': True, 'formats': ['%d/%m/%Y', '%Y-%m-%d']}},\n",
    "                                'fecha_fin':    {'date'   : {'dayfirst': True, 'formats': ['%d/%m/%Y', '%Y-%m-%d']}}\n",
    "                                },\n",
    "            # id_venta, producto, precio, cantidad, fecha_venta, categoria\n",
    "            \"df_ventas\" : {\n",
    "                                'producto':     {'string' : {'tipo': 'lower', 'normalizar_acentos': True}},\n",
    "                                'precio':       {'numeric': {'as_int': False}},\n",
    "                                'cantidad':     {'numeric': {'as_int': False}},\n",
    "                                'fecha_venta':  {'date'   : {'dayfirst': True, 'formats': ['%d/%m/%Y', '%Y-%m-%d']}},\n",
    "                                'categoria':    {'string' : {'tipo': 'lower', 'normalizar_acentos': True}}\n",
    "                            },\n",
    "            # id_cliente, nombre, edad, ciudad, ingresos\n",
    "            \"df_clientes\" : {\n",
    "                                'nombre':       {'string'  : {'tipo': 'title', 'normalizar_acentos': True}},\n",
    "                                'edad':         {'numeric' : {'as_int': True}},\n",
    "                                'ciudad':       {'string'  : {'tipo': 'title', 'normalizar_acentos': True}},\n",
    "                                'ingresos':     {'numeric' : {'as_int': False}}\n",
    "                            }\n",
    "    }\n",
    "reglas_por_archivo = {\n",
    "    'ventas.csv':    reglas[\"df_ventas\"],\n",
    "    'clientes.csv':  reglas[\"df_clientes\"],\n",
    "    'marketing.csv': reglas[\"df_marketing\"]\n",
    "}\n",
    "\n",
    "#zip_path = carpeta_reportes.parent / 'reports_dataset_tpi_v2.zip'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a06a6528-ba7e-4f2c-889a-5d428f5a1cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar el DataFrame\n",
    "def ver(df :pd.DataFrame):\n",
    "    print(f\"\"\"\n",
    "        Descripción preliminar:\n",
    "        {df.describe()}\n",
    "        Dimensiones:{ df.ndim}\n",
    "        Forma:{ df.shape}    \n",
    "        Número de elementos:{ df.size}\n",
    "        Nombres de columnas:{ df.columns}\n",
    "        Nombres de filas:{ df.index}\n",
    "        Tipos de datos:\\n{ df.dtypes}\n",
    "        Primeras 10 filas:\\n{ df.head(10)}\n",
    "        Últimas 3 filas:\\n{ df.tail(3)}\n",
    "    {\"*\"*50}\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2dee86f8-86c5-45f5-98d7-ea56cd905395",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<string>, line 52)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mFile \u001b[39m\u001b[32m<string>:52\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mreturn dic_dfs[nombre_df]\u001b[39m\n                             ^\n\u001b[31mIndentationError\u001b[39m\u001b[31m:\u001b[39m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "def series_en_dataframes(nombre_df, df_cada):\n",
    "     for nombre_columna, serie in df_cada.items():\n",
    "            nombre_columna= nombre_columna.lower().replace(\" \",\"_\")\n",
    "            if nombre_columna.startswith(\"id_\"):\n",
    "                continue\n",
    "            regla =  next(iter(reglas[nombre_df][nombre_columna]))\n",
    "            print (f\"\"\"\n",
    "            {nombre_columna=}\n",
    "            {serie=}\n",
    "            {regla=}\n",
    "            \"\"\")\n",
    "            s = serie.copy()\n",
    "            if regla == \"numeric\":\n",
    "                try:\n",
    "                    s = s.astype(str).str.strip()\n",
    "                    s = s.str.replace('$', '')\n",
    "                except:\n",
    "                    pass\n",
    "                s = pd.to_numeric(s, errors=\"coerce\")\n",
    "                if reglas[nombre_df][nombre_columna][\"numeric\"][\"as_int\"] :\n",
    "                    s = s.replace('.', '').replace(',', '')\n",
    "                    if not s.isna().any():\n",
    "                        s = s.astype(int)\n",
    "            elif regla == \"string\":\n",
    "                s = s.astype(str).str.strip().replace(\"  \",\" \")\n",
    "                match  reglas[nombre_df][nombre_columna][regla][\"tipo\"] :\n",
    "                    case \"upper\":\n",
    "                        s = s.str.upper()\n",
    "                    case \"title\":\n",
    "                        s = s.str.title()\n",
    "                    case \"lower\":\n",
    "                        s = s.str.lower()\n",
    "                #texto_n = unicodedata.normalize(\"NFD\", entrada)\n",
    "                s= s.apply(  lambda x: ''.join( c for c in unicodedata.normalize('NFKD', str(x)) if not unicodedata.combining(c)  )  )\n",
    "                #''.join(c for c in unicodedata.normalize('NFKD', str(x))  if not unicodedata.combining(c))  for x in df[\"columna\"]\n",
    "                '''\n",
    "                \n",
    "                Modo\tSignificado\tQué hace\tCuándo usar\n",
    "                NFD\tNormalization Form Decomposition\tDescompone los caracteres Unicode en su forma básica y diacrítica. Ej: \"á\" → \"a\" + \" ́\"\tCuando solo querés separar acentos.\n",
    "                NFKD\tCompatibility Decomposition\tHace lo mismo más normaliza formas equivalentes \"compatibles\" (por ejemplo, “①” → “1”, “ﬂ” → “fl”)\tIdeal para limpieza más completa de texto.\n",
    "                '''\n",
    "            elif regla == \"date\":\n",
    "                # Convertimos la serie a datetime\n",
    "                s = pd.to_datetime(  s,  dayfirst=reglas[nombre_df][nombre_columna][regla][\"dayfirst\"],   errors=\"coerce\"  ) \n",
    "                #s = s.dt.strftime('%Y/%m/%d')\n",
    "            elif regla == \"fillna\":\n",
    "                s = s.fillna(0)\n",
    "            dic_dfs[nombre_df][nombre_columna] = s\n",
    "            print (f\"\"\"\n",
    "            {\"*\"*50}\n",
    "            {regla=}\"\"\")\n",
    "         \n",
    "    return dic_dfs[nombre_df]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a93a9ef1-7c47-4115-a9ba-f3ae616f83c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "            nombre_columna='producto'\n",
      "            serie=0            cuadro decorativo\n",
      "1              lampara de mesa\n",
      "2                     secadora\n",
      "3                     heladera\n",
      "4                     secadora\n",
      "                 ...          \n",
      "3030           horno electrico\n",
      "3031                    laptop\n",
      "3032                    laptop\n",
      "3033                smartphone\n",
      "3034    consola de videojuegos\n",
      "Name: producto, Length: 3035, dtype: object\n",
      "            regla='string'\n",
      "            \n",
      "\n",
      "            **************************************************\n",
      "            regla='string'\n",
      "\n",
      "            nombre_columna='precio'\n",
      "            serie=0        69.94\n",
      "1       105.10\n",
      "2        97.96\n",
      "3       114.35\n",
      "4       106.21\n",
      "         ...  \n",
      "3030    104.12\n",
      "3031     85.27\n",
      "3032    107.81\n",
      "3033     99.85\n",
      "3034     55.47\n",
      "Name: precio, Length: 3035, dtype: float64\n",
      "            regla='numeric'\n",
      "            \n",
      "\n",
      "            **************************************************\n",
      "            regla='numeric'\n",
      "\n",
      "            nombre_columna='cantidad'\n",
      "            serie=0       5.0\n",
      "1       5.0\n",
      "2       3.0\n",
      "3       8.0\n",
      "4       4.0\n",
      "       ... \n",
      "3030    9.0\n",
      "3031    9.0\n",
      "3032    4.0\n",
      "3033    7.0\n",
      "3034    6.0\n",
      "Name: cantidad, Length: 3035, dtype: float64\n",
      "            regla='numeric'\n",
      "            \n",
      "\n",
      "            **************************************************\n",
      "            regla='numeric'\n",
      "\n",
      "            nombre_columna='fecha_venta'\n",
      "            serie=0      2024-01-02\n",
      "1      2024-01-02\n",
      "2      2024-01-02\n",
      "3      2024-01-02\n",
      "4      2024-01-02\n",
      "          ...    \n",
      "3030   2024-12-30\n",
      "3031   2024-12-30\n",
      "3032   2024-12-30\n",
      "3033   2024-12-30\n",
      "3034   2024-12-30\n",
      "Name: fecha_venta, Length: 3035, dtype: datetime64[ns]\n",
      "            regla='date'\n",
      "            \n",
      "\n",
      "            **************************************************\n",
      "            regla='date'\n",
      "\n",
      "            nombre_columna='categoria'\n",
      "            serie=0              decoracion\n",
      "1              decoracion\n",
      "2       electrodomesticos\n",
      "3       electrodomesticos\n",
      "4       electrodomesticos\n",
      "              ...        \n",
      "3030    electrodomesticos\n",
      "3031          electronica\n",
      "3032          electronica\n",
      "3033          electronica\n",
      "3034          electronica\n",
      "Name: categoria, Length: 3035, dtype: object\n",
      "            regla='string'\n",
      "            \n",
      "\n",
      "            **************************************************\n",
      "            regla='string'\n",
      "    id_venta                producto  precio  cantidad fecha_venta  \\\n",
      "0        792       cuadro decorativo   69.94       5.0  2024-01-02   \n",
      "1        811         lampara de mesa  105.10       5.0  2024-01-02   \n",
      "2       1156                secadora   97.96       3.0  2024-01-02   \n",
      "3       1372                heladera  114.35       8.0  2024-01-02   \n",
      "4       1546                secadora  106.21       4.0  2024-01-02   \n",
      "5       1697         horno electrico   35.35       9.0  2024-01-02   \n",
      "6       1710        plancha de vapor   65.43       2.0  2024-01-02   \n",
      "7       2959               proyector   88.17       9.0  2024-01-02   \n",
      "8        318       rincon de plantas   79.86      11.0  2024-01-03   \n",
      "9        419              candelabro   66.11       8.0  2024-01-03   \n",
      "10      1374              aspiradora   95.90       5.0  2024-01-03   \n",
      "11      1571      freidora electrica  111.18       1.0  2024-01-03   \n",
      "12      1814              aspiradora   70.91       2.0  2024-01-03   \n",
      "13      2769               proyector   43.62      11.0  2024-01-03   \n",
      "14      2794                  tablet   67.97       9.0  2024-01-03   \n",
      "15      2824                  tablet   74.09       5.0  2024-01-03   \n",
      "16       446                cortinas   62.10       4.0  2024-01-04   \n",
      "17       630         adorno de pared   71.99       9.0  2024-01-04   \n",
      "18       794       jarron decorativo   96.97       7.0  2024-01-04   \n",
      "19       882       cuadro decorativo  101.92       9.0  2024-01-04   \n",
      "20       969              candelabro   90.70      12.0  2024-01-04   \n",
      "21      1445                lavadora   28.41      10.0  2024-01-04   \n",
      "22      1971      freidora electrica  122.25      11.0  2024-01-04   \n",
      "23      2209               proyector   32.15       1.0  2024-01-04   \n",
      "24       256                cortinas   86.82       8.0  2024-01-05   \n",
      "25       606                cortinas  106.66      11.0  2024-01-05   \n",
      "26       704       jarron decorativo   57.22       9.0  2024-01-05   \n",
      "27      1362                heladera  109.49      11.0  2024-01-05   \n",
      "28      2155             auriculares   84.80      10.0  2024-01-05   \n",
      "29      2947          camara digital  107.78       3.0  2024-01-05   \n",
      "30      1495                lavadora   38.99       6.0  2024-01-06   \n",
      "31      1572                cafetera   61.40       9.0  2024-01-06   \n",
      "32      2180  consola de videojuegos  102.57       9.0  2024-01-06   \n",
      "33      2487          camara digital   50.76       3.0  2024-01-06   \n",
      "34      2603              smartphone   87.05       5.0  2024-01-06   \n",
      "35      2885             auriculares  100.40       6.0  2024-01-06   \n",
      "36        17   elementos de ceramica  108.48      11.0  2024-01-07   \n",
      "37       183       espejo decorativo   82.76       8.0  2024-01-07   \n",
      "38       560         adorno de pared   57.62       6.0  2024-01-07   \n",
      "39       632       cuadro decorativo   30.49      12.0  2024-01-07   \n",
      "\n",
      "            categoria  \n",
      "0          decoracion  \n",
      "1          decoracion  \n",
      "2   electrodomesticos  \n",
      "3   electrodomesticos  \n",
      "4   electrodomesticos  \n",
      "5   electrodomesticos  \n",
      "6   electrodomesticos  \n",
      "7         electronica  \n",
      "8          decoracion  \n",
      "9          decoracion  \n",
      "10  electrodomesticos  \n",
      "11  electrodomesticos  \n",
      "12  electrodomesticos  \n",
      "13        electronica  \n",
      "14        electronica  \n",
      "15        electronica  \n",
      "16         decoracion  \n",
      "17         decoracion  \n",
      "18         decoracion  \n",
      "19         decoracion  \n",
      "20         decoracion  \n",
      "21  electrodomesticos  \n",
      "22  electrodomesticos  \n",
      "23        electronica  \n",
      "24         decoracion  \n",
      "25         decoracion  \n",
      "26         decoracion  \n",
      "27  electrodomesticos  \n",
      "28        electronica  \n",
      "29        electronica  \n",
      "30  electrodomesticos  \n",
      "31  electrodomesticos  \n",
      "32        electronica  \n",
      "33        electronica  \n",
      "34        electronica  \n",
      "35        electronica  \n",
      "36         decoracion  \n",
      "37         decoracion  \n",
      "38         decoracion  \n",
      "39         decoracion  \n",
      "\n",
      "        Descripción preliminar:\n",
      "                  id_venta       precio     cantidad                    fecha_venta\n",
      "count  3035.000000  3033.000000  3033.000000                           3035\n",
      "mean   1499.851400    75.289034     6.496538  2024-06-25 20:51:09.785832192\n",
      "min       1.000000    26.000000     1.000000            2024-01-02 00:00:00\n",
      "25%     748.500000    50.020000     3.000000            2024-03-28 00:00:00\n",
      "50%    1502.000000    75.270000     7.000000            2024-06-21 00:00:00\n",
      "75%    2249.500000   100.040000     9.000000            2024-09-25 00:00:00\n",
      "max    3000.000000   124.970000    12.000000            2024-12-30 00:00:00\n",
      "std     866.465379    28.734666     3.457250                            NaN\n",
      "        Dimensiones:2\n",
      "        Forma:(3035, 6)    \n",
      "        Número de elementos:18210\n",
      "        Nombres de columnas:Index(['id_venta', 'producto', 'precio', 'cantidad', 'fecha_venta',\n",
      "       'categoria'],\n",
      "      dtype='object')\n",
      "        Nombres de filas:RangeIndex(start=0, stop=3035, step=1)\n",
      "        Tipos de datos:\n",
      "id_venta                int64\n",
      "producto               object\n",
      "precio                float64\n",
      "cantidad              float64\n",
      "fecha_venta    datetime64[ns]\n",
      "categoria              object\n",
      "dtype: object\n",
      "        Primeras 10 filas:\n",
      "   id_venta           producto  precio  cantidad fecha_venta  \\\n",
      "0       792  cuadro decorativo   69.94       5.0  2024-01-02   \n",
      "1       811    lampara de mesa  105.10       5.0  2024-01-02   \n",
      "2      1156           secadora   97.96       3.0  2024-01-02   \n",
      "3      1372           heladera  114.35       8.0  2024-01-02   \n",
      "4      1546           secadora  106.21       4.0  2024-01-02   \n",
      "5      1697    horno electrico   35.35       9.0  2024-01-02   \n",
      "6      1710   plancha de vapor   65.43       2.0  2024-01-02   \n",
      "7      2959          proyector   88.17       9.0  2024-01-02   \n",
      "8       318  rincon de plantas   79.86      11.0  2024-01-03   \n",
      "9       419         candelabro   66.11       8.0  2024-01-03   \n",
      "\n",
      "           categoria  \n",
      "0         decoracion  \n",
      "1         decoracion  \n",
      "2  electrodomesticos  \n",
      "3  electrodomesticos  \n",
      "4  electrodomesticos  \n",
      "5  electrodomesticos  \n",
      "6  electrodomesticos  \n",
      "7        electronica  \n",
      "8         decoracion  \n",
      "9         decoracion  \n",
      "        Últimas 3 filas:\n",
      "      id_venta                producto  precio  cantidad fecha_venta  \\\n",
      "3032      2696                  laptop  107.81       4.0  2024-12-30   \n",
      "3033      2913              smartphone   99.85       7.0  2024-12-30   \n",
      "3034      2930  consola de videojuegos   55.47       6.0  2024-12-30   \n",
      "\n",
      "        categoria  \n",
      "3032  electronica  \n",
      "3033  electronica  \n",
      "3034  electronica  \n",
      "    **************************************************\n",
      "    \n",
      "\n",
      "            nombre_columna='nombre'\n",
      "            serie=0          Aloysia Screase\n",
      "1      Kristina Scaplehorn\n",
      "2           Filip Castagne\n",
      "3              Liuka Luard\n",
      "4            Dore Cockshtt\n",
      "              ...         \n",
      "573          Minor Josephy\n",
      "574        Marylynne Piner\n",
      "575        Cari Marzellano\n",
      "576         Magdalene Pegg\n",
      "577          Lorry Santori\n",
      "Name: nombre, Length: 578, dtype: object\n",
      "            regla='string'\n",
      "            \n",
      "\n",
      "            **************************************************\n",
      "            regla='string'\n",
      "\n",
      "            nombre_columna='edad'\n",
      "            serie=0      44\n",
      "1      25\n",
      "2      50\n",
      "3      39\n",
      "4      28\n",
      "       ..\n",
      "573    28\n",
      "574    47\n",
      "575    38\n",
      "576    34\n",
      "577    47\n",
      "Name: edad, Length: 578, dtype: int64\n",
      "            regla='numeric'\n",
      "            \n",
      "\n",
      "            **************************************************\n",
      "            regla='numeric'\n",
      "\n",
      "            nombre_columna='ciudad'\n",
      "            serie=0      Mar Del Plata\n",
      "1            Posadas\n",
      "2        Resistencia\n",
      "3       Bahia Blanca\n",
      "4            Rosario\n",
      "           ...      \n",
      "573         Santa Fe\n",
      "574          Rosario\n",
      "575    Mar Del Plata\n",
      "576          Cordoba\n",
      "577       Corrientes\n",
      "Name: ciudad, Length: 578, dtype: object\n",
      "            regla='string'\n",
      "            \n",
      "\n",
      "            **************************************************\n",
      "            regla='string'\n",
      "\n",
      "            nombre_columna='ingresos'\n",
      "            serie=0      42294.68\n",
      "1      24735.04\n",
      "2      35744.85\n",
      "3      27647.96\n",
      "4      28245.65\n",
      "         ...   \n",
      "573    47018.78\n",
      "574    32826.37\n",
      "575    53114.05\n",
      "576    49849.42\n",
      "577    42000.81\n",
      "Name: ingresos, Length: 578, dtype: float64\n",
      "            regla='numeric'\n",
      "            \n",
      "\n",
      "            **************************************************\n",
      "            regla='numeric'\n",
      "    id_cliente               nombre  edad                 ciudad  ingresos\n",
      "0            1      Aloysia Screase    44          Mar Del Plata  42294.68\n",
      "1            2  Kristina Scaplehorn    25                Posadas  24735.04\n",
      "2            3       Filip Castagne    50            Resistencia  35744.85\n",
      "3            4          Liuka Luard    39           Bahia Blanca  27647.96\n",
      "4            5        Dore Cockshtt    28                Rosario  28245.65\n",
      "5            6        Patrick Earle    34  San Miguel De Tucuman  62763.31\n",
      "6            7           Etan Deeth    35            Resistencia  37489.71\n",
      "7            8       Booth Bielfelt    40                Cordoba  35255.94\n",
      "8            9         Shirl Labone    29                Rosario  27592.08\n",
      "9           10      Andy Mendenhall    52                Rosario  37153.94\n",
      "10          11          Hans Strong    69            Resistencia  35596.27\n",
      "11          12       Griffith Lowey    27             Corrientes  41862.78\n",
      "12          13     Hadria Hinkensen    33  San Miguel De Tucuman  56171.38\n",
      "13          14         Ilyssa Arden    52            Resistencia  14690.68\n",
      "14          15        Denni Dhillon    27            Resistencia  42168.75\n",
      "15          16       Garrott Bogart    32                Rosario  16480.55\n",
      "16          17        Minor Josephy    28               Santa Fe  47018.78\n",
      "17          18      Marylynne Piner    47                Rosario  32826.37\n",
      "18          19      Cari Marzellano    38          Mar Del Plata  53114.05\n",
      "19          20       Magdalene Pegg    34                Cordoba  49849.42\n",
      "20          21        Lorry Santori    47             Corrientes  42000.81\n",
      "21          22    Gertrude La Wille    44                  Merlo   9085.92\n",
      "22          23     Audrye Fairbeard    40               Santa Fe  46734.23\n",
      "23          24    Merle Musslewhite    33                  Salta  39770.63\n",
      "24          25          Lola Hansie    44               Santa Fe  25917.58\n",
      "25          26       Darelle Errett    47                  Salta  27928.46\n",
      "26          27     Marianna Lossman    36                Cordoba  36720.12\n",
      "27          28      Charmaine Vanin    37               Santa Fe  33220.06\n",
      "28          29         Paul Perrott    34          Mar Del Plata  41813.93\n",
      "29          30         Tedi O'Shiel    32           Bahia Blanca  44137.90\n",
      "30          31         Merv Brislan    35          Mar Del Plata  21063.82\n",
      "31          32     Winnifred Edland    35  San Miguel De Tucuman  54193.68\n",
      "32          33         Bevin Keenor    28            Resistencia  33986.78\n",
      "33          34       Tomaso Murname    35          Mar Del Plata  28615.26\n",
      "34          35        Carmelia Bunn    52                Rosario  27136.93\n",
      "35          36        Karie Premble    44                Posadas  52128.76\n",
      "36          37      Maurice Pelling    26             Corrientes  25838.89\n",
      "37          38   Clotilda Abilowitz    57                Posadas  42757.46\n",
      "38          39         Ginger Askaw    36                  Salta  36779.95\n",
      "39          40        Sallie Stubbe    37           Bahia Blanca  28333.21\n",
      "\n",
      "        Descripción preliminar:\n",
      "               id_cliente        edad      ingresos\n",
      "count  578.000000  578.000000    578.000000\n",
      "mean   289.500000   37.968858  34755.977266\n",
      "std    166.998503   10.253244  12989.576812\n",
      "min      1.000000   20.000000    170.290000\n",
      "25%    145.250000   30.000000  26119.060000\n",
      "50%    289.500000   37.000000  35102.285000\n",
      "75%    433.750000   43.000000  42600.435000\n",
      "max    578.000000   81.000000  88053.010000\n",
      "        Dimensiones:2\n",
      "        Forma:(578, 5)    \n",
      "        Número de elementos:2890\n",
      "        Nombres de columnas:Index(['id_cliente', 'nombre', 'edad', 'ciudad', 'ingresos'], dtype='object')\n",
      "        Nombres de filas:RangeIndex(start=0, stop=578, step=1)\n",
      "        Tipos de datos:\n",
      "id_cliente      int64\n",
      "nombre         object\n",
      "edad            int64\n",
      "ciudad         object\n",
      "ingresos      float64\n",
      "dtype: object\n",
      "        Primeras 10 filas:\n",
      "   id_cliente               nombre  edad                 ciudad  ingresos\n",
      "0           1      Aloysia Screase    44          Mar Del Plata  42294.68\n",
      "1           2  Kristina Scaplehorn    25                Posadas  24735.04\n",
      "2           3       Filip Castagne    50            Resistencia  35744.85\n",
      "3           4          Liuka Luard    39           Bahia Blanca  27647.96\n",
      "4           5        Dore Cockshtt    28                Rosario  28245.65\n",
      "5           6        Patrick Earle    34  San Miguel De Tucuman  62763.31\n",
      "6           7           Etan Deeth    35            Resistencia  37489.71\n",
      "7           8       Booth Bielfelt    40                Cordoba  35255.94\n",
      "8           9         Shirl Labone    29                Rosario  27592.08\n",
      "9          10      Andy Mendenhall    52                Rosario  37153.94\n",
      "        Últimas 3 filas:\n",
      "     id_cliente           nombre  edad         ciudad  ingresos\n",
      "575         576  Cari Marzellano    38  Mar Del Plata  53114.05\n",
      "576         577   Magdalene Pegg    34        Cordoba  49849.42\n",
      "577         578    Lorry Santori    47     Corrientes  42000.81\n",
      "    **************************************************\n",
      "    \n",
      "\n",
      "            nombre_columna='producto'\n",
      "            serie=0        adorno de pared\n",
      "1                 tablet\n",
      "2        lampara de mesa\n",
      "3             smartphone\n",
      "4               alfombra\n",
      "             ...        \n",
      "85            aspiradora\n",
      "86             televisor\n",
      "87     rincon de plantas\n",
      "88              secadora\n",
      "89    freidora electrica\n",
      "Name: producto, Length: 90, dtype: object\n",
      "            regla='string'\n",
      "            \n",
      "\n",
      "            **************************************************\n",
      "            regla='string'\n",
      "\n",
      "            nombre_columna='canal'\n",
      "            serie=0        TV\n",
      "1      RRSS\n",
      "2     EMAIL\n",
      "3      RRSS\n",
      "4     EMAIL\n",
      "      ...  \n",
      "85       TV\n",
      "86       TV\n",
      "87       TV\n",
      "88    EMAIL\n",
      "89     RRSS\n",
      "Name: canal, Length: 90, dtype: object\n",
      "            regla='string'\n",
      "            \n",
      "\n",
      "            **************************************************\n",
      "            regla='string'\n",
      "\n",
      "            nombre_columna='costo'\n",
      "            serie=0     4.81\n",
      "1     3.40\n",
      "2     5.54\n",
      "3     6.37\n",
      "4     4.25\n",
      "      ... \n",
      "85    3.06\n",
      "86    4.98\n",
      "87    5.81\n",
      "88    3.80\n",
      "89    5.27\n",
      "Name: costo, Length: 90, dtype: float64\n",
      "            regla='numeric'\n",
      "            \n",
      "\n",
      "            **************************************************\n",
      "            regla='numeric'\n",
      "\n",
      "            nombre_columna='fecha_inicio'\n",
      "            serie=0    2024-03-20\n",
      "1    2024-03-26\n",
      "2    2024-03-28\n",
      "3    2024-03-29\n",
      "4    2024-03-31\n",
      "        ...    \n",
      "85   2024-12-13\n",
      "86   2024-12-13\n",
      "87   2024-12-17\n",
      "88   2024-12-20\n",
      "89   2024-12-29\n",
      "Name: fecha_inicio, Length: 90, dtype: datetime64[ns]\n",
      "            regla='date'\n",
      "            \n",
      "\n",
      "            **************************************************\n",
      "            regla='date'\n",
      "\n",
      "            nombre_columna='fecha_fin'\n",
      "            serie=0    2024-05-03\n",
      "1    2024-05-13\n",
      "2    2024-04-20\n",
      "3    2024-05-16\n",
      "4    2024-05-05\n",
      "        ...    \n",
      "85   2024-12-29\n",
      "86   2025-02-08\n",
      "87   2025-02-14\n",
      "88   2025-01-07\n",
      "89   2025-01-21\n",
      "Name: fecha_fin, Length: 90, dtype: datetime64[ns]\n",
      "            regla='date'\n",
      "            \n",
      "\n",
      "            **************************************************\n",
      "            regla='date'\n",
      "    id_campanha                producto  canal  costo fecha_inicio  fecha_fin\n",
      "0            74         adorno de pared     TV   4.81   2024-03-20 2024-05-03\n",
      "1            12                  tablet   RRSS   3.40   2024-03-26 2024-05-13\n",
      "2            32         lampara de mesa  EMAIL   5.54   2024-03-28 2024-04-20\n",
      "3            21              smartphone   RRSS   6.37   2024-03-29 2024-05-16\n",
      "4            58                alfombra  EMAIL   4.25   2024-03-31 2024-05-05\n",
      "5            85              smartwatch     TV   5.07   2024-04-01 2024-05-05\n",
      "6            36        plancha de vapor  EMAIL   5.41   2024-04-02 2024-06-01\n",
      "7            57                batidora  EMAIL   4.48   2024-04-10 2024-06-08\n",
      "8            44         adorno de pared  EMAIL   5.08   2024-04-13 2024-05-10\n",
      "9            84     parlantes bluetooth     TV   4.42   2024-04-17 2024-05-05\n",
      "10            1       cuadro decorativo   RRSS   5.27   2024-04-27 2024-06-04\n",
      "11           43                cortinas  EMAIL   5.67   2024-05-02 2024-06-17\n",
      "12           50  consola de videojuegos  EMAIL   4.97   2024-05-03 2024-05-28\n",
      "13           34                heladera  EMAIL   4.20   2024-05-06 2024-07-05\n",
      "14           15       jarron decorativo   RRSS   4.65   2024-05-09 2024-06-13\n",
      "15           46                lavadora  EMAIL   3.63   2024-05-12 2024-05-29\n",
      "16           29               televisor   RRSS   3.96   2024-05-17 2024-06-28\n",
      "17           67               proyector     TV   3.68   2024-05-22 2024-07-12\n",
      "18           76                lavadora     TV   4.66   2024-05-26 2024-07-02\n",
      "19           51              smartphone  EMAIL   4.65   2024-05-28 2024-06-15\n",
      "20           69              candelabro     TV   3.25   2024-05-29 2024-06-30\n",
      "21            2         lampara de mesa   RRSS   5.88   2024-05-30 2024-06-29\n",
      "22            4                heladera   RRSS   4.53   2024-05-31 2024-07-15\n",
      "23           83       espejo decorativo     TV   5.24   2024-05-31 2024-07-08\n",
      "24           47             auriculares  EMAIL   4.19   2024-06-02 2024-07-22\n",
      "25           45       jarron decorativo  EMAIL   4.52   2024-06-05 2024-07-31\n",
      "26           71      freidora electrica     TV   4.37   2024-06-05 2024-07-24\n",
      "27           38       rincon de plantas  EMAIL   5.76   2024-06-14 2024-07-15\n",
      "28           49                cafetera  EMAIL   5.20   2024-06-20 2024-07-22\n",
      "29           40              aspiradora  EMAIL   6.24   2024-06-24 2024-08-12\n",
      "30           22   elementos de ceramica   RRSS   5.44   2024-06-26 2024-07-15\n",
      "31           37               proyector  EMAIL   3.22   2024-07-06 2024-07-26\n",
      "32           72                  tablet     TV   4.90   2024-07-08 2024-09-03\n",
      "33           64                heladera     TV   4.38   2024-07-10 2024-08-09\n",
      "34           42                  tablet  EMAIL   4.42   2024-07-14 2024-09-03\n",
      "35           17             auriculares   RRSS   6.06   2024-07-15 2024-08-15\n",
      "36           20  consola de videojuegos   RRSS   3.16   2024-07-15 2024-08-03\n",
      "37           18          camara digital   RRSS   5.46   2024-07-16 2024-09-13\n",
      "38           39              candelabro  EMAIL   6.08   2024-07-17 2024-08-18\n",
      "39           53       espejo decorativo  EMAIL   4.90   2024-07-17 2024-08-01\n",
      "\n",
      "        Descripción preliminar:\n",
      "               id_campanha      costo         fecha_inicio            fecha_fin\n",
      "count    90.000000  90.000000                   90                   90\n",
      "mean     45.500000   4.928667  2024-08-03 16:48:00  2024-09-10 09:04:00\n",
      "min       1.000000   2.950000  2024-03-20 00:00:00  2024-04-20 00:00:00\n",
      "25%      23.250000   4.372500  2024-05-31 00:00:00  2024-07-12 18:00:00\n",
      "50%      45.500000   4.900000  2024-08-02 12:00:00  2024-09-12 12:00:00\n",
      "75%      67.750000   5.562500  2024-10-02 12:00:00  2024-11-11 18:00:00\n",
      "max      90.000000   7.390000  2024-12-29 00:00:00  2025-02-14 00:00:00\n",
      "std      26.124701   0.947750                  NaN                  NaN\n",
      "        Dimensiones:2\n",
      "        Forma:(90, 6)    \n",
      "        Número de elementos:540\n",
      "        Nombres de columnas:Index(['id_campanha', 'producto', 'canal', 'costo', 'fecha_inicio',\n",
      "       'fecha_fin'],\n",
      "      dtype='object')\n",
      "        Nombres de filas:RangeIndex(start=0, stop=90, step=1)\n",
      "        Tipos de datos:\n",
      "id_campanha              int64\n",
      "producto                object\n",
      "canal                   object\n",
      "costo                  float64\n",
      "fecha_inicio    datetime64[ns]\n",
      "fecha_fin       datetime64[ns]\n",
      "dtype: object\n",
      "        Primeras 10 filas:\n",
      "   id_campanha             producto  canal  costo fecha_inicio  fecha_fin\n",
      "0           74      adorno de pared     TV   4.81   2024-03-20 2024-05-03\n",
      "1           12               tablet   RRSS   3.40   2024-03-26 2024-05-13\n",
      "2           32      lampara de mesa  EMAIL   5.54   2024-03-28 2024-04-20\n",
      "3           21           smartphone   RRSS   6.37   2024-03-29 2024-05-16\n",
      "4           58             alfombra  EMAIL   4.25   2024-03-31 2024-05-05\n",
      "5           85           smartwatch     TV   5.07   2024-04-01 2024-05-05\n",
      "6           36     plancha de vapor  EMAIL   5.41   2024-04-02 2024-06-01\n",
      "7           57             batidora  EMAIL   4.48   2024-04-10 2024-06-08\n",
      "8           44      adorno de pared  EMAIL   5.08   2024-04-13 2024-05-10\n",
      "9           84  parlantes bluetooth     TV   4.42   2024-04-17 2024-05-05\n",
      "        Últimas 3 filas:\n",
      "    id_campanha            producto  canal  costo fecha_inicio  fecha_fin\n",
      "87           68   rincon de plantas     TV   5.81   2024-12-17 2025-02-14\n",
      "88           33            secadora  EMAIL   3.80   2024-12-20 2025-01-07\n",
      "89           11  freidora electrica   RRSS   5.27   2024-12-29 2025-01-21\n",
      "    **************************************************\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "def dataframes_en_diccionario():\n",
    "    \"\"\"\n",
    "    Limpia el DataFrame aplicando reglas_por_columna = {\"col\": (\"regla\", parametros)...}\n",
    "    Las reglas se asignan automáticamente según el tipo o formato:\n",
    "      - Columnas numéricas o con símbolos ($, %, dígitos) → 'numeric'\n",
    "      - Columnas que parecen fechas → 'date'\n",
    "      - Otras columnas → 'string'\n",
    "    \"\"\"\n",
    "    for nombre_df, df_cada in dic_dfs.items():\n",
    "        dic_dfs[nombre_df] = series_en_dataframes(nombre_df, df_cada)\n",
    "    print (dic_dfs[nombre_df].head(40))\n",
    "    ver( dic_dfs[nombre_df])\n",
    "limpiar_dataframes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc3a7982-b970-401c-94bf-ee301fd62c83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "            nombre_columna='producto'\n",
      "            serie=0            Cuadro decorativo\n",
      "1              Lámpara de mesa\n",
      "2                     Secadora\n",
      "3                     Heladera\n",
      "4                     Secadora\n",
      "                 ...          \n",
      "3030           Horno eléctrico\n",
      "3031                    Laptop\n",
      "3032                    Laptop\n",
      "3033                Smartphone\n",
      "3034    Consola de videojuegos\n",
      "Name: producto, Length: 3035, dtype: object\n",
      "            regla='string'\n",
      "            \n",
      "\n",
      "            **************************************************\n",
      "            regla='string'\n",
      "\n",
      "            nombre_columna='precio'\n",
      "            serie=0        $69.94\n",
      "1       $105.10\n",
      "2        $97.96\n",
      "3       $114.35\n",
      "4       $106.21\n",
      "         ...   \n",
      "3030    $104.12\n",
      "3031     $85.27\n",
      "3032    $107.81\n",
      "3033     $99.85\n",
      "3034     $55.47\n",
      "Name: precio, Length: 3035, dtype: object\n",
      "            regla='numeric'\n",
      "            \n",
      "\n",
      "            **************************************************\n",
      "            regla='numeric'\n",
      "\n",
      "            nombre_columna='cantidad'\n",
      "            serie=0       5.0\n",
      "1       5.0\n",
      "2       3.0\n",
      "3       8.0\n",
      "4       4.0\n",
      "       ... \n",
      "3030    9.0\n",
      "3031    9.0\n",
      "3032    4.0\n",
      "3033    7.0\n",
      "3034    6.0\n",
      "Name: cantidad, Length: 3035, dtype: float64\n",
      "            regla='numeric'\n",
      "            \n",
      "\n",
      "            **************************************************\n",
      "            regla='numeric'\n",
      "\n",
      "            nombre_columna='fecha_venta'\n",
      "            serie=0       02/01/2024\n",
      "1       02/01/2024\n",
      "2       02/01/2024\n",
      "3       02/01/2024\n",
      "4       02/01/2024\n",
      "           ...    \n",
      "3030    30/12/2024\n",
      "3031    30/12/2024\n",
      "3032    30/12/2024\n",
      "3033    30/12/2024\n",
      "3034    30/12/2024\n",
      "Name: fecha_venta, Length: 3035, dtype: object\n",
      "            regla='date'\n",
      "            \n",
      "\n",
      "            **************************************************\n",
      "            regla='date'\n",
      "\n",
      "            nombre_columna='categoria'\n",
      "            serie=0              Decoración\n",
      "1              Decoración\n",
      "2       Electrodomésticos\n",
      "3       Electrodomésticos\n",
      "4       Electrodomésticos\n",
      "              ...        \n",
      "3030    Electrodomésticos\n",
      "3031          Electrónica\n",
      "3032          Electrónica\n",
      "3033          Electrónica\n",
      "3034          Electrónica\n",
      "Name: categoria, Length: 3035, dtype: object\n",
      "            regla='string'\n",
      "            \n",
      "\n",
      "            **************************************************\n",
      "            regla='string'\n",
      "    id_venta                producto  precio  cantidad fecha_venta  \\\n",
      "0        792       cuadro decorativo   69.94       5.0  2024-01-02   \n",
      "1        811         lampara de mesa  105.10       5.0  2024-01-02   \n",
      "2       1156                secadora   97.96       3.0  2024-01-02   \n",
      "3       1372                heladera  114.35       8.0  2024-01-02   \n",
      "4       1546                secadora  106.21       4.0  2024-01-02   \n",
      "5       1697         horno electrico   35.35       9.0  2024-01-02   \n",
      "6       1710        plancha de vapor   65.43       2.0  2024-01-02   \n",
      "7       2959               proyector   88.17       9.0  2024-01-02   \n",
      "8        318       rincon de plantas   79.86      11.0  2024-01-03   \n",
      "9        419              candelabro   66.11       8.0  2024-01-03   \n",
      "10      1374              aspiradora   95.90       5.0  2024-01-03   \n",
      "11      1571      freidora electrica  111.18       1.0  2024-01-03   \n",
      "12      1814              aspiradora   70.91       2.0  2024-01-03   \n",
      "13      2769               proyector   43.62      11.0  2024-01-03   \n",
      "14      2794                  tablet   67.97       9.0  2024-01-03   \n",
      "15      2824                  tablet   74.09       5.0  2024-01-03   \n",
      "16       446                cortinas   62.10       4.0  2024-01-04   \n",
      "17       630         adorno de pared   71.99       9.0  2024-01-04   \n",
      "18       794       jarron decorativo   96.97       7.0  2024-01-04   \n",
      "19       882       cuadro decorativo  101.92       9.0  2024-01-04   \n",
      "20       969              candelabro   90.70      12.0  2024-01-04   \n",
      "21      1445                lavadora   28.41      10.0  2024-01-04   \n",
      "22      1971      freidora electrica  122.25      11.0  2024-01-04   \n",
      "23      2209               proyector   32.15       1.0  2024-01-04   \n",
      "24       256                cortinas   86.82       8.0  2024-01-05   \n",
      "25       606                cortinas  106.66      11.0  2024-01-05   \n",
      "26       704       jarron decorativo   57.22       9.0  2024-01-05   \n",
      "27      1362                heladera  109.49      11.0  2024-01-05   \n",
      "28      2155             auriculares   84.80      10.0  2024-01-05   \n",
      "29      2947          camara digital  107.78       3.0  2024-01-05   \n",
      "30      1495                lavadora   38.99       6.0  2024-01-06   \n",
      "31      1572                cafetera   61.40       9.0  2024-01-06   \n",
      "32      2180  consola de videojuegos  102.57       9.0  2024-01-06   \n",
      "33      2487          camara digital   50.76       3.0  2024-01-06   \n",
      "34      2603              smartphone   87.05       5.0  2024-01-06   \n",
      "35      2885             auriculares  100.40       6.0  2024-01-06   \n",
      "36        17   elementos de ceramica  108.48      11.0  2024-01-07   \n",
      "37       183       espejo decorativo   82.76       8.0  2024-01-07   \n",
      "38       560         adorno de pared   57.62       6.0  2024-01-07   \n",
      "39       632       cuadro decorativo   30.49      12.0  2024-01-07   \n",
      "\n",
      "            categoria  \n",
      "0          decoracion  \n",
      "1          decoracion  \n",
      "2   electrodomesticos  \n",
      "3   electrodomesticos  \n",
      "4   electrodomesticos  \n",
      "5   electrodomesticos  \n",
      "6   electrodomesticos  \n",
      "7         electronica  \n",
      "8          decoracion  \n",
      "9          decoracion  \n",
      "10  electrodomesticos  \n",
      "11  electrodomesticos  \n",
      "12  electrodomesticos  \n",
      "13        electronica  \n",
      "14        electronica  \n",
      "15        electronica  \n",
      "16         decoracion  \n",
      "17         decoracion  \n",
      "18         decoracion  \n",
      "19         decoracion  \n",
      "20         decoracion  \n",
      "21  electrodomesticos  \n",
      "22  electrodomesticos  \n",
      "23        electronica  \n",
      "24         decoracion  \n",
      "25         decoracion  \n",
      "26         decoracion  \n",
      "27  electrodomesticos  \n",
      "28        electronica  \n",
      "29        electronica  \n",
      "30  electrodomesticos  \n",
      "31  electrodomesticos  \n",
      "32        electronica  \n",
      "33        electronica  \n",
      "34        electronica  \n",
      "35        electronica  \n",
      "36         decoracion  \n",
      "37         decoracion  \n",
      "38         decoracion  \n",
      "39         decoracion  \n",
      "\n",
      "        Descripción preliminar:\n",
      "                  id_venta       precio     cantidad                    fecha_venta\n",
      "count  3035.000000  3033.000000  3033.000000                           3035\n",
      "mean   1499.851400    75.289034     6.496538  2024-06-25 20:51:09.785832192\n",
      "min       1.000000    26.000000     1.000000            2024-01-02 00:00:00\n",
      "25%     748.500000    50.020000     3.000000            2024-03-28 00:00:00\n",
      "50%    1502.000000    75.270000     7.000000            2024-06-21 00:00:00\n",
      "75%    2249.500000   100.040000     9.000000            2024-09-25 00:00:00\n",
      "max    3000.000000   124.970000    12.000000            2024-12-30 00:00:00\n",
      "std     866.465379    28.734666     3.457250                            NaN\n",
      "        Dimensiones:2\n",
      "        Forma:(3035, 6)    \n",
      "        Número de elementos:18210\n",
      "        Nombres de columnas:Index(['id_venta', 'producto', 'precio', 'cantidad', 'fecha_venta',\n",
      "       'categoria'],\n",
      "      dtype='object')\n",
      "        Nombres de filas:RangeIndex(start=0, stop=3035, step=1)\n",
      "        Tipos de datos:\n",
      "id_venta                int64\n",
      "producto               object\n",
      "precio                float64\n",
      "cantidad              float64\n",
      "fecha_venta    datetime64[ns]\n",
      "categoria              object\n",
      "dtype: object\n",
      "        Primeras 10 filas:\n",
      "   id_venta           producto  precio  cantidad fecha_venta  \\\n",
      "0       792  cuadro decorativo   69.94       5.0  2024-01-02   \n",
      "1       811    lampara de mesa  105.10       5.0  2024-01-02   \n",
      "2      1156           secadora   97.96       3.0  2024-01-02   \n",
      "3      1372           heladera  114.35       8.0  2024-01-02   \n",
      "4      1546           secadora  106.21       4.0  2024-01-02   \n",
      "5      1697    horno electrico   35.35       9.0  2024-01-02   \n",
      "6      1710   plancha de vapor   65.43       2.0  2024-01-02   \n",
      "7      2959          proyector   88.17       9.0  2024-01-02   \n",
      "8       318  rincon de plantas   79.86      11.0  2024-01-03   \n",
      "9       419         candelabro   66.11       8.0  2024-01-03   \n",
      "\n",
      "           categoria  \n",
      "0         decoracion  \n",
      "1         decoracion  \n",
      "2  electrodomesticos  \n",
      "3  electrodomesticos  \n",
      "4  electrodomesticos  \n",
      "5  electrodomesticos  \n",
      "6  electrodomesticos  \n",
      "7        electronica  \n",
      "8         decoracion  \n",
      "9         decoracion  \n",
      "        Últimas 3 filas:\n",
      "      id_venta                producto  precio  cantidad fecha_venta  \\\n",
      "3032      2696                  laptop  107.81       4.0  2024-12-30   \n",
      "3033      2913              smartphone   99.85       7.0  2024-12-30   \n",
      "3034      2930  consola de videojuegos   55.47       6.0  2024-12-30   \n",
      "\n",
      "        categoria  \n",
      "3032  electronica  \n",
      "3033  electronica  \n",
      "3034  electronica  \n",
      "    **************************************************\n",
      "    \n",
      "\n",
      "            nombre_columna='nombre'\n",
      "            serie=0          Aloysia Screase\n",
      "1      Kristina Scaplehorn\n",
      "2           Filip Castagne\n",
      "3              Liuka Luard\n",
      "4            Dore Cockshtt\n",
      "              ...         \n",
      "573          Minor Josephy\n",
      "574        Marylynne Piner\n",
      "575        Cari Marzellano\n",
      "576         Magdalene Pegg\n",
      "577          Lorry Santori\n",
      "Name: nombre, Length: 578, dtype: object\n",
      "            regla='string'\n",
      "            \n",
      "\n",
      "            **************************************************\n",
      "            regla='string'\n",
      "\n",
      "            nombre_columna='edad'\n",
      "            serie=0      44\n",
      "1      25\n",
      "2      50\n",
      "3      39\n",
      "4      28\n",
      "       ..\n",
      "573    28\n",
      "574    47\n",
      "575    38\n",
      "576    34\n",
      "577    47\n",
      "Name: edad, Length: 578, dtype: int64\n",
      "            regla='numeric'\n",
      "            \n",
      "\n",
      "            **************************************************\n",
      "            regla='numeric'\n",
      "\n",
      "            nombre_columna='ciudad'\n",
      "            serie=0      Mar del Plata\n",
      "1            Posadas\n",
      "2        Resistencia\n",
      "3       Bahía Blanca\n",
      "4            Rosario\n",
      "           ...      \n",
      "573         Santa Fe\n",
      "574          Rosario\n",
      "575    Mar del Plata\n",
      "576          Córdoba\n",
      "577       Corrientes\n",
      "Name: ciudad, Length: 578, dtype: object\n",
      "            regla='string'\n",
      "            \n",
      "\n",
      "            **************************************************\n",
      "            regla='string'\n",
      "\n",
      "            nombre_columna='ingresos'\n",
      "            serie=0      42294.68\n",
      "1      24735.04\n",
      "2      35744.85\n",
      "3      27647.96\n",
      "4      28245.65\n",
      "         ...   \n",
      "573    47018.78\n",
      "574    32826.37\n",
      "575    53114.05\n",
      "576    49849.42\n",
      "577    42000.81\n",
      "Name: ingresos, Length: 578, dtype: float64\n",
      "            regla='numeric'\n",
      "            \n",
      "\n",
      "            **************************************************\n",
      "            regla='numeric'\n",
      "    id_cliente               nombre  edad                 ciudad  ingresos\n",
      "0            1      Aloysia Screase    44          Mar Del Plata  42294.68\n",
      "1            2  Kristina Scaplehorn    25                Posadas  24735.04\n",
      "2            3       Filip Castagne    50            Resistencia  35744.85\n",
      "3            4          Liuka Luard    39           Bahia Blanca  27647.96\n",
      "4            5        Dore Cockshtt    28                Rosario  28245.65\n",
      "5            6        Patrick Earle    34  San Miguel De Tucuman  62763.31\n",
      "6            7           Etan Deeth    35            Resistencia  37489.71\n",
      "7            8       Booth Bielfelt    40                Cordoba  35255.94\n",
      "8            9         Shirl Labone    29                Rosario  27592.08\n",
      "9           10      Andy Mendenhall    52                Rosario  37153.94\n",
      "10          11          Hans Strong    69            Resistencia  35596.27\n",
      "11          12       Griffith Lowey    27             Corrientes  41862.78\n",
      "12          13     Hadria Hinkensen    33  San Miguel De Tucuman  56171.38\n",
      "13          14         Ilyssa Arden    52            Resistencia  14690.68\n",
      "14          15        Denni Dhillon    27            Resistencia  42168.75\n",
      "15          16       Garrott Bogart    32                Rosario  16480.55\n",
      "16          17        Minor Josephy    28               Santa Fe  47018.78\n",
      "17          18      Marylynne Piner    47                Rosario  32826.37\n",
      "18          19      Cari Marzellano    38          Mar Del Plata  53114.05\n",
      "19          20       Magdalene Pegg    34                Cordoba  49849.42\n",
      "20          21        Lorry Santori    47             Corrientes  42000.81\n",
      "21          22    Gertrude La Wille    44                  Merlo   9085.92\n",
      "22          23     Audrye Fairbeard    40               Santa Fe  46734.23\n",
      "23          24    Merle Musslewhite    33                  Salta  39770.63\n",
      "24          25          Lola Hansie    44               Santa Fe  25917.58\n",
      "25          26       Darelle Errett    47                  Salta  27928.46\n",
      "26          27     Marianna Lossman    36                Cordoba  36720.12\n",
      "27          28      Charmaine Vanin    37               Santa Fe  33220.06\n",
      "28          29         Paul Perrott    34          Mar Del Plata  41813.93\n",
      "29          30         Tedi O'Shiel    32           Bahia Blanca  44137.90\n",
      "30          31         Merv Brislan    35          Mar Del Plata  21063.82\n",
      "31          32     Winnifred Edland    35  San Miguel De Tucuman  54193.68\n",
      "32          33         Bevin Keenor    28            Resistencia  33986.78\n",
      "33          34       Tomaso Murname    35          Mar Del Plata  28615.26\n",
      "34          35        Carmelia Bunn    52                Rosario  27136.93\n",
      "35          36        Karie Premble    44                Posadas  52128.76\n",
      "36          37      Maurice Pelling    26             Corrientes  25838.89\n",
      "37          38   Clotilda Abilowitz    57                Posadas  42757.46\n",
      "38          39         Ginger Askaw    36                  Salta  36779.95\n",
      "39          40        Sallie Stubbe    37           Bahia Blanca  28333.21\n",
      "\n",
      "        Descripción preliminar:\n",
      "               id_cliente        edad      ingresos\n",
      "count  578.000000  578.000000    578.000000\n",
      "mean   289.500000   37.968858  34755.977266\n",
      "std    166.998503   10.253244  12989.576812\n",
      "min      1.000000   20.000000    170.290000\n",
      "25%    145.250000   30.000000  26119.060000\n",
      "50%    289.500000   37.000000  35102.285000\n",
      "75%    433.750000   43.000000  42600.435000\n",
      "max    578.000000   81.000000  88053.010000\n",
      "        Dimensiones:2\n",
      "        Forma:(578, 5)    \n",
      "        Número de elementos:2890\n",
      "        Nombres de columnas:Index(['id_cliente', 'nombre', 'edad', 'ciudad', 'ingresos'], dtype='object')\n",
      "        Nombres de filas:RangeIndex(start=0, stop=578, step=1)\n",
      "        Tipos de datos:\n",
      "id_cliente      int64\n",
      "nombre         object\n",
      "edad            int64\n",
      "ciudad         object\n",
      "ingresos      float64\n",
      "dtype: object\n",
      "        Primeras 10 filas:\n",
      "   id_cliente               nombre  edad                 ciudad  ingresos\n",
      "0           1      Aloysia Screase    44          Mar Del Plata  42294.68\n",
      "1           2  Kristina Scaplehorn    25                Posadas  24735.04\n",
      "2           3       Filip Castagne    50            Resistencia  35744.85\n",
      "3           4          Liuka Luard    39           Bahia Blanca  27647.96\n",
      "4           5        Dore Cockshtt    28                Rosario  28245.65\n",
      "5           6        Patrick Earle    34  San Miguel De Tucuman  62763.31\n",
      "6           7           Etan Deeth    35            Resistencia  37489.71\n",
      "7           8       Booth Bielfelt    40                Cordoba  35255.94\n",
      "8           9         Shirl Labone    29                Rosario  27592.08\n",
      "9          10      Andy Mendenhall    52                Rosario  37153.94\n",
      "        Últimas 3 filas:\n",
      "     id_cliente           nombre  edad         ciudad  ingresos\n",
      "575         576  Cari Marzellano    38  Mar Del Plata  53114.05\n",
      "576         577   Magdalene Pegg    34        Cordoba  49849.42\n",
      "577         578    Lorry Santori    47     Corrientes  42000.81\n",
      "    **************************************************\n",
      "    \n",
      "\n",
      "            nombre_columna='producto'\n",
      "            serie=0        Adorno de pared\n",
      "1                 Tablet\n",
      "2        Lámpara de mesa\n",
      "3             Smartphone\n",
      "4               Alfombra\n",
      "             ...        \n",
      "85            Aspiradora\n",
      "86             Televisor\n",
      "87     Rincón de plantas\n",
      "88              Secadora\n",
      "89    Freidora eléctrica\n",
      "Name: producto, Length: 90, dtype: object\n",
      "            regla='string'\n",
      "            \n",
      "\n",
      "            **************************************************\n",
      "            regla='string'\n",
      "\n",
      "            nombre_columna='canal'\n",
      "            serie=0        TV\n",
      "1      RRSS\n",
      "2     Email\n",
      "3      RRSS\n",
      "4     Email\n",
      "      ...  \n",
      "85       TV\n",
      "86       TV\n",
      "87       TV\n",
      "88    Email\n",
      "89     RRSS\n",
      "Name: canal, Length: 90, dtype: object\n",
      "            regla='string'\n",
      "            \n",
      "\n",
      "            **************************************************\n",
      "            regla='string'\n",
      "\n",
      "            nombre_columna='costo'\n",
      "            serie=0     4.81\n",
      "1     3.40\n",
      "2     5.54\n",
      "3     6.37\n",
      "4     4.25\n",
      "      ... \n",
      "85    3.06\n",
      "86    4.98\n",
      "87    5.81\n",
      "88    3.80\n",
      "89    5.27\n",
      "Name: costo, Length: 90, dtype: float64\n",
      "            regla='numeric'\n",
      "            \n",
      "\n",
      "            **************************************************\n",
      "            regla='numeric'\n",
      "\n",
      "            nombre_columna='fecha_inicio'\n",
      "            serie=0     20/03/2024\n",
      "1     26/03/2024\n",
      "2     28/03/2024\n",
      "3     29/03/2024\n",
      "4     31/03/2024\n",
      "         ...    \n",
      "85    13/12/2024\n",
      "86    13/12/2024\n",
      "87    17/12/2024\n",
      "88    20/12/2024\n",
      "89    29/12/2024\n",
      "Name: fecha_inicio, Length: 90, dtype: object\n",
      "            regla='date'\n",
      "            \n",
      "\n",
      "            **************************************************\n",
      "            regla='date'\n",
      "\n",
      "            nombre_columna='fecha_fin'\n",
      "            serie=0     03/05/2024\n",
      "1     13/05/2024\n",
      "2     20/04/2024\n",
      "3     16/05/2024\n",
      "4     05/05/2024\n",
      "         ...    \n",
      "85    29/12/2024\n",
      "86      8/2/2025\n",
      "87     14/2/2025\n",
      "88      7/1/2025\n",
      "89     21/1/2025\n",
      "Name: fecha_fin, Length: 90, dtype: object\n",
      "            regla='date'\n",
      "            \n",
      "\n",
      "            **************************************************\n",
      "            regla='date'\n",
      "    id_campanha                producto  canal  costo fecha_inicio  fecha_fin\n",
      "0            74         adorno de pared     TV   4.81   2024-03-20 2024-05-03\n",
      "1            12                  tablet   RRSS   3.40   2024-03-26 2024-05-13\n",
      "2            32         lampara de mesa  EMAIL   5.54   2024-03-28 2024-04-20\n",
      "3            21              smartphone   RRSS   6.37   2024-03-29 2024-05-16\n",
      "4            58                alfombra  EMAIL   4.25   2024-03-31 2024-05-05\n",
      "5            85              smartwatch     TV   5.07   2024-04-01 2024-05-05\n",
      "6            36        plancha de vapor  EMAIL   5.41   2024-04-02 2024-06-01\n",
      "7            57                batidora  EMAIL   4.48   2024-04-10 2024-06-08\n",
      "8            44         adorno de pared  EMAIL   5.08   2024-04-13 2024-05-10\n",
      "9            84     parlantes bluetooth     TV   4.42   2024-04-17 2024-05-05\n",
      "10            1       cuadro decorativo   RRSS   5.27   2024-04-27 2024-06-04\n",
      "11           43                cortinas  EMAIL   5.67   2024-05-02 2024-06-17\n",
      "12           50  consola de videojuegos  EMAIL   4.97   2024-05-03 2024-05-28\n",
      "13           34                heladera  EMAIL   4.20   2024-05-06 2024-07-05\n",
      "14           15       jarron decorativo   RRSS   4.65   2024-05-09 2024-06-13\n",
      "15           46                lavadora  EMAIL   3.63   2024-05-12 2024-05-29\n",
      "16           29               televisor   RRSS   3.96   2024-05-17 2024-06-28\n",
      "17           67               proyector     TV   3.68   2024-05-22 2024-07-12\n",
      "18           76                lavadora     TV   4.66   2024-05-26 2024-07-02\n",
      "19           51              smartphone  EMAIL   4.65   2024-05-28 2024-06-15\n",
      "20           69              candelabro     TV   3.25   2024-05-29 2024-06-30\n",
      "21            2         lampara de mesa   RRSS   5.88   2024-05-30 2024-06-29\n",
      "22            4                heladera   RRSS   4.53   2024-05-31 2024-07-15\n",
      "23           83       espejo decorativo     TV   5.24   2024-05-31 2024-07-08\n",
      "24           47             auriculares  EMAIL   4.19   2024-06-02 2024-07-22\n",
      "25           45       jarron decorativo  EMAIL   4.52   2024-06-05 2024-07-31\n",
      "26           71      freidora electrica     TV   4.37   2024-06-05 2024-07-24\n",
      "27           38       rincon de plantas  EMAIL   5.76   2024-06-14 2024-07-15\n",
      "28           49                cafetera  EMAIL   5.20   2024-06-20 2024-07-22\n",
      "29           40              aspiradora  EMAIL   6.24   2024-06-24 2024-08-12\n",
      "30           22   elementos de ceramica   RRSS   5.44   2024-06-26 2024-07-15\n",
      "31           37               proyector  EMAIL   3.22   2024-07-06 2024-07-26\n",
      "32           72                  tablet     TV   4.90   2024-07-08 2024-09-03\n",
      "33           64                heladera     TV   4.38   2024-07-10 2024-08-09\n",
      "34           42                  tablet  EMAIL   4.42   2024-07-14 2024-09-03\n",
      "35           17             auriculares   RRSS   6.06   2024-07-15 2024-08-15\n",
      "36           20  consola de videojuegos   RRSS   3.16   2024-07-15 2024-08-03\n",
      "37           18          camara digital   RRSS   5.46   2024-07-16 2024-09-13\n",
      "38           39              candelabro  EMAIL   6.08   2024-07-17 2024-08-18\n",
      "39           53       espejo decorativo  EMAIL   4.90   2024-07-17 2024-08-01\n",
      "\n",
      "        Descripción preliminar:\n",
      "               id_campanha      costo         fecha_inicio            fecha_fin\n",
      "count    90.000000  90.000000                   90                   90\n",
      "mean     45.500000   4.928667  2024-08-03 16:48:00  2024-09-10 09:04:00\n",
      "min       1.000000   2.950000  2024-03-20 00:00:00  2024-04-20 00:00:00\n",
      "25%      23.250000   4.372500  2024-05-31 00:00:00  2024-07-12 18:00:00\n",
      "50%      45.500000   4.900000  2024-08-02 12:00:00  2024-09-12 12:00:00\n",
      "75%      67.750000   5.562500  2024-10-02 12:00:00  2024-11-11 18:00:00\n",
      "max      90.000000   7.390000  2024-12-29 00:00:00  2025-02-14 00:00:00\n",
      "std      26.124701   0.947750                  NaN                  NaN\n",
      "        Dimensiones:2\n",
      "        Forma:(90, 6)    \n",
      "        Número de elementos:540\n",
      "        Nombres de columnas:Index(['id_campanha', 'producto', 'canal', 'costo', 'fecha_inicio',\n",
      "       'fecha_fin'],\n",
      "      dtype='object')\n",
      "        Nombres de filas:RangeIndex(start=0, stop=90, step=1)\n",
      "        Tipos de datos:\n",
      "id_campanha              int64\n",
      "producto                object\n",
      "canal                   object\n",
      "costo                  float64\n",
      "fecha_inicio    datetime64[ns]\n",
      "fecha_fin       datetime64[ns]\n",
      "dtype: object\n",
      "        Primeras 10 filas:\n",
      "   id_campanha             producto  canal  costo fecha_inicio  fecha_fin\n",
      "0           74      adorno de pared     TV   4.81   2024-03-20 2024-05-03\n",
      "1           12               tablet   RRSS   3.40   2024-03-26 2024-05-13\n",
      "2           32      lampara de mesa  EMAIL   5.54   2024-03-28 2024-04-20\n",
      "3           21           smartphone   RRSS   6.37   2024-03-29 2024-05-16\n",
      "4           58             alfombra  EMAIL   4.25   2024-03-31 2024-05-05\n",
      "5           85           smartwatch     TV   5.07   2024-04-01 2024-05-05\n",
      "6           36     plancha de vapor  EMAIL   5.41   2024-04-02 2024-06-01\n",
      "7           57             batidora  EMAIL   4.48   2024-04-10 2024-06-08\n",
      "8           44      adorno de pared  EMAIL   5.08   2024-04-13 2024-05-10\n",
      "9           84  parlantes bluetooth     TV   4.42   2024-04-17 2024-05-05\n",
      "        Últimas 3 filas:\n",
      "    id_campanha            producto  canal  costo fecha_inicio  fecha_fin\n",
      "87           68   rincon de plantas     TV   5.81   2024-12-17 2025-02-14\n",
      "88           33            secadora  EMAIL   3.80   2024-12-20 2025-01-07\n",
      "89           11  freidora electrica   RRSS   5.27   2024-12-29 2025-01-21\n",
      "    **************************************************\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "def limpiar_dataframes() :\n",
    "    \"\"\"\n",
    "    Limpia el DataFrame aplicando reglas_por_columna = {\"col\": (\"regla\", parametros)...}\n",
    "    Las reglas se asignan automáticamente según el tipo o formato:\n",
    "      - Columnas numéricas o con símbolos ($, %, dígitos) → 'numeric'\n",
    "      - Columnas que parecen fechas → 'date'\n",
    "      - Otras columnas → 'string'\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "\n",
    "    for nombre_df, df_cada in dic_dfs.items():\n",
    "        '''\n",
    "        print (f\"\"\"{nombre_df}\n",
    "        {dic_dfs[nombre_df]}\n",
    "        \"\"\")\n",
    "        '''\n",
    "        for nombre_columna, serie in df_cada.items():\n",
    "            nombre_columna= nombre_columna.lower().replace(\" \",\"_\")\n",
    "            if nombre_columna.startswith(\"id_\"):\n",
    "                continue\n",
    "            regla =  next(iter(reglas[nombre_df][nombre_columna]))\n",
    "            print (f\"\"\"\n",
    "            {nombre_columna=}\n",
    "            {serie=}\n",
    "            {regla=}\n",
    "            \"\"\")\n",
    "            s = serie.copy()\n",
    "            if regla == \"numeric\":\n",
    "                try:\n",
    "                    s = s.astype(str).str.strip()\n",
    "                    s = s.str.replace('$', '')\n",
    "                except:\n",
    "                    pass\n",
    "                s = pd.to_numeric(s, errors=\"coerce\")\n",
    "                if reglas[nombre_df][nombre_columna][\"numeric\"][\"as_int\"] :\n",
    "                    s = s.replace('.', '').replace(',', '')\n",
    "                    if not s.isna().any():\n",
    "                        s = s.astype(int)\n",
    "            elif regla == \"string\":\n",
    "                s = s.astype(str).str.strip().replace(\"  \",\" \")\n",
    "                match  reglas[nombre_df][nombre_columna][regla][\"tipo\"] :\n",
    "                    case \"upper\":\n",
    "                        s = s.str.upper()\n",
    "                    case \"title\":\n",
    "                        s = s.str.title()\n",
    "                    case \"lower\":\n",
    "                        s = s.str.lower()\n",
    "                #texto_n = unicodedata.normalize(\"NFD\", entrada)\n",
    "                s= s.apply(  lambda x: ''.join( c for c in unicodedata.normalize('NFKD', str(x)) if not unicodedata.combining(c)  )  )\n",
    "                #''.join(c for c in unicodedata.normalize('NFKD', str(x))  if not unicodedata.combining(c))  for x in df[\"columna\"]\n",
    "                '''\n",
    "                \n",
    "                Modo\tSignificado\tQué hace\tCuándo usar\n",
    "                NFD\tNormalization Form Decomposition\tDescompone los caracteres Unicode en su forma básica y diacrítica. Ej: \"á\" → \"a\" + \" ́\"\tCuando solo querés separar acentos.\n",
    "                NFKD\tCompatibility Decomposition\tHace lo mismo más normaliza formas equivalentes \"compatibles\" (por ejemplo, “①” → “1”, “ﬂ” → “fl”)\tIdeal para limpieza más completa de texto.\n",
    "                '''\n",
    "            elif regla == \"date\":\n",
    "                # Convertimos la serie a datetime\n",
    "                s = pd.to_datetime(  s,  dayfirst=reglas[nombre_df][nombre_columna][regla][\"dayfirst\"],   errors=\"coerce\"  ) \n",
    "                #s = s.dt.strftime('%Y/%m/%d')\n",
    "            elif regla == \"fillna\":\n",
    "                s = s.fillna(0)\n",
    "            dic_dfs[nombre_df][nombre_columna] = s\n",
    "            print (f\"\"\"\n",
    "            {\"*\"*50}\n",
    "            {regla=}\"\"\")\n",
    "        print (dic_dfs[nombre_df].head(40))\n",
    "        ver( dic_dfs[nombre_df])\n",
    "limpiar_dataframes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e42599a-abe2-4447-b8e6-6c1024f0d651",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nombre_limpio = ventas_limpio.csv\n",
      "Guardado cleaned en: datasets_salida\\limpios\\ventas_limpio.csv\n",
      "nombre_limpio = clientes_limpio.csv\n",
      "Guardado cleaned en: datasets_salida\\limpios\\clientes_limpio.csv\n",
      "nombre_limpio = marketing_limpio.csv\n",
      "Guardado cleaned en: datasets_salida\\limpios\\marketing_limpio.csv\n"
     ]
    }
   ],
   "source": [
    "# Función auxiliar para guardar CSVs\n",
    "def guardar_csv(df, ruta):\n",
    "    \"\"\"\n",
    "    Guarda df en ruta (string o Path). Crea directorio padre si no existe.\n",
    "    \"\"\"\n",
    "    ruta = Path(ruta)\n",
    "    ruta.parent.mkdir(parents=True, exist_ok=True)\n",
    "    df.to_csv(ruta, index=False, encoding='utf-8')\n",
    "    return ruta\n",
    "\n",
    "for [path_archivo, df_actual],[nombre_archivo,_] in zip( dic_dfs.items() , reglas_por_archivo.items() ):\n",
    "\n",
    "    nombre_limpio = nombre_archivo[:-4] + '_limpio.csv' if nombre_archivo.lower().endswith('.csv') else nombre_archivo + ' limpio.csv'\n",
    "    print(f'nombre_limpio = {nombre_limpio}')\n",
    "    # guardar cleaned\n",
    "    ruta_guardado = carpeta_limpios / nombre_limpio\n",
    "    guardar_csv(df_actual, ruta_guardado)\n",
    "    print(f'Guardado cleaned en: {ruta_guardado}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f4aefb8b-3e14-4917-9986-8b7f27033cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def es_valor_faltante(se):\n",
    "    \"\"\"\n",
    "    Determina si un valor debe considerarse faltante (True) usando tokens y NaN.\n",
    "    \"\"\"\n",
    "    if pd.isna(valor):\n",
    "        return True\n",
    "    salida = s in TOKENS_VALOR_FALTANTE\n",
    "    print (salida)\n",
    "    return salida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4634aeae-c21a-47dc-9bb9-cffdeafcbe54",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Detección de outliers (IQR) - función corregida y robusta\n",
    "def mascara_valores_atipicos_rango_intercuartil(serie_datos):\n",
    "    \"\"\"\n",
    "    Devuelve una tupla: (mascara_bool_series, cantidad_outliers, (limite_inferior, limite_superior))\n",
    "    - serie_datos: pd.Series (acepta valores no numéricos, se intentará convertir)\n",
    "    - La máscara tiene la misma indexación que la serie original (NaNs -> False)\n",
    "    \"\"\"\n",
    "    # Intentar convertir a numérico (coerce -> NaN para no numéricos)\n",
    "    serie_numerica = pd.to_numeric(serie_datos, errors='coerce')\n",
    "    # Serie limpia para cálculos de cuartiles (sin NaN)\n",
    "    serie_limpia = serie_numerica.dropna().astype(float)\n",
    "    if serie_limpia.shape[0] < 4:\n",
    "        # No hay suficientes datos para IQR: devolver máscara False de la misma longitud\n",
    "        mascara = pd.Series([False] * len(serie_datos), index=serie_datos.index)\n",
    "        return mascara, int(mascara.sum()), (None, None)\n",
    "    cuartil_1 = float(serie_limpia.quantile(0.25))\n",
    "    cuartil_3 = float(serie_limpia.quantile(0.75))\n",
    "    rango_intercuartil = cuartil_3 - cuartil_1\n",
    "    limite_inferior = cuartil_1 - desviacion_margen * rango_intercuartil\n",
    "    limite_superior = cuartil_3 + desviacion_margen * rango_intercuartil\n",
    "    # Crear máscara sobre la serie numérica original (alineada con el index original)\n",
    "    mascara = (serie_numerica < limite_inferior) | (serie_numerica > limite_superior)\n",
    "    mascara = mascara.fillna(False).astype(bool)\n",
    "    return mascara, int(mascara.sum()), (limite_inferior, limite_superior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4c15444c-3df6-409e-a932-c08afaebfd51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Funciones utilitarias definidas.\n"
     ]
    }
   ],
   "source": [
    "# Detección de outliers (Z-score)\n",
    "def mascara_valores_atipicos_zscore(serie_datos, desviacion_umbral=3.0):\n",
    "    \"\"\"\n",
    "    Devuelve máscara booleana (True = outlier) según Z-score.\n",
    "    \"\"\"\n",
    "    serie_limpia = serie_datos.dropna().astype(float)\n",
    "    if serie_limpia.shape[0] < 4 or serie_limpia.std() == 0:\n",
    "        return pd.Series([False] * len(serie_datos), index=serie_datos.index)\n",
    "    puntaje_z = (serie_datos - serie_limpia.mean()) / serie_limpia.std()\n",
    "    return puntaje_z.abs() > desviacion_umbral  \n",
    "print('Funciones utilitarias definidas.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f411cb90-17af-45f2-9dfb-9fe7534bacbb",
   "metadata": {},
   "source": [
    "# limpieza y normalización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fe131403",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Función detectar_problemas_en_dataframe cargada.\n"
     ]
    }
   ],
   "source": [
    "# ---------- Detección de problemas en un DataFrame ----------\n",
    "def detectar_problemas_en_dataframe(df: pd.DataFrame):\n",
    " \n",
    "    resumen                       = {}\n",
    "    resumen['filas']              = df.shape[0]\n",
    "    resumen['columnas']           = df.shape[1]\n",
    "    resumen['nulos_por_columna']  = df.isna().sum().to_dict()\n",
    "    dup_mask                      = df.duplicated(keep=False)\n",
    "    resumen['duplicados_exactos'] = int(dup_mask.sum())\n",
    "    chequeos_por_columna          = {}\n",
    "    print(f\"\"\"\\033[1;37;44m\\n\n",
    "╔═════════════════════════════════════════════════════════════════════════════╗\n",
    "║                              Valores a eliminar                             ║\n",
    "╠═════════════════════════════════════════════════════════════════════════════╣\n",
    "║     Afecta                                                                  ║\n",
    "║         Elimina espacios iniciales y finales.                               ║\n",
    "║         Borra Na                                                            ║\n",
    "║         Borra duplicados                                                    ║\n",
    "╚═════════════════════════════════════════════════════════════════════════════╝\\033[0;m\"\"\") \n",
    "    print(f\"\"\"\\033[1;37;44m\\n\n",
    "╔═════════════════════════════════════════════════════════════════════════════╗\n",
    "║                               Valores atípicos                              ║\n",
    "╠═════════════════════════════════════════════════════════════════════════════╣\n",
    "║     Afecta                                                                  ║\n",
    "║         NO Modifica datos.                                                  ║\n",
    "║         Se guarda la información en archivo excel para referencias futuras  ║\n",
    "║         Se evalua es mediante dos formas                                    ║\n",
    "║            1) limites intercuartiles 25 y 75 % * desviacion_margen {desviacion_margen}      ║\n",
    "║            2) Z-score mayor a desviacion_umbral {desviacion_umbral}                         ║\n",
    "╚═════════════════════════════════════════════════════════════════════════════╝\\033[0;m\"\"\")\n",
    "    for col in df.columns:\n",
    "        serie = df[col]\n",
    "        info = {'dtype': str(serie.dtype), 'nulos': int(serie.isna().sum())}\n",
    "        if serie.dtype == object or pd.api.types.is_string_dtype(serie):\n",
    "            s = serie.astype(str)\n",
    "            info['espacios_inicio']          = int(s.str.match(r'^\\s+').sum())\n",
    "            info['espacios_final']           = int(s.str.match(r'\\s+$').sum())\n",
    "            try:\n",
    "                unique_original              = set(s.dropna().unique())\n",
    "                unique_lower                 = set(s.dropna().str.lower().unique())\n",
    "                info['unique_original']      = len(unique_original)\n",
    "                info['unique_lower']         = len(unique_lower)\n",
    "                info['variantes_mayusculas'] = len(unique_lower) < len(unique_original)\n",
    "            except Exception:\n",
    "                info['unique_original']      = serie.nunique(dropna=True)\n",
    "                info['unique_lower']         = None\n",
    "                info['variantes_mayusculas'] = None\n",
    "            try:\n",
    "                unaccented                   = s.dropna().map(lambda x: sacar_acentos(x).lower())\n",
    "                groups                       = unaccented.groupby(unaccented).size()\n",
    "                conflicts                    = groups[groups > 1]\n",
    "                info['grupos_var_acentos']   = int(conflicts.shape[0])\n",
    "                ejemplos = {}\n",
    "                if not conflicts.empty:\n",
    "                    for val in conflicts.index[:5]:\n",
    "                        originales           = sorted(list(s[unaccented == val].unique())[:10])\n",
    "                        ejemplos[val]        = originales\n",
    "                info['ejemplos_var_acentos'] = ejemplos\n",
    "            except Exception:\n",
    "                info['grupos_var_acentos']   = None\n",
    "                info['ejemplos_var_acentos'] = {}\n",
    "            info['tokens_aparente_faltante'] = int(\n",
    "                s.map(lambda x: str(x).strip().lower()).map(lambda v: sacar_acentos(v) in TOKENS_VALOR_FALTANTE).sum()\n",
    "            )\n",
    "            info['muestras'] = list(s.dropna().unique()[:10])\n",
    "        else:\n",
    "            # numeric\n",
    "            if pd.api.types.is_numeric_dtype(serie) or (serie.dropna().astype(str).str.replace('.','',1).str.isnumeric().all() if len(serie.dropna())>0 else False):\n",
    "                try:\n",
    "                    serie_numerica = serie.dropna().astype(float)\n",
    "                except Exception:\n",
    "                    serie_numerica = pd.to_numeric(serie, errors='coerce').dropna().astype(float)\n",
    "                info['media'] = float(serie_numerica.mean()) if not serie_numerica.empty else None\n",
    "                info['std']   = float(serie_numerica.std()) if not serie_numerica.empty else None\n",
    "                info['min']   = float(serie_numerica.min()) if not serie_numerica.empty else None\n",
    "                info['max']   = float(serie_numerica.max()) if not serie_numerica.empty else None\n",
    "                if len(serie_numerica) >= 4:\n",
    "                    mascara_outliers_iqr, cant,(info['outliers_iqr'] ,info['limites_iqr']) =mascara_valores_atipicos_rango_intercuartil(serie)\n",
    "                    #mascara, int(mascara.sum()), (limite_inferior, limite_superior)\n",
    "                    '''\n",
    "                    print (f\"\"\"\n",
    "                    {mascara_outliers_iqr=}\n",
    "                    {cant=}\n",
    "                    {info['outliers_iqr']=}\n",
    "                    {info['limites_iqr']=}\n",
    "                    {\"-\"*100}\n",
    "                    \"\"\")\n",
    "                    '''\n",
    "                    \n",
    "                else:\n",
    "                    info['outliers_iqr'] = None\n",
    "                    info['limites_iqr'] = None\n",
    "                if len(serie_numerica) >= 4 and serie_numerica.std() != 0:\n",
    "                    z = (serie_numerica - serie_numerica.mean()) / serie_numerica.std()\n",
    "                    info['outliers_z'] = int((z.abs() > 3).sum())\n",
    "                else:\n",
    "                    info['outliers_z'] = None\n",
    "            else:\n",
    "                # fechas intento parseo\n",
    "                parsed = pd.to_datetime(serie, errors='coerce', dayfirst=True)\n",
    "                info['fechas_parseables'] = int(parsed.notna().sum())\n",
    "                info['muestras'] = list(serie.dropna().unique()[:10])\n",
    "        chequeos_por_columna[col] = info\n",
    "\n",
    "    filas_problemas = []\n",
    "    df.columns = [c.strip().lower().replace(' ', '_') for c in df.columns]\n",
    "    for idx, fila in df.iterrows():\n",
    "        lista_problemas = []\n",
    "        if dup_mask.loc[idx]:\n",
    "            lista_problemas.append('duplicado_exacto')\n",
    "        for col in df.columns:\n",
    "            val = fila[col]\n",
    "            \n",
    "            # heurísticas textuales\n",
    "            if pd.api.types.is_string_dtype(type(val)) or isinstance(val, str) or (\n",
    "                not pd.isna(val) and not pd.api.types.is_numeric_dtype(type(val)) and str(chequeos_por_columna[col].get('dtype','')).startswith('object')\n",
    "            ):\n",
    "                s = str(val)\n",
    "                if s != s.strip():\n",
    "                    lista_problemas.append(f'espacios_en_columna_{col}')\n",
    "                if chequeos_por_columna[col].get('variantes_mayusculas'):\n",
    "                    if s and s != s.lower() and s.lower() in [str(x).lower() for x in df[col].dropna().unique()]:\n",
    "                        lista_problemas.append(f'inconsistencia_mayusculas_columna_{col}')\n",
    "                if chequeos_por_columna[col].get('grupos_var_acentos') and chequeos_por_columna[col]['grupos_var_acentos'] > 0:\n",
    "                    try:\n",
    "                        #un = sacar_acentos(s).lower()\n",
    "                        #group_vals = [x for x in chequeos_por_columna[col].get('muestras', []) if sacar_acentos(str(x)).lower() == un]\n",
    "                        \n",
    "                        \n",
    "                        \n",
    "                        \n",
    "                        df['col'] = df['col'].apply(sacar_acentos)\n",
    "                        \n",
    "                        \n",
    "                        \n",
    "                        if group_vals and any(sacar_acentos(str(x)).lower() != sacar_acentos(s).lower() for x in group_vals):\n",
    "                            lista_problemas.append(f'variantes_acentos_columna_{col}')\n",
    "                    except Exception:\n",
    "                        pass\n",
    "                if es_valor_faltante(s):\n",
    "                    lista_problemas.append(f'token_faltante_columna_{col}')\n",
    "            else:\n",
    "                # heurísticas numéricas\n",
    "                try:\n",
    "                    fval = float(val)\n",
    "                    info_col = chequeos_por_columna[col]\n",
    "                    limites = info_col.get('limites_iqr')\n",
    "                    if limites and (fval < limites[0] or fval > limites[1]):\n",
    "                        lista_problemas.append(f'outlier_iqr_columna_{col}')\n",
    "                    if info_col.get('std') not in (None, 0):\n",
    "                        mean = info_col.get('media')\n",
    "                        std = info_col.get('std')\n",
    "                        if std and abs((fval - mean) / std) > 3:\n",
    "                            lista_problemas.append(f'outlier_z_columna_{col}')\n",
    "                except Exception:\n",
    "                    pass\n",
    "        if lista_problemas:\n",
    "            filas_problemas.append({\n",
    "                'row_index': idx,\n",
    "                'problemas': ';'.join(sorted(set(lista_problemas))),\n",
    "                'muestra': json.dumps({str(c): str(fila[c]) for c in df.columns[:8]})\n",
    "            })\n",
    "\n",
    "    df_problemas = pd.DataFrame(filas_problemas)\n",
    "    return resumen, chequeos_por_columna, df_problemas\n",
    "\n",
    "print('Función detectar_problemas_en_dataframe cargada.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ccc0f0c3-0e31-4f27-9661-3215c9185f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_frames = {\n",
    "    ruta_ventas     : df_ventas,\n",
    "    ruta_clientes   : df_clientes,\n",
    "    ruta_marketing  : df_marketing\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "32235fb9-1e09-422e-931b-3471d6fbf123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;37;44m\n",
      "\n",
      "╔═════════════════════════════════════════════════════════════════════════════╗\n",
      "║                     Aplico reglas según columna específica                  ║\n",
      "╠═════════════════════════════════════════════════════════════════════════════╣\n",
      "║     Afecta                                                                  ║\n",
      "║             Numéricos (int/float)                                           ║\n",
      "║             fechas --> YYYY,MM,DD                                           ║\n",
      "╚═════════════════════════════════════════════════════════════════════════════╝\u001b[0;m\n",
      "\u001b[1;37;44m\n",
      "\n",
      "╔═════════════════════════════════════════════════════════════════════════════╗\n",
      "║                              Valores a eliminar                             ║\n",
      "╠═════════════════════════════════════════════════════════════════════════════╣\n",
      "║     Afecta                                                                  ║\n",
      "║         Elimina espacios iniciales y finales.                               ║\n",
      "║         Borra Na                                                            ║\n",
      "║         Borra duplicados                                                    ║\n",
      "╚═════════════════════════════════════════════════════════════════════════════╝\u001b[0;m\n",
      "\u001b[1;37;44m\n",
      "\n",
      "╔═════════════════════════════════════════════════════════════════════════════╗\n",
      "║                               Valores atípicos                              ║\n",
      "╠═════════════════════════════════════════════════════════════════════════════╣\n",
      "║     Afecta                                                                  ║\n",
      "║         NO Modifica datos.                                                  ║\n",
      "║         Se guarda la información en archivo excel para referencias futuras  ║\n",
      "║         Se evalua es mediante dos formas                                    ║\n",
      "║            1) limites intercuartiles 25 y 75 % * desviacion_margen 1.5      ║\n",
      "║            2) Z-score mayor a desviacion_umbral 3.0                         ║\n",
      "╚═════════════════════════════════════════════════════════════════════════════╝\u001b[0;m\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'sacar_acentos' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 68\u001b[39m\n\u001b[32m     66\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mProceso completo del diccionario de DataFrames.\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     67\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m errores_df\n\u001b[32m---> \u001b[39m\u001b[32m68\u001b[39m errores_df = \u001b[43mmenu_procesar_diccionario\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdic_frames\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreglas_por_archivo\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 20\u001b[39m, in \u001b[36mmenu_procesar_diccionario\u001b[39m\u001b[34m(dic_frames, reglas_por_archivo)\u001b[39m\n\u001b[32m     18\u001b[39m \u001b[38;5;66;03m# trabajamos sobre una copia para evitar modificar dict original por error\u001b[39;00m\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m [path_archivo, df_actual],[nombre_archivo,_] \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m( dic_frames.items() , reglas_por_archivo.items() ):\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m     resumen_antes, chequeos_antes, problemas_antes = \u001b[43mdetectar_problemas_en_dataframe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_actual\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     21\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m--- RESUMEN ANTES: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnombre_archivo\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m ---\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     22\u001b[39m     \u001b[38;5;66;03m# Para no volcar objetos muy grandes, mostramos el head del DataFrame de problemas (si existe)\u001b[39;00m\n\u001b[32m     23\u001b[39m     \u001b[38;5;66;03m#print('Muestras de problemas antes (primeras 5 filas):')\u001b[39;00m\n\u001b[32m     24\u001b[39m     \u001b[38;5;66;03m#print( display(problemas_antes.head(5) if not problemas_antes.empty else 'No se detectaron filas con problemas.') )\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 63\u001b[39m, in \u001b[36mdetectar_problemas_en_dataframe\u001b[39m\u001b[34m(df)\u001b[39m\n\u001b[32m     60\u001b[39m         info[\u001b[33m'\u001b[39m\u001b[33mgrupos_var_acentos\u001b[39m\u001b[33m'\u001b[39m]   = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m     61\u001b[39m         info[\u001b[33m'\u001b[39m\u001b[33mejemplos_var_acentos\u001b[39m\u001b[33m'\u001b[39m] = {}\n\u001b[32m     62\u001b[39m     info[\u001b[33m'\u001b[39m\u001b[33mtokens_aparente_faltante\u001b[39m\u001b[33m'\u001b[39m] = \u001b[38;5;28mint\u001b[39m(\n\u001b[32m---> \u001b[39m\u001b[32m63\u001b[39m         \u001b[43ms\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstrip\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlower\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msacar_acentos\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mTOKENS_VALOR_FALTANTE\u001b[49m\u001b[43m)\u001b[49m.sum()\n\u001b[32m     64\u001b[39m     )\n\u001b[32m     65\u001b[39m     info[\u001b[33m'\u001b[39m\u001b[33mmuestras\u001b[39m\u001b[33m'\u001b[39m] = \u001b[38;5;28mlist\u001b[39m(s.dropna().unique()[:\u001b[32m10\u001b[39m])\n\u001b[32m     66\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     67\u001b[39m     \u001b[38;5;66;03m# numeric\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Python312\\Lib\\site-packages\\pandas\\core\\series.py:4711\u001b[39m, in \u001b[36mSeries.map\u001b[39m\u001b[34m(self, arg, na_action)\u001b[39m\n\u001b[32m   4631\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmap\u001b[39m(\n\u001b[32m   4632\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   4633\u001b[39m     arg: Callable | Mapping | Series,\n\u001b[32m   4634\u001b[39m     na_action: Literal[\u001b[33m\"\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m\"\u001b[39m] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   4635\u001b[39m ) -> Series:\n\u001b[32m   4636\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   4637\u001b[39m \u001b[33;03m    Map values of Series according to an input mapping or function.\u001b[39;00m\n\u001b[32m   4638\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   4709\u001b[39m \u001b[33;03m    dtype: object\u001b[39;00m\n\u001b[32m   4710\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m4711\u001b[39m     new_values = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[43m=\u001b[49m\u001b[43mna_action\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4712\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._constructor(new_values, index=\u001b[38;5;28mself\u001b[39m.index, copy=\u001b[38;5;28;01mFalse\u001b[39;00m).__finalize__(\n\u001b[32m   4713\u001b[39m         \u001b[38;5;28mself\u001b[39m, method=\u001b[33m\"\u001b[39m\u001b[33mmap\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   4714\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Python312\\Lib\\site-packages\\pandas\\core\\base.py:925\u001b[39m, in \u001b[36mIndexOpsMixin._map_values\u001b[39m\u001b[34m(self, mapper, na_action, convert)\u001b[39m\n\u001b[32m    922\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[32m    923\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m arr.map(mapper, na_action=na_action)\n\u001b[32m--> \u001b[39m\u001b[32m925\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[43m=\u001b[49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Python312\\Lib\\site-packages\\pandas\\core\\algorithms.py:1743\u001b[39m, in \u001b[36mmap_array\u001b[39m\u001b[34m(arr, mapper, na_action, convert)\u001b[39m\n\u001b[32m   1741\u001b[39m values = arr.astype(\u001b[38;5;28mobject\u001b[39m, copy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m   1742\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1743\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1745\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m lib.map_infer_mask(\n\u001b[32m   1746\u001b[39m         values, mapper, mask=isna(values).view(np.uint8), convert=convert\n\u001b[32m   1747\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/lib.pyx:2999\u001b[39m, in \u001b[36mpandas._libs.lib.map_infer\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 63\u001b[39m, in \u001b[36mdetectar_problemas_en_dataframe.<locals>.<lambda>\u001b[39m\u001b[34m(v)\u001b[39m\n\u001b[32m     60\u001b[39m         info[\u001b[33m'\u001b[39m\u001b[33mgrupos_var_acentos\u001b[39m\u001b[33m'\u001b[39m]   = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m     61\u001b[39m         info[\u001b[33m'\u001b[39m\u001b[33mejemplos_var_acentos\u001b[39m\u001b[33m'\u001b[39m] = {}\n\u001b[32m     62\u001b[39m     info[\u001b[33m'\u001b[39m\u001b[33mtokens_aparente_faltante\u001b[39m\u001b[33m'\u001b[39m] = \u001b[38;5;28mint\u001b[39m(\n\u001b[32m---> \u001b[39m\u001b[32m63\u001b[39m         s.map(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;28mstr\u001b[39m(x).strip().lower()).map(\u001b[38;5;28;01mlambda\u001b[39;00m v: \u001b[43msacar_acentos\u001b[49m(v) \u001b[38;5;129;01min\u001b[39;00m TOKENS_VALOR_FALTANTE).sum()\n\u001b[32m     64\u001b[39m     )\n\u001b[32m     65\u001b[39m     info[\u001b[33m'\u001b[39m\u001b[33mmuestras\u001b[39m\u001b[33m'\u001b[39m] = \u001b[38;5;28mlist\u001b[39m(s.dropna().unique()[:\u001b[32m10\u001b[39m])\n\u001b[32m     66\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     67\u001b[39m     \u001b[38;5;66;03m# numeric\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'sacar_acentos' is not defined"
     ]
    }
   ],
   "source": [
    "# ---------- Bucle/menu principal (usa dic_frames) ----------\n",
    "def menu_procesar_diccionario(dic_frames, reglas_por_archivo):\n",
    "    \"\"\"\n",
    "    Recorre dic_frames: clave = nombre_archivo (ej. 'marketing.csv'), valor = DataFrame.\n",
    "    Ejecuta: detectar_problemas_en_dataframe antes, limpiar_dataframe, detectar_problemas_en_dataframe despues,\n",
    "    imprime resúmenes y guarda cleaned en carpeta_limpios con sufijo ' limpio.csv'.\n",
    "    También sobreescribe variables en RAM (df_marketing, df_ventas, df_clientes) si se encuentran en el nombre.\n",
    "    \"\"\"\n",
    "    print(\"\"\"\\033[1;37;44m\\n\n",
    "╔═════════════════════════════════════════════════════════════════════════════╗\n",
    "║                     Aplico reglas según columna específica                  ║\n",
    "╠═════════════════════════════════════════════════════════════════════════════╣\n",
    "║     Afecta                                                                  ║\n",
    "║             Numéricos (int/float)                                           ║\n",
    "║             fechas --> YYYY,MM,DD                                           ║\n",
    "╚═════════════════════════════════════════════════════════════════════════════╝\\033[0;m\"\"\")\n",
    "    errores_df=pd.DataFrame()\n",
    "    # trabajamos sobre una copia para evitar modificar dict original por error\n",
    "    for [path_archivo, df_actual],[nombre_archivo,_] in zip( dic_frames.items() , reglas_por_archivo.items() ):\n",
    "        resumen_antes, chequeos_antes, problemas_antes = detectar_problemas_en_dataframe(df_actual)\n",
    "        print(f\"--- RESUMEN ANTES: {nombre_archivo} ---\")\n",
    "        # Para no volcar objetos muy grandes, mostramos el head del DataFrame de problemas (si existe)\n",
    "        #print('Muestras de problemas antes (primeras 5 filas):')\n",
    "        #print( display(problemas_antes.head(5) if not problemas_antes.empty else 'No se detectaron filas con problemas.') )\n",
    "\n",
    "        errores_df  = pd.concat ([errores_df,problemas_antes])\n",
    "\n",
    "        #df_actual[df_actual.duplicated(keep=False)].copy()\n",
    "        reglas    = reglas_por_archivo.get(nombre_archivo, {})\n",
    "        df_limpio = limpiar_dataframe(df_actual, reglas_por_columna=reglas)\n",
    "\n",
    "        resumen_despues, chequeos_despues, problemas_despues = detectar_problemas_en_dataframe(df_limpio)\n",
    "        '''\n",
    "        print(f\"n--- RESUMEN DESPUÉS: {nombre_archivo} ---\")\n",
    "        print(resumen_despues)\n",
    "        print('Muestras de problemas después (primeras 5 filas):')\n",
    "        print( display(problemas_despues.head(5) if not problemas_despues.empty else 'No se detectaron filas con problemas tras la limpieza.'))\n",
    "        '''\n",
    "        # mostrar separadores y tipo-nombre\n",
    "\n",
    "        #print('-'*100)\n",
    "        #print(f'nombre_archivo = {nombre_archivo}')\n",
    "        #print(f'type(nombre_archivo) = {type(nombre_archivo)}')\n",
    "        #print('-'*100)\n",
    "\n",
    "        # Guardo el archivo en limpios  ruta_base carpeta_reportes\n",
    "        nombre_limpio = nombre_archivo[:-4] + '_limpio.csv' if nombre_archivo.lower().endswith('.csv') else nombre_archivo + ' limpio.csv'\n",
    "        print(f'nombre_limpio = {nombre_limpio}')\n",
    "    \n",
    "        # guardar cleaned\n",
    "        ruta_guardado = carpeta_limpios / nombre_limpio\n",
    "        guardar_csv(df_limpio, ruta_guardado)\n",
    "        print(f'Guardado cleaned en: {ruta_guardado}')\n",
    "\n",
    "        # sobreescribir en RAM según el nombre\n",
    "        # (nota: usar globals() para actualizar variables en el entorno global del notebook)\n",
    "        dic_dfs[nombre_archivo.lower()] = df_limpio\n",
    "        '''\n",
    "        if 'marketing' in nombre_archivo.lower():\n",
    "            globals()['df_marketing'] = df_limpio\n",
    "        elif 'ventas' in nombre_archivo.lower():\n",
    "            globals()['df_ventas'] = df_limpio\n",
    "        elif 'clientes' in nombre_archivo.lower():\n",
    "            globals()['df_clientes'] = df_limpio\n",
    "        '''\n",
    "    print('Proceso completo del diccionario de DataFrames.')\n",
    "    return errores_df\n",
    "errores_df = menu_procesar_diccionario(dic_frames, reglas_por_archivo)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f4ffe5-0f8d-465e-be9e-6d180fa42789",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#CCCCCC; padding:10px; border-radius:6px;\">\n",
    "<h2 style=\"color:black; text-align:center;\">Resultados de limpieza</h2>\n",
    "<p style=\"color:black;\">- Revisados los 3 csv  pasados a DataFrames.</p>\n",
    "<p style=\"color:blue;\">- DataFrames filtrados.</p>\n",
    "<p style=\"color:black;\">- Filtrado de Nulos.</p>\n",
    "<p style=\"color:black;\">- Filtrado de duplicados.</p>\n",
    "<p style=\"color:black;\">- Sin '', 'na', 'n/a', 'null', 'none', 'sin dato', 's/d', 'nd', '-', '--', '?', 'sin_dato', 'n/d'</p>    \n",
    "<p style=\"color:black;\">- Normalisados Strings segun reglas. Estilo (lower,string.upper) unicodedata.normalize('NFKD')</p>\n",
    "<p style=\"color:black;\">- Normalisados precios a float sin signo ($)</p>\n",
    "<p style=\"color:black;\">- Normalisados Numericos a int o float segun regla</p>    \n",
    "<p style=\"color:black;\">- Normalisados Fechas segun regla YYYY/MM/DD</p>    \n",
    "<p style=\"color:black;\">- Resguardo <code>datasets_salida/limpios/clientes_limpio.csv</code>.</p>\n",
    "<p style=\"color:black;\">- Resguardo <code>datasets_salida/limpios/marketing_limpio.csv</code>.</p>\n",
    "<p style=\"color:black;\">- Resguardo <code>datasets_salida/limpios/ventas_limpio.csv</code>.</p>\n",
    "<p style=\"color:blue;\">- Registros filtrados eliminados</p>\n",
    "<p style=\"color:black;\">- Resguardo <code>datasets_salida/reportes/reporte_limpieza.xlsx</code> con hojas (duplicados borrados, outliers, totales)</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f1ab45f-4494-4b83-8470-20c6aab64b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Crear df_duplicados_total\n",
    "print (f\"\"\"\n",
    "{cantidad_duplicados=}\n",
    "\"\"\")\n",
    "# Filtra las filas donde la columna 'problemas' contiene la subcadena 'duplicado_exacto'\n",
    "df_duplicados_total = errores_df[errores_df['problemas'].str.contains('duplicado_exacto', case=False, na=False)].copy()\n",
    "\n",
    "# 2. Crear df_outliers_total\n",
    "# Filtra las filas donde la columna 'problemas' contiene la subcadena 'outlier_'\n",
    "df_outliers_total = errores_df[errores_df['problemas'].str.contains('outlier_', case=False, na=False)].copy()\n",
    "\n",
    "# 3. Crear df_resumen (Combinación y Ordenamiento)\n",
    "# Concatena los dos DataFrames creados\n",
    "df_resumen = pd.concat([df_duplicados_total, df_outliers_total])\n",
    "\n",
    "# Ordena el DataFrame resultante por la columna 'problemas'\n",
    "df_resumen = df_resumen.sort_values(by=\"problemas\").reset_index(drop=True)\n",
    "'''\n",
    "print (f\"\"\"\n",
    "df_duplicados_total\n",
    "{df_duplicados_total}\n",
    "\n",
    "{\"-\"*100}\n",
    "\n",
    "df_outliers_total\n",
    "{df_outliers_total}\n",
    "\n",
    "{\"-\"*100}\n",
    "df_resumen\n",
    "{df_resumen}\n",
    "{\"-\"*100}\n",
    "\"\"\")\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3a213a-5293-46f6-ad63-4cabc9e5b920",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar en Excel con manejo de fallo si no existe el engine\n",
    "try:\n",
    "    with pd.ExcelWriter(ruta_excel, engine='openpyxl') as writer:\n",
    "        try:\n",
    "            df_duplicados_total.to_excel(writer, index=False, sheet_name='duplicados')\n",
    "        except Exception:\n",
    "            pd.DataFrame().to_excel(writer, index=False, sheet_name='duplicados')\n",
    "        try:\n",
    "            df_outliers_total.to_excel(writer, index=False, sheet_name='outliers')\n",
    "        except Exception:\n",
    "            pd.DataFrame().to_excel(writer, index=False, sheet_name='outliers')\n",
    "        try:\n",
    "            df_resumen.to_excel(writer, index=False, sheet_name='resumen_filtros')\n",
    "        except Exception:\n",
    "            pd.DataFrame(lista_resumen).to_excel(writer, index=False, sheet_name='resumen_filtros')\n",
    "    guardado_ok = True\n",
    "except Exception as e_openpyxl:\n",
    "    mensajes.append('Error usando openpyxl: ' + str(e_openpyxl))\n",
    "    try:\n",
    "        with pd.ExcelWriter(ruta_excel) as writer:\n",
    "            df_duplicados_total.to_excel(writer, index=False, sheet_name='duplicados')\n",
    "            df_outliers_total.to_excel(writer, index=False, sheet_name='outliers')\n",
    "            df_resumen.to_excel(writer, index=False, sheet_name='resumen_filtros')\n",
    "        guardado_ok = True\n",
    "    except Exception as e_default:\n",
    "        mensajes.append('Error sin engine: ' + str(e_default))\n",
    "        try:\n",
    "            df_duplicados_total.to_csv(carpeta_reportes / 'duplicados.csv', index=False, encoding='utf-8')\n",
    "            df_outliers_total.to_csv(carpeta_reportes / 'outliers.csv', index=False, encoding='utf-8')\n",
    "            df_resumen.to_csv(carpeta_reportes / 'resumen_filtros.csv', index=False, encoding='utf-8')\n",
    "            mensajes.append('Se guardaron CSVs separados como fallback.')\n",
    "            guardado_ok = True\n",
    "        except Exception as e_csv:\n",
    "            mensajes.append('Error guardando CSV fallback: ' + str(e_csv))\n",
    "            guardado_ok = False\n",
    "\n",
    "print('Guardado OK:', guardado_ok)\n",
    "if mensajes:\n",
    "    print('Mensajes/Errores durante guardado:')\n",
    "    for m in mensajes:\n",
    "        print('-', m)\n",
    "print('Ruta final esperada del Excel (si guardado):', ruta_excel)\n",
    "print('Resumen por dataset:')\n",
    "print(df_resumen)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f43150b-eb7b-4ae8-a0a6-233f4b6ca5f1",
   "metadata": {},
   "source": [
    "ventas.csv  análisis de ventas, limpieza de datos y estadísticas descriptivas.\n",
    " \t\n",
    "clientes.csv  unirse a las ventas mediante el uso de funciones de combinación para analizar características de los clientes relacionados con sus \tcompras.\n",
    " \t\n",
    "marketing.csv analizar la efectividad de las campañas de marketing en las ventas y buscar correlaciones.\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4f5fcf9c-6140-4160-9ca0-ebf688f8c921",
   "metadata": {},
   "source": [
    "2) Claves candidatas para merge o concat\n",
    "\n",
    "Intersecciones observadas:\n",
    "\n",
    "ventas ∩ marketing → producto (clave natural para unir campañas con ventas por producto)\n",
    "\n",
    "ventas ∩ clientes → ninguna columna en común\n",
    "\n",
    "clientes ∩ marketing → ninguna columna en común\n",
    "\n",
    "Interpretación pedagógica:\n",
    "\n",
    "Puedes unir ventas con marketing por producto (p. ej. para ver qué canal promocionó qué producto y coste).\n",
    "\n",
    "No puedes unir directamente ventas con clientes porque ventas_limpio no contiene id_cliente ni email ni nombre_cliente. Para unir ventas↔clientes necesitas:\n",
    "\n",
    "que ventas_limpio tenga una columna id_cliente (recomendado), o\n",
    "\n",
    "un fichero/mapeo que vincule id_venta → id_cliente, o\n",
    "\n",
    "usar correspondencia por email/nombre (menos fiable) si esos campos existieran.\n",
    "\n",
    "3) Ejemplos de combinaciones útiles (casos prácticos)\n",
    "\n",
    "Ventas por canal de marketing (recomendado)\n",
    "\n",
    "Merge ventas_limpio ⟵ marketing_limpio por producto (left join): asignás a cada venta el canal y id_campanha. Luego agrupás por canal para métricas.\n",
    "\n",
    "Análisis de ticket promedio por categoría y canal\n",
    "\n",
    "Después del merge anterior, crear monto = precio * cantidad y agrupar por categoria y canal.\n",
    "\n",
    "Concatenación (vertical)\n",
    "\n",
    "Si tuvieras varios archivos de ventas de distintos periodos: pd.concat([ventas_periodo1, ventas_periodo2], axis=0).\n",
    "\n",
    "Unir clientes (si se dispone de id_cliente en ventas)\n",
    "\n",
    "ventas_limpio.merge(clientes_limpio, on='id_cliente', how='left') → permite segmentar ventas por edad, ciudad, ingresos.\n",
    "\n",
    "Si no hay id_cliente en ventas\n",
    "\n",
    "Crear un mapping table (archivo) que contenga id_venta → id_cliente y hacer merge por esa tabla.\n",
    "\n",
    "4) Código limpio en pandas (listo para ejecutar — adaptá nombres de columnas si quieres otro comportamiento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93885b49-e04a-401c-9c03-78439696cdbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 3) Tipos y limpiezas básicas\n",
    "ventas['fecha_venta'] = pd.to_datetime(ventas['fecha_venta'], errors='coerce')\n",
    "marketing['fecha_inicio'] = pd.to_datetime(marketing['fecha_inicio'], errors='coerce')\n",
    "marketing['fecha_fin'] = pd.to_datetime(marketing['fecha_fin'], errors='coerce')\n",
    "\n",
    "# Asegurar numéricos\n",
    "ventas['precio'] = pd.to_numeric(ventas['precio'], errors='coerce')\n",
    "ventas['cantidad'] = pd.to_numeric(ventas['cantidad'], errors='coerce')\n",
    "clientes['ingresos'] = pd.to_numeric(clientes['ingresos'], errors='coerce')\n",
    "marketing['costo'] = pd.to_numeric(marketing['costo'], errors='coerce')\n",
    "\n",
    "# 4) Crear columnas útiles\n",
    "ventas['monto'] = ventas['precio'] * ventas['cantidad']\n",
    "\n",
    "# 5) Merge ejemplo: ventas + marketing por 'producto' (asignar canal a cada venta)\n",
    "ventas_marketing = pd.merge(\n",
    "    ventas,\n",
    "    marketing[['producto', 'id_campanha', 'canal', 'costo', 'fecha_inicio', 'fecha_fin']],\n",
    "    on='producto',\n",
    "    how='left',   # left para conservar todas las ventas aunque no tengan campana asociada\n",
    "    validate='m:1'  # opcional: espera muchos registros ventas para 1 campaña por producto\n",
    ")\n",
    "\n",
    "# 6) Agregados: ventas por canal\n",
    "ventas_por_canal = (\n",
    "    ventas_marketing\n",
    "    .groupby('canal', dropna=False)\n",
    "    .agg(\n",
    "        total_monto=('monto', 'sum'),\n",
    "        cantidad_transacciones=('monto', 'count'),\n",
    "        ticket_promedio=('monto', 'mean')\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# 7) Agregado: ventas por categoria y canal\n",
    "ventas_categoria_canal = (\n",
    "    ventas_marketing\n",
    "    .groupby(['categoria', 'canal'], dropna=False)\n",
    "    .agg(\n",
    "        total_monto     = ('monto', 'sum'),\n",
    "        transacciones   = ('monto', 'count'),\n",
    "        ticket_promedio = ('monto', 'mean')\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# 8) Guardar resultados (opcional)\n",
    "ventas_por_canal.to_csv('/mnt/data/ventas_por_canal.csv', index=False)\n",
    "ventas_categoria_canal.to_csv('/mnt/data/ventas_categoria_canal.csv', index=False)\n",
    "\n",
    "# 9) ¿Y clientes? Si tienes id_cliente en ventas:\n",
    "# ventas_con_clientes = ventas.merge(clientes, on='id_cliente', how='left')\n",
    "\n",
    "# 10) Checks útiles\n",
    "# - Ver duplicados en claves: ventas['id_venta'].duplicated().sum()\n",
    "# - Ver clientes sin ventas: clientes[~clientes['id_cliente'].isin(ventas.get('id_cliente', []))]\n",
    "\n",
    "Recomendaciones prácticas (breves, accionables)\n",
    "\n",
    "Si querés unir ventas con clientes agregá id_cliente a ventas_limpio (registro en punto de venta o mapeo).\n",
    "\n",
    "Revisá duplicados en producto dentro de marketing (puede haber varias campañas por producto: decidir estrategia — por ejemplo filtrar la campaña activa por fecha).\n",
    "\n",
    "Elegí tipo de join con criterio pedagógico:\n",
    "\n",
    "left join para preservar todas las ventas (evitar perder datos).\n",
    "\n",
    "inner join si sólo te interesa el subset con campaña asociada.\n",
    "\n",
    "Creá fecha de periodo (día/semana/mes) para series temporales: ventas['mes'] = ventas['fecha_venta'].dt.to_period('M').\n",
    "\n",
    "Documentá supuestos: por qué usás how='left', cómo tratás ventas sin campaña, cómo imputás nulos en precio/cantidad.\n",
    "\n",
    "Ejemplo aplicado (interpretación cotidiana)\n",
    "\n",
    "Imaginá a Juan, vendedor en una pyme familiar con 2 hijos. Quiere saber si la campaña en Instagram está trayendo ventas: con el merge ventas + marketing por producto obtiene canal asignado a cada venta. Luego agrupa por canal y ve: “Instagram” tiene muchas visitas pero ticket promedio bajo — decisión: ajustar oferta o dirigir una campaña de cross-sell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40448d5e-62bf-4d58-9c5c-28da021964b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "a mano\n",
    "ver que es lo que falta en drop na\n",
    "precios == 0 buscar en categoria el producto o promedo si no hay otro dato\n",
    "duplicate si el id es =\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21ab2c8-5a03-4fe6-9f02-60d2dc73d966",
   "metadata": {},
   "outputs": [],
   "source": [
    "productos mas vendidos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0737e69-7b61-4fa9-b678-3a178e09b62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ventas por mes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d1d542-093a-49ad-b788-5e1b23af562d",
   "metadata": {},
   "outputs": [],
   "source": [
    "git remote set-url origin https://github.com/CursosAGT/nombre-nuevo.git\n",
    "git push -u origin main\n",
    "https://github.com/CursosAGT/-GarciaTrabaArielH-Comisi-n25262-TPI_Data_Analytics/blob/main/Garcia%20Traba%20Ariel%20H%20-%20Comisi%C3%B3n%2025262%20-%20TPI%20Data%20Analytics.ipynb\n",
    "Garcia Traba Ariel H - Comisión 25262 - TPI Data Analytics.ipynb\n",
    "https://github.com/CursosAGT/-GarciaTrabaArielH-Comisi-n25262-TPI_Data_Analytics/blob/main/datasets_entrada/clientes.csv\n",
    "https://github.com/CursosAGT/-GarciaTrabaArielH-Comisi-n25262-TPI_Data_Analytics/blob/main/datasets_entrada/marketing.csv\n",
    "https://github.com/CursosAGT/-GarciaTrabaArielH-Comisi-n25262-TPI_Data_Analytics/blob/main/datasets_entrada/ventas.csv.csv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
