{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cedbb1b4",
   "metadata": {},
   "source": [
    "\n",
    "<div style=\"background-color:#CCCCCC; padding:12px; border-radius:8px;\">\n",
    "<h1 style=\"color:#003366; text-align:center; margin:8px 0;\">Revisión y limpieza de 3 DataFrames (TPI - Data Analytics)</h1>\n",
    "<p style=\"text-align:center; color:#003366; margin:0;\"><em>Notebook docente en castellano — nombres descriptivos en snake_case — código y documentación</em></p>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c723b86a",
   "metadata": {},
   "source": [
    "\n",
    "<div style=\"background-color:#CCCCCC; padding:10px; border-radius:6px;\">\n",
    "<h2 style=\"color:black; text-align:center; margin-top:6px;\">Resumen</h2>\n",
    "\n",
    "<p style=\"color:black;\">\n",
    "Este notebook está diseñado con finalidades pedagógicas. Revisa, normaliza y valida tres datasets contenidos en CSV:\n",
    "</p>\n",
    "\n",
    "<ul style=\"color:black;\">\n",
    "<li><code>marketing.csv</code> → variable: <code>df_marketing</code></li>\n",
    "<li><code>ventas.csv</code>    → variable: <code>df_ventas</code></li>\n",
    "<li><code>clientes.csv</code>  → variable: <code>df_clientes</code></li>\n",
    "</ul>\n",
    "\n",
    "<p style=\"color:black;\">\n",
    "Coloca los CSV en <code>/content/drive/MyDrive/CABA/Garcia Traba Ariel H - Comisión 25262 - TPI Data Analytics/</code> \n",
    "    en <code>/datasets_entrada/</code>. El notebook busca primero en google drive y si no encuentra, usa <code>localhost (127.0.0.1)</code> (útil para entornos donde los archivos están pre-subidos).\n",
    "</p>\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be46fb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports y configuración inicial (nombres en castellano)\n",
    "import os, re, json, unicodedata\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from colorama import *\n",
    "from math import isnan\n",
    "import zipfile\n",
    "from collections import defaultdict\n",
    "import argparse\n",
    "import pandas as pd\n",
    "from pandas.api.types import is_numeric_dtype\n",
    "import numpy as np\n",
    "from typing import Dict, Any, Optional\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63edff5b-828e-4254-a4d7-4b0ef05ecea6",
   "metadata": {},
   "source": [
    "## 1- Crear un documento en Google Colaboratory y cargar los sets de datos como DataFrames."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddfa535f-ef52-4f49-9d1b-e70dd8d5ad27",
   "metadata": {},
   "source": [
    "si se usa en disco local comentarla celda de debajo (JuPyteR , VSC, ATOM, Spider, Geany, etc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "144444b3-1dc1-4f3f-a621-025d1cdb6465",
   "metadata": {},
   "source": [
    "# 1ra parte Definición de ETL\n",
    "ETL es un conjunto de procedimientos que permiten mover datos desde sistemas de origen, que pueden ser bases de datos, archivos o fuentes en la nube, hasta un sistema de destino como un data warehouse o data lake, realizando previamente procesos de limpieza, estructuración y organización de los datos para hacerlos aptos para análisis.​\n",
    "\n",
    "## Fases del proceso ETL\n",
    "Extracción: Consiste en recopilar datos relevantes de diferentes fuentes, asegurando que el impacto en los sistemas origen sea mínimo. Los datos pueden extraerse mediante diversos métodos como consultas SQL o servicios web.​\n",
    "\n",
    "Transformación: En esta etapa, los datos se limpian y se ajustan para garantizar coherencia y calidad, incluyendo la eliminación de valores nulos, normalización y conversión a formatos consistentes, además de aplicar reglas específicas de negocio.\n",
    "\n",
    "Carga: Finalmente, los datos transformados se cargan en el sistema de destino, donde estarán disponibles para análisis, informes o modelado de datos.\n",
    "\n",
    "## Importancia del ETL\n",
    "Es crucial en la minería de datos porque preparar los datos brutos para que puedan ser utilizados en análisis estadísticos, modelados predictivos o técnicas de aprendizaje automático, asegurando la calidad, coherencia y accesibilidad de la información."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c8f6200-1ad0-4fa8-9cf1-aa1df22c4b3b",
   "metadata": {},
   "source": [
    "## 1.1 - Crear estructura de directorios segun modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e60a16a-d97c-4f77-bc49-2a5f668a1dff",
   "metadata": {},
   "source": [
    "## 1.2 -Carga de fuente de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "605182b8-9652-410e-8c79-13b10a33e692",
   "metadata": {},
   "outputs": [],
   "source": [
    "def carga_rutas():\n",
    "    global carpeta_entrada,carpeta_datasets_entrada,carpeta_datasets_salida,carpeta_reportes,carpeta_limpios\n",
    "    #archivo_ventas,archivo_clientes,archivo_marketing\n",
    "    try: \n",
    "        carpeta_entrada = Path(ruta_base)\n",
    "        carpeta_datasets_entrada   = carpeta_entrada / 'datasets_entrada'\n",
    "            \n",
    "        carpeta_datasets_salida   = carpeta_entrada / 'datasets_salida'\n",
    "        carpeta_datasets_salida.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        carpeta_reportes   = carpeta_datasets_salida / 'reportes'\n",
    "        carpeta_reportes.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        carpeta_limpios    = carpeta_datasets_salida / 'limpios'\n",
    "        carpeta_limpios.mkdir(parents=True, exist_ok=True)\n",
    "    except Exception as e:\n",
    "        print(f\"\"\"{Fore.WHITE+Back.RED}\n",
    "        {e}\"\"\")\n",
    "        exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d0eefb1-d4fd-48f5-9f68-babde9025894",
   "metadata": {},
   "source": [
    "# 2- Realizar un script básico que calcule las ventas mensuales utilizando variables y operadores."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a31ab95-6764-4904-8f26-992504d7ca18",
   "metadata": {},
   "source": [
    "### 2.1 Desde python sin librerias pandas / polars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf9ed364-452d-4588-8435-6349e03c90e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "archivo_ventas     = 'ventas.csv'\n",
    "archivo_clientes   = 'clientes.csv'\n",
    "archivo_marketing  = 'marketing.csv'\n",
    "archivos= {\n",
    "            archivo_ventas     : 'ventas.csv',\n",
    "            archivo_clientes   : 'clientes.csv',\n",
    "            archivo_marketing  : 'marketing.csv'   \n",
    "        }\n",
    "dic_dfs = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "076f3944-731b-4f8b-8bbb-3a9e34dfe1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from collections import defaultdict\n",
    "dic_dfs = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c4472bd-915b-4c06-9c2d-9813b49a11a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv_to_table(ruta, encoding='utf-8', delimiter=','):\n",
    "    \"\"\"\n",
    "    Helper: lee un CSV y devuelve una estructura tipo \"mini-DataFrame\" sin pandas.\n",
    "    Retorna dict con keys: rows, cols, nrows, ncols, columns\n",
    "    \"\"\"\n",
    "    if not os.path.isfile(ruta):\n",
    "        raise FileNotFoundError(f\"Archivo no encontrado: {ruta}\")\n",
    "\n",
    "    with open(ruta, newline='', encoding=encoding) as f:\n",
    "        reader = csv.DictReader(f, delimiter=delimiter)\n",
    "        columns = reader.fieldnames or []\n",
    "        rows = [row for row in reader]\n",
    "\n",
    "    # construir columnas como listas\n",
    "    cols = defaultdict(list)\n",
    "    for row in rows:\n",
    "        for col in columns:\n",
    "            cols[col].append(row.get(col, ''))\n",
    "\n",
    "    # si hay header pero 0 filas, crear listas vacías para cada columna\n",
    "    if not rows and columns:\n",
    "        for col in columns:\n",
    "            cols[col] = []\n",
    "\n",
    "    return {\n",
    "        'rows': rows,\n",
    "        'cols': dict(cols),\n",
    "        'nrows': len(rows),\n",
    "        'ncols': len(columns),\n",
    "        'columns': columns\n",
    "    }\n",
    "\n",
    "def carga_de_datos_sin_pandas():\n",
    "    \"\"\"\n",
    "    Carga 3 CSV (ventas, clientes, marketing) SIN usar pandas/numpy.\n",
    "    Usa las variables globales:\n",
    "      - carpeta_datasets_entrada\n",
    "      - archivo_ventas, archivo_clientes, archivo_marketing\n",
    "    PISA la variable global dic_dfs con la estructura:\n",
    "      { \"df_ventas\": {...}, \"df_clientes\": {...}, \"df_marketing\": {...} }\n",
    "    \"\"\"\n",
    "    global dic_dfs\n",
    "    dic_dfs = {}  # pisamos lo anterior\n",
    "\n",
    "    encoding = 'utf-8'\n",
    "    delimiter = ','\n",
    "\n",
    "    # asegurar que las variables globales existan\n",
    "    required_globals = ['carpeta_datasets_entrada', 'archivo_ventas', 'archivo_clientes', 'archivo_marketing']\n",
    "    missing = [g for g in required_globals if g not in globals()]\n",
    "    if missing:\n",
    "        raise RuntimeError(f\"Faltan variables globales requeridas: {missing}\")\n",
    "\n",
    "    # Mapear nombres a archivos (mantenemos la convención 'df_ventas' para compatibilidad)\n",
    "    archivos = {\n",
    "        'df_ventas':   globals()['archivo_ventas'],\n",
    "        'df_clientes': globals()['archivo_clientes'],\n",
    "        'df_marketing':globals()['archivo_marketing']\n",
    "    }\n",
    "\n",
    "    print(f\"{Fore.WHITE+Back.BLUE}\\n╔════════════════════════════════════════════════════╗\")\n",
    "    print(\"║            CARGA DE DATOS (SIN PANDAS)             ║\")\n",
    "    print(\"╚════════════════════════════════════════════════════╝\" + Style.RESET_ALL)\n",
    "\n",
    "    for nombre_key, archivo in archivos.items():\n",
    "        ruta = os.path.join(globals()['carpeta_datasets_entrada'], archivo)\n",
    "        print(f\"\\nLeyendo -> {nombre_key}  |  Archivo: {ruta}\")\n",
    "\n",
    "        if not os.path.isfile(ruta):\n",
    "            print(f\"{Fore.RED}✖ Archivo no encontrado: {ruta}  -> se crea entrada vacía{Style.RESET_ALL}\")\n",
    "            dic_dfs[nombre_key] = {\n",
    "                'rows': [],\n",
    "                'cols': {},\n",
    "                'nrows': 0,\n",
    "                'ncols': 0,\n",
    "                'columns': []\n",
    "            }\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            tabla = read_csv_to_table(ruta, encoding=encoding, delimiter=delimiter)\n",
    "            dic_dfs[nombre_key] = tabla\n",
    "            print(f\"{Fore.GREEN}✔ {nombre_key}: {tabla['nrows']} filas, {tabla['ncols']} columnas{Style.RESET_ALL}\")\n",
    "        except Exception as e:\n",
    "            print(f\"{Fore.RED}✖ Error leyendo {ruta}: {e}{Style.RESET_ALL}\")\n",
    "            dic_dfs[nombre_key] = {\n",
    "                'rows': [],\n",
    "                'cols': {},\n",
    "                'nrows': 0,\n",
    "                'ncols': 0,\n",
    "                'columns': []\n",
    "            }\n",
    "\n",
    "    # Validación rápida de columnas (para orientar joins/merges)\n",
    "    print(\"\\nValidación rápida de columnas entre datasets:\")\n",
    "    pairs = [('df_ventas','df_marketing'), ('df_ventas','df_clientes'), ('df_clientes','df_marketing')]\n",
    "    for a,b in pairs:\n",
    "        cols_a = set(dic_dfs.get(a, {}).get('columns', []))\n",
    "        cols_b = set(dic_dfs.get(b, {}).get('columns', []))\n",
    "        inter = cols_a.intersection(cols_b)\n",
    "        if inter:\n",
    "            muestra = sorted(list(inter))[:10]\n",
    "            print(f\" → {a} ∩ {b} : {len(inter)} columnas en común -> {muestra}{'...' if len(inter)>10 else ''}\")\n",
    "        else:\n",
    "            print(f\" → {a} ∩ {b} : 0 columnas en común\")\n",
    "\n",
    "    print(f\"\\n{Fore.WHITE+Back.BLUE}╚════════════════════════════════════════════════════╝{Style.RESET_ALL}\")\n",
    "    print(\"Carga finalizada. `dic_dfs` ha sido pisado con estructuras tipo tabla (sin pandas).\")\n",
    "    return \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f234b5-539a-4328-8beb-f0cffbd8320c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ffa6027-ea9a-4ae2-b0b1-594dcc4516ff",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Faltan variables globales requeridas: ['carpeta_datasets_entrada']",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mcarga_de_datos_sin_pandas\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Acceder al DataFrame \"ventas\" como lista de filas:\u001b[39;00m\n\u001b[32m      4\u001b[39m primeras_filas_ventas = dic_dfs[\u001b[33m'\u001b[39m\u001b[33mventas\u001b[39m\u001b[33m'\u001b[39m][\u001b[33m'\u001b[39m\u001b[33mrows\u001b[39m\u001b[33m'\u001b[39m][:\u001b[32m5\u001b[39m]\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 52\u001b[39m, in \u001b[36mcarga_de_datos_sin_pandas\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     50\u001b[39m missing = [g \u001b[38;5;28;01mfor\u001b[39;00m g \u001b[38;5;129;01min\u001b[39;00m required_globals \u001b[38;5;28;01mif\u001b[39;00m g \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mglobals\u001b[39m()]\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m missing:\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFaltan variables globales requeridas: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmissing\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     54\u001b[39m \u001b[38;5;66;03m# Mapear nombres a archivos (mantenemos la convención 'df_ventas' para compatibilidad)\u001b[39;00m\n\u001b[32m     55\u001b[39m archivos = {\n\u001b[32m     56\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mdf_ventas\u001b[39m\u001b[33m'\u001b[39m:   \u001b[38;5;28mglobals\u001b[39m()[\u001b[33m'\u001b[39m\u001b[33marchivo_ventas\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m     57\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mdf_clientes\u001b[39m\u001b[33m'\u001b[39m: \u001b[38;5;28mglobals\u001b[39m()[\u001b[33m'\u001b[39m\u001b[33marchivo_clientes\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m     58\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mdf_marketing\u001b[39m\u001b[33m'\u001b[39m:\u001b[38;5;28mglobals\u001b[39m()[\u001b[33m'\u001b[39m\u001b[33marchivo_marketing\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     59\u001b[39m }\n",
      "\u001b[31mRuntimeError\u001b[39m: Faltan variables globales requeridas: ['carpeta_datasets_entrada']"
     ]
    }
   ],
   "source": [
    "carga_de_datos_sin_pandas()\n",
    "\n",
    "# Acceder al DataFrame \"ventas\" como lista de filas:\n",
    "primeras_filas_ventas = dic_dfs['ventas']['rows'][:5]\n",
    "\n",
    "# Acceder a la columna 'producto' como lista:\n",
    "productos = dic_dfs['ventas']['cols'].get('producto', [])\n",
    "\n",
    "# Ejemplo: contar cuántas veces aparece 'Leche entera' sin pandas\n",
    "producto_buscado = 'Leche entera'\n",
    "conteo = sum(1 for v in productos if v == producto_buscado)\n",
    "print(f\"La familia compró '{producto_buscado}' {conteo} veces en el dataset de ventas.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "028e9d18-ebfb-4aea-b8c3-990e1a3b13fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e45bc1cc-1cb0-44ea-aefc-ba8e15de0b17",
   "metadata": {},
   "source": [
    "# 3- Estructuras de Datos: Desarrollar un programa que almacene los datos de ventas (producto, precio, cantidad). Decidir si conviene utilizar diccionarios o listas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2653049b-2c46-4cfe-9171-5b70df53da09",
   "metadata": {},
   "outputs": [],
   "source": [
    "for nombre,valores in dic_dfs.items():\n",
    "    print (f\"\"\"{nombre}\n",
    "    {valores}\"\"\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f1e3ac1c-c680-4a7c-ba06-bd7c35c28749",
   "metadata": {},
   "source": [
    "exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2250b37-ec4d-43f2-a1bb-528ddf288c8e",
   "metadata": {},
   "source": [
    "# 4- Introducción a Pandas: realizar un análisis exploratorio inicial de los DataFrames."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4225f2e7-fccf-4a13-86a6-92acee434aa7",
   "metadata": {},
   "source": [
    "## 4.1.2 Desde python con librerias pandas / polars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "052e6d76-d227-4749-af2c-f065eabf82f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def carga_de_datos():\n",
    "    global dic_dfs\n",
    "    print(\"Cargando datasets del curso...\")\n",
    "    try:\n",
    "        ruta_ventas     = os.path.join(carpeta_datasets_entrada, archivo_ventas)\n",
    "        ruta_clientes   = os.path.join(carpeta_datasets_entrada, archivo_clientes)\n",
    "        ruta_marketing  = os.path.join(carpeta_datasets_entrada, archivo_marketing)\n",
    "        \n",
    "        df_ventas       = pd.read_csv(f\"{ruta_ventas}\")\n",
    "        df_clientes     = pd.read_csv(f\"{ruta_clientes}\")\n",
    "        df_marketing    = pd.read_csv(f\"{ruta_marketing}\")\n",
    "        dic_dfs = { \"df_ventas\"   : df_ventas,\n",
    "                    \"df_clientes\" : df_clientes,\n",
    "                    \"df_marketing\": df_marketing}\n",
    "        print (\"...Arhivos cargados con exito!!!\")\n",
    "    except FileNotFoundError:\n",
    "        print(\"Archivos no encontrados en:\", carpeta_datasets_entrada)\n",
    "        exit()\n",
    "    except pd.errors.EmptyDataError:\n",
    "        print(\"Archivo vacío detectado\")\n",
    "        exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db39080-2749-457a-848f-5e618de4786d",
   "metadata": {},
   "source": [
    "### 4.1.3 rutas y carga de los dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "164ce6c2-bdd6-4eaf-97a3-1b81cc0096f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[37m\u001b[44m\n",
      "╔═════════════════════════════════════════════════════════════════════════════╗\n",
      "║                      Datos en ámbito Google Drive                           ║\n",
      "╚═════════════════════════════════════════════════════════════════════════════╝\u001b[0m\n",
      "Requirement already satisfied: google in c:\\python312\\lib\\site-packages (3.0.0)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\python312\\lib\\site-packages (from google) (4.13.5)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\python312\\lib\\site-packages (from beautifulsoup4->google) (2.8)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in c:\\python312\\lib\\site-packages (from beautifulsoup4->google) (4.15.0)\n",
      "\u001b[37m\u001b[41m\n",
      "╔═════════════════════════════════════════════════════════════════════════════╗\n",
      "║                          Google Drive NO cargado                            ║\n",
      "║                           No module named 'google'                          ║\n",
      "╚═════════════════════════════════════════════════════════════════════════════╝\u001b[0m\n",
      "\u001b[37m\u001b[44m\n",
      "╔═════════════════════════════════════════════════════════════════════════════╗\n",
      "║                          Datos en ámbito local                              ║\n",
      "╚═════════════════════════════════════════════════════════════════════════════╝\u001b[0m\n",
      "ruta_base='./'\n",
      "carpeta_entrada=WindowsPath('.')\n",
      "**************************************************\n",
      "Cargando datasets del curso...\n",
      "...Arhivos cargados con exito!!!\n",
      "\u001b[37m\u001b[42m\n",
      "╔═════════════════════════════════════════════════════════════════════════════╗\n",
      "║                        ámbito local cargado con exito                       ║\n",
      "╚═════════════════════════════════════════════════════════════════════════════╝\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "def carga_fuente_de_datos():\n",
    "    global ruta_base, archivo_ventas, archivo_clientes,archivo_marketing\n",
    "    archivo_ventas     = 'ventas.csv'\n",
    "    archivo_clientes   = 'clientes.csv'\n",
    "    archivo_marketing  = 'marketing.csv'\n",
    "    #################################################################################\n",
    "    try: \n",
    "        print(f\"\"\"{Fore.WHITE+Back.BLUE}\n",
    "╔═════════════════════════════════════════════════════════════════════════════╗\n",
    "║                      Datos en ámbito Google Drive                           ║\n",
    "╚═════════════════════════════════════════════════════════════════════════════╝{Style.RESET_ALL}\"\"\")\n",
    "        # Montar tu Google Drive\n",
    "        !pip install google\n",
    "        from google.colab import drive\n",
    "        drive.mount('/content/drive')\n",
    "        !ls \"/content/drive/MyDrive/CABA/Garcia Traba Ariel H - Comisión 25262 - TPI Data Analytics/\"\n",
    "        # Ruta del archivo (ajústala a la carpeta real en tu Drive)\n",
    "        ruta_base = \"/content/drive/MyDrive/CABA/Garcia Traba Ariel H - Comisión 25262 - TPI Data Analytics/\"\n",
    "        carga_rutas()\n",
    "        if not os.path.exists(ruta_base):\n",
    "            raise FileNotFoundError(f\"La carpeta especificada no existe: {ruta_base}\")\n",
    "        carga_de_datos()\n",
    "        print(f\"\"\"{Fore.WHITE+Back.BLUE}\n",
    "╔═════════════════════════════════════════════════════════════════════════════╗\n",
    "║                      Google Drive cargado con exito                         ║\n",
    "╚═════════════════════════════════════════════════════════════════════════════╝{Style.RESET_ALL}\"\"\")\n",
    "        return\n",
    "    except Exception as e:\n",
    "        print(f\"\"\"{Fore.WHITE+Back.RED}\n",
    "╔═════════════════════════════════════════════════════════════════════════════╗\n",
    "║                          Google Drive NO cargado                            ║\n",
    "║{str(e).center(77)}║\n",
    "╚═════════════════════════════════════════════════════════════════════════════╝{Style.RESET_ALL}\"\"\")\n",
    "    #################################################################################\n",
    "    try:\n",
    "        print(f\"\"\"{Fore.WHITE+Back.BLUE}\n",
    "╔═════════════════════════════════════════════════════════════════════════════╗\n",
    "║                          Datos en ámbito local                              ║\n",
    "╚═════════════════════════════════════════════════════════════════════════════╝{Style.RESET_ALL}\"\"\")\n",
    "        ruta_base = \"./\"\n",
    "        print (f\"{ruta_base=}\")\n",
    "        carga_rutas()\n",
    "        print (f\"{carpeta_entrada=}\")\n",
    "        print (\"*\"*50)\n",
    "        if not os.path.exists(ruta_base):\n",
    "            raise FileNotFoundError(f\"La carpeta especificada no existe: {ruta_base}\")\n",
    "        carga_de_datos()\n",
    "        print(f\"\"\"{Fore.WHITE+Back.GREEN}\n",
    "╔═════════════════════════════════════════════════════════════════════════════╗\n",
    "║                        ámbito local cargado con exito                       ║\n",
    "╚═════════════════════════════════════════════════════════════════════════════╝{Style.RESET_ALL}\"\"\")\n",
    "        return\n",
    "    except Exception as e:\n",
    "        print(f\"\"\"{Fore.WHITE+Back.RED}\n",
    "╔═════════════════════════════════════════════════════════════════════════════╗\n",
    "║                         ámbito local  NO cargado                            ║\n",
    "║{str(e).center(77)}║\n",
    "╚═════════════════════════════════════════════════════════════════════════════╝{Style.RESET_ALL}\"\"\")\n",
    "    #################################################################################\n",
    "    '''\n",
    "    try:\n",
    "        print(f\"\"\"{Fore.WHITE+Back.BLUE}\n",
    "╔═════════════════════════════════════════════════════════════════════════════╗\n",
    "║                          Datos en ámbito github                             ║\n",
    "╚═════════════════════════════════════════════════════════════════════════════╝{Style.RESET_ALL}\"\"\")\n",
    "        ruta_base = \"https://github.com/CursosAGT/-GarciaTrabaArielH-Comisi-n25262-TPI_Data_Analytics/tree/main/datasets_salida/limpios\"\n",
    "        carga_rutas()\n",
    "        if not os.path.exists(ruta_base):\n",
    "            raise FileNotFoundError(f\"La carpeta especificada no existe: {ruta_base}\")\n",
    "        carga_de_datos()  \n",
    "        print(f\"\"\"{Fore.WHITE+Back.GREEN}\n",
    "╔═════════════════════════════════════════════════════════════════════════════╗\n",
    "║                        ámbito github cargado con exito                      ║\n",
    "╚═════════════════════════════════════════════════════════════════════════════╝{Style.RESET_ALL}\"\"\")\n",
    "        return\n",
    "    except Exception as e:\n",
    "        print(f\"\"\"{Fore.WHITE+Back.RED}\n",
    "╔═════════════════════════════════════════════════════════════════════════════╗\n",
    "║                         ámbito github NO cargado                            ║\n",
    "║{str(e).center(77)}║\n",
    "╚═════════════════════════════════════════════════════════════════════════════╝{Style.RESET_ALL}\"\"\")\n",
    "    '''\n",
    "    #################################################################################\n",
    "    print(f\"\"\"{Fore.WHITE+Back.RED}\n",
    "╔═════════════════════════════════════════════════════════════════════════════╗\n",
    "║                  No se encontraron los datos básicos (CSV)                  ║\n",
    "║                  No se puede continuar                                      ║\n",
    "╚═════════════════════════════════════════════════════════════════════════════╝{Style.RESET_ALL}\"\"\")\n",
    "    exit()\n",
    "carga_fuente_de_datos()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86754f0-a78b-453c-9127-5abd20e1877d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876facae-5d32-47aa-8b55-d9b04deadb85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6e91d4ff-4465-4ec3-b5e1-29f5d4cc0277",
   "metadata": {},
   "source": [
    "### 4.1.3 Estructura de parámetros "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "895c63d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Proceso principal para los 3 CSV ----------\n",
    "desviacion_margen     = 1.5\n",
    "desviacion_umbral     = 3.0\n",
    "cantidad_duplicados   = 0\n",
    "reportes_creados      = []\n",
    "ruta_excel            = carpeta_reportes / 'reporte_limpieza.xlsx'\n",
    "guardado_ok           = False\n",
    "mensajes              = []\n",
    "TOKENS_VALOR_FALTANTE = {'na', 'n/a', 'null', 'none', 'sin dato', 's/d', 'nd', '-', '--', '?', 'sin_dato', 'n/d'}\n",
    "\n",
    "\n",
    "reglas= {\n",
    "            \"df_marketing\" : {\n",
    "                                'producto':     {'string' : {'tipo': 'lower', 'normalizar_acentos': True}},\n",
    "                                'canal':        {'string' : {'tipo': 'upper', 'normalizar_acentos': True}},\n",
    "                                'costo':        {'numeric': {'as_int': False}},\n",
    "                                'fecha_inicio': {'date'   : {'dayfirst': True, 'formats': ['%d/%m/%Y', '%Y-%m-%d']}},\n",
    "                                'fecha_fin':    {'date'   : {'dayfirst': True, 'formats': ['%d/%m/%Y', '%Y-%m-%d']}}\n",
    "                                },\n",
    "            # id_venta, producto, precio, cantidad, fecha_venta, categoria\n",
    "            \"df_ventas\" : {\n",
    "                                'producto':     {'string' : {'tipo': 'lower', 'normalizar_acentos': True}},\n",
    "                                'precio':       {'numeric': {'as_int': False}},\n",
    "                                'cantidad':     {'numeric': {'as_int': False}},\n",
    "                                'fecha_venta':  {'date'   : {'dayfirst': True, 'formats': ['%d/%m/%Y', '%Y-%m-%d']}},\n",
    "                                'categoria':    {'string' : {'tipo': 'lower', 'normalizar_acentos': True}}\n",
    "                            },\n",
    "            # id_cliente, nombre, edad, ciudad, ingresos\n",
    "            \"df_clientes\" : {\n",
    "                                'nombre':       {'string'  : {'tipo': 'title', 'normalizar_acentos': True}},\n",
    "                                'edad':         {'numeric' : {'as_int': True}},\n",
    "                                'ciudad':       {'string'  : {'tipo': 'title', 'normalizar_acentos': True}},\n",
    "                                'ingresos':     {'numeric' : {'as_int': False}}\n",
    "                            }\n",
    "    }\n",
    "reglas_por_archivo = {\n",
    "    'ventas.csv':    reglas[\"df_ventas\"],\n",
    "    'clientes.csv':  reglas[\"df_clientes\"],\n",
    "    'marketing.csv': reglas[\"df_marketing\"]\n",
    "}\n",
    "\n",
    "#zip_path = carpeta_reportes.parent / 'reports_dataset_tpi_v2.zip'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "731f35b3-99e0-43cb-8085-2ab7da9c9692",
   "metadata": {},
   "source": [
    "### 4.1.4 ETL "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a06a6528-ba7e-4f2c-889a-5d428f5a1cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar el DataFrame\n",
    "def ver(df :pd.DataFrame,nombre_df =\"\"):\n",
    "    print(f\"\"\"{Fore.WHITE+Back.BLUE}\n",
    "╔═════════════════════════════════════════════════════════════════════════════╗\n",
    "║                            E.T.L.:  {nombre_df.center(20)}                    ║\n",
    "╚═════════════════════════════════════════════════════════════════════════════╝{Style.RESET_ALL}\n",
    "        Descripción preliminar:\n",
    "        {df.describe()}\n",
    "        Dimensiones:      { df.ndim}\n",
    "        Forma:            { df.shape}\n",
    "                filas:    {df.shape[0]}\n",
    "                Número de elementos:{ df.size}\n",
    "                Nombres de filas:{ df.index}\n",
    "                columnas: {df.shape[1]}\n",
    "                Nombres de columnas:{ df.columns}\n",
    "        Valores nulos:    {df.isna().sum().to_dict()}\n",
    "        Valores duplicados:{int(df.duplicated(keep=False).sum())}\n",
    "        Tipos de datos:\\n{ df.dtypes}\n",
    "        Primeras 7 filas:\\n{ df.head(7)}\n",
    "        Últimas 3 filas:\\n{ df.tail(3)}\n",
    "    {\"*\"*50}\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22cc5348-7574-4e16-8608-44d2a221fb0a",
   "metadata": {},
   "source": [
    "### 4.1.4 Valores faltantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f4aefb8b-3e14-4917-9986-8b7f27033cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def es_valor_faltante(serie,nombre_serie,nombre_df):\n",
    "    \"\"\"\n",
    "    Determina si los valores de una serie deben considerarse faltantes.\n",
    "    \n",
    "    Parámetros:\n",
    "        serie (pd.Series): columna de pandas a evaluar.\n",
    "    \n",
    "    Retorna:\n",
    "        dict:\n",
    "            'mask' -> pd.Series booleana (True si el valor es faltante)\n",
    "            'valores_faltantes' -> lista de valores detectados como faltantes\n",
    "    \"\"\"\n",
    "    serie_limpia = serie.astype(str).str.strip().str.lower()\n",
    "    mask = serie.isna() | serie_limpia.isin(TOKENS_VALOR_FALTANTE)\n",
    "    \n",
    "    # Extraemos los valores faltantes con su índice\n",
    "    valores_detectados = serie[mask]\n",
    "    \n",
    "    if not valores_detectados.empty:\n",
    "        print(f\"\"\"{Fore.WHITE+Back.RED}\n",
    "╔═════════════════════════════════════════════════════════════════════════════╗\n",
    "║                             Valor NO VALIDO                                 ║\n",
    "╚═════════════════════════════════════════════════════════════════════════════╝{Style.RESET_ALL}\n",
    "{nombre_df=}      {nombre_serie=}\n",
    "Valores faltantes detectados con fila/índice:\\n, {valores_detectados}\"\"\")\n",
    "    return {'mask': mask, 'valores_faltantes': valores_detectados.unique().tolist()}#True si es NaN o está en los tokens de faltante"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68115820-6bda-49b4-a3e8-912d44cdd440",
   "metadata": {},
   "source": [
    "### 4.1.5 Modificar/filtrar series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2dee86f8-86c5-45f5-98d7-ea56cd905395",
   "metadata": {},
   "outputs": [],
   "source": [
    "def series_en_dataframes(nombre_df, df_cada):\n",
    "    for nombre_serie, serie in df_cada.items():\n",
    "        resultado = es_valor_faltante(serie,nombre_serie,nombre_df)           \n",
    "        nombre_serie= nombre_serie.lower().replace(\" \",\"_\")\n",
    "        if nombre_serie.startswith(\"id_\"):\n",
    "            continue\n",
    "        regla =  next(iter(reglas[nombre_df][nombre_serie]))\n",
    "        '''\n",
    "        print (f\"\"\"\n",
    "        {nombre_serie=}\n",
    "        {serie=}\n",
    "        {regla=}\n",
    "        \"\"\")'''\n",
    "        s = serie.copy()\n",
    "        if regla == \"numeric\":\n",
    "            try:\n",
    "                s = s.astype(str).str.strip()\n",
    "                '''\n",
    "            ╔═════════════════════════════════════════════════════════════════════════════╗\n",
    "            ║                              Sacar simbolo $                                ║\n",
    "            ╚═════════════════════════════════════════════════════════════════════════════╝'''\n",
    "                s = s.str.replace('$', '')\n",
    "            except:\n",
    "                pass\n",
    "            '''\n",
    "            ╔═════════════════════════════════════════════════════════════════════════════╗\n",
    "            ║                              A numerico (float 32/4)                        ║\n",
    "            ╚═════════════════════════════════════════════════════════════════════════════╝'''\n",
    "            # difiere para windows vs mac-linuxs = pd.to_numeric(s, errors=\"coerce\").astype(np.float32)\n",
    "            s = pd.to_numeric(s, errors=\"coerce\", downcast='float')  # Intenta float32\n",
    "            if reglas[nombre_df][nombre_serie][\"numeric\"][\"as_int\"] :\n",
    "                s = s.replace('.', '').replace(',', '')\n",
    "                if not s.isna().any():\n",
    "                    '''\n",
    "            ╔═════════════════════════════════════════════════════════════════════════════╗\n",
    "            ║                              A numerico (int32/4)                           ║\n",
    "            ╚═════════════════════════════════════════════════════════════════════════════╝'''\n",
    "                    s = s.astype(np.int32)  # Garantizado int32\n",
    "        elif regla == \"string\":\n",
    "            '''\n",
    "            ╔═════════════════════════════════════════════════════════════════════════════╗\n",
    "            ║      Verdadero formato Python papa reemplazar mas de 2 espacios por 1       ║\n",
    "            ╚═════════════════════════════════════════════════════════════════════════════╝'''\n",
    "            s = s.astype(str).str.strip().replace(r'\\s+', ' ', regex=True)\n",
    "            match  reglas[nombre_df][nombre_serie][regla][\"tipo\"] :\n",
    "                case \"upper\":\n",
    "                    s = s.str.upper()\n",
    "                case \"title\":\n",
    "                    s = s.str.title()\n",
    "                case \"lower\":\n",
    "                    s = s.str.lower()\n",
    "            '''\n",
    "            ╔═════════════════════════════════════════════════════════════════════════════╗\n",
    "            ║                              Sacar acentos                                  ║\n",
    "            ╚═════════════════════════════════════════════════════════════════════════════╝'''\n",
    "            #texto_n = unicodedata.normalize(\"NFD\", entrada)\n",
    "            s= s.apply(  lambda x: ''.join( c for c in unicodedata.normalize('NFKD', str(x)) if not unicodedata.combining(c)  )  )\n",
    "            #''.join(c for c in unicodedata.normalize('NFKD', str(x))  if not unicodedata.combining(c))  for x in df[\"columna\"]\n",
    "            '''            \n",
    "            Modo\tSignificado\tQué hace\tCuándo usar\n",
    "            NFD\tNormalization Form Decomposition\tDescompone los caracteres Unicode en su forma básica y diacrítica. Ej: \"á\" → \"a\" + \" ́\"\tCuando solo querés separar acentos.\n",
    "            NFKD\tCompatibility Decomposition\tHace lo mismo más normaliza formas equivalentes \"compatibles\" (por ejemplo, “①” → “1”, “ﬂ” → “fl”)\tIdeal para limpieza más completa de texto.\n",
    "            '''\n",
    "        elif regla == \"date\":\n",
    "            '''\n",
    "            ╔═════════════════════════════════════════════════════════════════════════════╗\n",
    "            ║                   Formato de fecha ISO('%Y/%m/%d') YYYY/MM/DD               ║\n",
    "            ╚═════════════════════════════════════════════════════════════════════════════╝'''\n",
    "            s = pd.to_datetime(  s,  dayfirst=reglas[nombre_df][nombre_serie][regla][\"dayfirst\"],   errors=\"coerce\"  ) \n",
    "            #s = s.dt.strftime('%Y/%m/%d')\n",
    "        #elif regla == \"fillna\":\n",
    "            #s = s.fillna(0)\n",
    "        dic_dfs[nombre_df][nombre_serie] = s\n",
    "        '''\n",
    "        print (f\"\"\"\n",
    "        {\"*\"*50}\n",
    "        {regla=}\"\"\")'''\n",
    "         \n",
    "    return dic_dfs[nombre_df]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1c710c-ac0d-48ad-b1ff-805de91adf12",
   "metadata": {},
   "source": [
    "### 4.1.6 seleccionar DataFrame del diccionario --> series en cada DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a93a9ef1-7c47-4115-a9ba-f3ae616f83c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[37m\u001b[41m\n",
      "╔═════════════════════════════════════════════════════════════════════════════╗\n",
      "║                             Valor NO VALIDO                                 ║\n",
      "╚═════════════════════════════════════════════════════════════════════════════╝\u001b[0m\n",
      "nombre_df='df_ventas'      nombre_serie='precio'\n",
      "Valores faltantes detectados con fila/índice:\n",
      ", 136    NaN\n",
      "139    NaN\n",
      "Name: precio, dtype: object\n",
      "\u001b[37m\u001b[41m\n",
      "╔═════════════════════════════════════════════════════════════════════════════╗\n",
      "║                             Valor NO VALIDO                                 ║\n",
      "╚═════════════════════════════════════════════════════════════════════════════╝\u001b[0m\n",
      "nombre_df='df_ventas'      nombre_serie='cantidad'\n",
      "Valores faltantes detectados con fila/índice:\n",
      ", 136   NaN\n",
      "139   NaN\n",
      "Name: cantidad, dtype: float64\n",
      "\u001b[37m\u001b[44m\n",
      "╔═════════════════════════════════════════════════════════════════════════════╗\n",
      "║                            E.T.L.:       df_ventas                          ║\n",
      "╚═════════════════════════════════════════════════════════════════════════════╝\u001b[0m\n",
      "        Descripción preliminar:\n",
      "                  id_venta       precio     cantidad                    fecha_venta\n",
      "count  3035.000000  3033.000000  3033.000000                           3035\n",
      "mean   1499.851400    75.289032     6.496538  2024-06-25 20:51:09.785832192\n",
      "min       1.000000    26.000000     1.000000            2024-01-02 00:00:00\n",
      "25%     748.500000    50.020000     3.000000            2024-03-28 00:00:00\n",
      "50%    1502.000000    75.269997     7.000000            2024-06-21 00:00:00\n",
      "75%    2249.500000   100.040001     9.000000            2024-09-25 00:00:00\n",
      "max    3000.000000   124.970001    12.000000            2024-12-30 00:00:00\n",
      "std     866.465379    28.734667     3.457250                            NaN\n",
      "        Dimensiones:      2\n",
      "        Forma:            (3035, 6)\n",
      "                filas:    3035\n",
      "                Número de elementos:18210\n",
      "                Nombres de filas:RangeIndex(start=0, stop=3035, step=1)\n",
      "                columnas: 6\n",
      "                Nombres de columnas:Index(['id_venta', 'producto', 'precio', 'cantidad', 'fecha_venta',\n",
      "       'categoria'],\n",
      "      dtype='object')\n",
      "        Valores nulos:    {'id_venta': 0, 'producto': 0, 'precio': 2, 'cantidad': 2, 'fecha_venta': 0, 'categoria': 0}\n",
      "        Valores duplicados:70\n",
      "        Tipos de datos:\n",
      "id_venta                int64\n",
      "producto               object\n",
      "precio                float32\n",
      "cantidad              float32\n",
      "fecha_venta    datetime64[ns]\n",
      "categoria              object\n",
      "dtype: object\n",
      "        Primeras 7 filas:\n",
      "   id_venta           producto      precio  cantidad fecha_venta  \\\n",
      "0       792  cuadro decorativo   69.940002       5.0  2024-01-02   \n",
      "1       811    lampara de mesa  105.099998       5.0  2024-01-02   \n",
      "2      1156           secadora   97.959999       3.0  2024-01-02   \n",
      "3      1372           heladera  114.349998       8.0  2024-01-02   \n",
      "4      1546           secadora  106.209999       4.0  2024-01-02   \n",
      "5      1697    horno electrico   35.349998       9.0  2024-01-02   \n",
      "6      1710   plancha de vapor   65.430000       2.0  2024-01-02   \n",
      "\n",
      "           categoria  \n",
      "0         decoracion  \n",
      "1         decoracion  \n",
      "2  electrodomesticos  \n",
      "3  electrodomesticos  \n",
      "4  electrodomesticos  \n",
      "5  electrodomesticos  \n",
      "6  electrodomesticos  \n",
      "        Últimas 3 filas:\n",
      "      id_venta                producto      precio  cantidad fecha_venta  \\\n",
      "3032      2696                  laptop  107.809998       4.0  2024-12-30   \n",
      "3033      2913              smartphone   99.849998       7.0  2024-12-30   \n",
      "3034      2930  consola de videojuegos   55.470001       6.0  2024-12-30   \n",
      "\n",
      "        categoria  \n",
      "3032  electronica  \n",
      "3033  electronica  \n",
      "3034  electronica  \n",
      "    **************************************************\n",
      "    \n",
      "\u001b[37m\u001b[44m\n",
      "╔═════════════════════════════════════════════════════════════════════════════╗\n",
      "║                            E.T.L.:      df_clientes                         ║\n",
      "╚═════════════════════════════════════════════════════════════════════════════╝\u001b[0m\n",
      "        Descripción preliminar:\n",
      "               id_cliente        edad      ingresos\n",
      "count  578.000000  578.000000    578.000000\n",
      "mean   289.500000   37.968858  34755.977266\n",
      "std    166.998503   10.253244  12989.576812\n",
      "min      1.000000   20.000000    170.290000\n",
      "25%    145.250000   30.000000  26119.060000\n",
      "50%    289.500000   37.000000  35102.285000\n",
      "75%    433.750000   43.000000  42600.435000\n",
      "max    578.000000   81.000000  88053.010000\n",
      "        Dimensiones:      2\n",
      "        Forma:            (578, 5)\n",
      "                filas:    578\n",
      "                Número de elementos:2890\n",
      "                Nombres de filas:RangeIndex(start=0, stop=578, step=1)\n",
      "                columnas: 5\n",
      "                Nombres de columnas:Index(['id_cliente', 'nombre', 'edad', 'ciudad', 'ingresos'], dtype='object')\n",
      "        Valores nulos:    {'id_cliente': 0, 'nombre': 0, 'edad': 0, 'ciudad': 0, 'ingresos': 0}\n",
      "        Valores duplicados:0\n",
      "        Tipos de datos:\n",
      "id_cliente      int64\n",
      "nombre         object\n",
      "edad            int32\n",
      "ciudad         object\n",
      "ingresos      float64\n",
      "dtype: object\n",
      "        Primeras 7 filas:\n",
      "   id_cliente               nombre  edad                 ciudad  ingresos\n",
      "0           1      Aloysia Screase    44          Mar Del Plata  42294.68\n",
      "1           2  Kristina Scaplehorn    25                Posadas  24735.04\n",
      "2           3       Filip Castagne    50            Resistencia  35744.85\n",
      "3           4          Liuka Luard    39           Bahia Blanca  27647.96\n",
      "4           5        Dore Cockshtt    28                Rosario  28245.65\n",
      "5           6        Patrick Earle    34  San Miguel De Tucuman  62763.31\n",
      "6           7           Etan Deeth    35            Resistencia  37489.71\n",
      "        Últimas 3 filas:\n",
      "     id_cliente           nombre  edad         ciudad  ingresos\n",
      "575         576  Cari Marzellano    38  Mar Del Plata  53114.05\n",
      "576         577   Magdalene Pegg    34        Cordoba  49849.42\n",
      "577         578    Lorry Santori    47     Corrientes  42000.81\n",
      "    **************************************************\n",
      "    \n",
      "\u001b[37m\u001b[44m\n",
      "╔═════════════════════════════════════════════════════════════════════════════╗\n",
      "║                            E.T.L.:      df_marketing                        ║\n",
      "╚═════════════════════════════════════════════════════════════════════════════╝\u001b[0m\n",
      "        Descripción preliminar:\n",
      "               id_campanha      costo         fecha_inicio            fecha_fin\n",
      "count    90.000000  90.000000                   90                   90\n",
      "mean     45.500000   4.928666  2024-08-03 16:48:00  2024-09-10 09:04:00\n",
      "min       1.000000   2.950000  2024-03-20 00:00:00  2024-04-20 00:00:00\n",
      "25%      23.250000   4.372500  2024-05-31 00:00:00  2024-07-12 18:00:00\n",
      "50%      45.500000   4.900000  2024-08-02 12:00:00  2024-09-12 12:00:00\n",
      "75%      67.750000   5.562500  2024-10-02 12:00:00  2024-11-11 18:00:00\n",
      "max      90.000000   7.390000  2024-12-29 00:00:00  2025-02-14 00:00:00\n",
      "std      26.124701   0.947750                  NaN                  NaN\n",
      "        Dimensiones:      2\n",
      "        Forma:            (90, 6)\n",
      "                filas:    90\n",
      "                Número de elementos:540\n",
      "                Nombres de filas:RangeIndex(start=0, stop=90, step=1)\n",
      "                columnas: 6\n",
      "                Nombres de columnas:Index(['id_campanha', 'producto', 'canal', 'costo', 'fecha_inicio',\n",
      "       'fecha_fin'],\n",
      "      dtype='object')\n",
      "        Valores nulos:    {'id_campanha': 0, 'producto': 0, 'canal': 0, 'costo': 0, 'fecha_inicio': 0, 'fecha_fin': 0}\n",
      "        Valores duplicados:0\n",
      "        Tipos de datos:\n",
      "id_campanha              int64\n",
      "producto                object\n",
      "canal                   object\n",
      "costo                  float32\n",
      "fecha_inicio    datetime64[ns]\n",
      "fecha_fin       datetime64[ns]\n",
      "dtype: object\n",
      "        Primeras 7 filas:\n",
      "   id_campanha          producto  canal  costo fecha_inicio  fecha_fin\n",
      "0           74   adorno de pared     TV   4.81   2024-03-20 2024-05-03\n",
      "1           12            tablet   RRSS   3.40   2024-03-26 2024-05-13\n",
      "2           32   lampara de mesa  EMAIL   5.54   2024-03-28 2024-04-20\n",
      "3           21        smartphone   RRSS   6.37   2024-03-29 2024-05-16\n",
      "4           58          alfombra  EMAIL   4.25   2024-03-31 2024-05-05\n",
      "5           85        smartwatch     TV   5.07   2024-04-01 2024-05-05\n",
      "6           36  plancha de vapor  EMAIL   5.41   2024-04-02 2024-06-01\n",
      "        Últimas 3 filas:\n",
      "    id_campanha            producto  canal  costo fecha_inicio  fecha_fin\n",
      "87           68   rincon de plantas     TV   5.81   2024-12-17 2025-02-14\n",
      "88           33            secadora  EMAIL   3.80   2024-12-20 2025-01-07\n",
      "89           11  freidora electrica   RRSS   5.27   2024-12-29 2025-01-21\n",
      "    **************************************************\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "def dataframes_en_diccionario():\n",
    "    \"\"\"\n",
    "    Limpia el DataFrame aplicando reglas_por_columna = {\"col\": (\"regla\", parametros)...}\n",
    "    Las reglas se asignan automáticamente según el tipo o formato:\n",
    "      - Columnas numéricas o con símbolos ($, %, dígitos) → 'numeric'\n",
    "      - Columnas que parecen fechas → 'date'\n",
    "      - Otras columnas → 'string'\n",
    "    \"\"\"\n",
    "    for nombre_df, df_cada in dic_dfs.items():           \n",
    "        dic_dfs[nombre_df] = series_en_dataframes(nombre_df, df_cada)\n",
    "        #print (dic_dfs[nombre_df].head(40))\n",
    "        ver( dic_dfs[nombre_df],nombre_df)\n",
    "dataframes_en_diccionario()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e10404-a8a3-4ea9-ab38-c8c49fa8cbcb",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#7FFFD4; padding:10px; border-radius:6px;\">\n",
    "    <h2 style=\"color:black; text-align:center; margin-top:6px;\">Decisión</h2>\n",
    "    <p style=\"color:black;\">\n",
    "    Resolución del analista de datos\n",
    "    </p>\n",
    "    <p style=\"color:black;\">Se encontraron 2 registros NaN</p>\n",
    "        <ul style=\"color:black;\">\n",
    "            <li>Cada registro tiene dos valores faltantes (cantidad y precio)</li>\n",
    "            <li>Los precios se pueden evaluar buscando el mismo producto con fecha similar (inflación)</li>\n",
    "            <li>Las cantidades no se pueden inventar, aunque si el DF fuese más grande y el cliente tuviese varias compras se evaluaría un promedio de las anteriores</li>\n",
    "        </ul>\n",
    "    <p style=\"color:#0000ff;\">En base a esto se procede a borrar los registros con datos nulos o faltantes</p>\n",
    "</div>\n",
    "<!-- si amo la tabulacion/identación -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b617883-6875-4a23-881d-1d5ee86f72aa",
   "metadata": {},
   "source": [
    "### 4.1.7 Modificar registros con indices y demas datos duplicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3eee5bfa-299f-46e6-ad02-e0d2d1f1ec09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Antes:  (3035, 6)\n",
      "Después: (3033, 6)\n",
      "\n",
      "    Se eliminaron '2' registros donde la cantidad estaba en null o NaN\n",
      "    \n",
      "\n",
      "================================================================================\n",
      "REGISTROS ELIMINADOS ACUMULADOS:\n",
      "================================================================================\n",
      "     id_venta               producto  precio  cantidad fecha_venta  \\\n",
      "136       627  elementos de ceramica     NaN       NaN  2024-01-17   \n",
      "139      2171    parlantes bluetooth     NaN       NaN  2024-01-17   \n",
      "\n",
      "       categoria motivo_eliminacion dataframe_origen columna_problema  \n",
      "136   decoracion    NaN en cantidad        df_ventas         cantidad  \n",
      "139  electronica    NaN en cantidad        df_ventas         cantidad  \n",
      "\n",
      "Total de registros eliminados: 2\n"
     ]
    }
   ],
   "source": [
    "def eliminar_registros():\n",
    "    global n_registros_eliminados, df_registros_eliminados\n",
    "    \n",
    "    print(f\"Antes:  {dic_dfs['df_ventas'].shape}\")\n",
    "    \n",
    "    # Guardar cantidad inicial\n",
    "    n_inicial = len(dic_dfs['df_ventas'])\n",
    "    \n",
    "    # Identificar registros con NaN en 'cantidad'\n",
    "    mascara_nulos = dic_dfs['df_ventas']['cantidad'].isna()\n",
    "    registros_a_eliminar = dic_dfs['df_ventas'][mascara_nulos].copy()\n",
    "    \n",
    "    # Agregar información sobre el motivo de eliminación\n",
    "    if not registros_a_eliminar.empty:\n",
    "        registros_a_eliminar['motivo_eliminacion'] = 'NaN en cantidad'\n",
    "        registros_a_eliminar['dataframe_origen'] = 'df_ventas'\n",
    "        registros_a_eliminar['columna_problema'] = 'cantidad'\n",
    "        \n",
    "        # Acumular en el DataFrame global\n",
    "        if 'df_registros_eliminados' not in globals() or df_registros_eliminados is None:\n",
    "            df_registros_eliminados = registros_a_eliminar\n",
    "        else:\n",
    "            df_registros_eliminados = pd.concat([df_registros_eliminados, registros_a_eliminar], ignore_index=True)\n",
    "    \n",
    "    # Eliminar registros con NaN en 'cantidad'\n",
    "    dic_dfs['df_ventas'] = dic_dfs['df_ventas'].dropna(subset=['cantidad'])\n",
    "    \n",
    "    # Calcular registros eliminados\n",
    "    n_final = len(dic_dfs['df_ventas'])\n",
    "    n_registros_eliminados = n_inicial - n_final\n",
    "    \n",
    "    print(f\"Después: {dic_dfs['df_ventas'].shape}\")\n",
    "    print(f\"\"\"\n",
    "    Se eliminaron '{n_registros_eliminados}' registros donde la cantidad estaba en null o NaN\n",
    "    \"\"\")\n",
    "    \n",
    "    return n_registros_eliminados\n",
    "\n",
    "# Inicializar el DataFrame global\n",
    "df_registros_eliminados = None\n",
    "\n",
    "# Ejecutar\n",
    "eliminar_registros()\n",
    "\n",
    "# Ver los registros eliminados\n",
    "if df_registros_eliminados is not None:\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"REGISTROS ELIMINADOS ACUMULADOS:\")\n",
    "    print(\"=\"*80)\n",
    "    print(df_registros_eliminados)\n",
    "    print(f\"\\nTotal de registros eliminados: {len(df_registros_eliminados)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1866cdfc-9cb5-497a-86dc-9225ef5f7103",
   "metadata": {},
   "source": [
    "### 4.1.8 reporte duplicados por DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "867ebfb2-e1ce-4153-b2bf-74948055eb52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[37m\u001b[44m\n",
      "╔═════════════════════════════════════════════════════════════════════════════╗\n",
      "║                              REPORTE DUPLICADOS                             ║\n",
      "╠═════════════════════════════════════════════════════════════════════════════╣\u001b[0m\n",
      "\u001b[37m\u001b[44m║ \u001b[30m\u001b[43m              [df_ventas] Se encontraron 70 duplicados exactos             \u001b[37m\u001b[44m ║\u001b[0m\n",
      "\u001b[37m\u001b[44m║ \u001b[30m\u001b[42m                      [df_clientes] No hay duplicados                      \u001b[37m\u001b[44m ║\u001b[0m\n",
      "\u001b[37m\u001b[44m║ \u001b[30m\u001b[42m                      [df_marketing] No hay duplicados                     \u001b[37m\u001b[44m ║\u001b[0m\n",
      "\u001b[37m\u001b[44m╚═════════════════════════════════════════════════════════════════════════════╝\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_venta</th>\n",
       "      <th>producto</th>\n",
       "      <th>precio</th>\n",
       "      <th>cantidad</th>\n",
       "      <th>fecha_venta</th>\n",
       "      <th>categoria</th>\n",
       "      <th>origen_df</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56</td>\n",
       "      <td>cortinas</td>\n",
       "      <td>66.239998</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2024-04-05</td>\n",
       "      <td>decoracion</td>\n",
       "      <td>df_ventas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>421</td>\n",
       "      <td>lampara de mesa</td>\n",
       "      <td>114.830002</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2024-04-05</td>\n",
       "      <td>decoracion</td>\n",
       "      <td>df_ventas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>424</td>\n",
       "      <td>jarron decorativo</td>\n",
       "      <td>87.940002</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2024-04-05</td>\n",
       "      <td>decoracion</td>\n",
       "      <td>df_ventas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1868</td>\n",
       "      <td>cafetera</td>\n",
       "      <td>62.230000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2024-04-05</td>\n",
       "      <td>electrodomesticos</td>\n",
       "      <td>df_ventas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2545</td>\n",
       "      <td>auriculares</td>\n",
       "      <td>32.810001</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2024-04-05</td>\n",
       "      <td>electronica</td>\n",
       "      <td>df_ventas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>1381</td>\n",
       "      <td>freidora electrica</td>\n",
       "      <td>38.119999</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2024-04-08</td>\n",
       "      <td>electrodomesticos</td>\n",
       "      <td>df_ventas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>2365</td>\n",
       "      <td>auriculares</td>\n",
       "      <td>92.910004</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2024-04-08</td>\n",
       "      <td>electronica</td>\n",
       "      <td>df_ventas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>2486</td>\n",
       "      <td>laptop</td>\n",
       "      <td>124.949997</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2024-04-08</td>\n",
       "      <td>electronica</td>\n",
       "      <td>df_ventas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>2506</td>\n",
       "      <td>laptop</td>\n",
       "      <td>34.740002</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2024-04-08</td>\n",
       "      <td>electronica</td>\n",
       "      <td>df_ventas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>2705</td>\n",
       "      <td>auriculares</td>\n",
       "      <td>87.290001</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2024-04-08</td>\n",
       "      <td>electronica</td>\n",
       "      <td>df_ventas</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    id_venta            producto      precio  cantidad fecha_venta  \\\n",
       "0         56            cortinas   66.239998       5.0  2024-04-05   \n",
       "1        421     lampara de mesa  114.830002       9.0  2024-04-05   \n",
       "2        424   jarron decorativo   87.940002       2.0  2024-04-05   \n",
       "3       1868            cafetera   62.230000       1.0  2024-04-05   \n",
       "4       2545         auriculares   32.810001      11.0  2024-04-05   \n",
       "..       ...                 ...         ...       ...         ...   \n",
       "65      1381  freidora electrica   38.119999       2.0  2024-04-08   \n",
       "66      2365         auriculares   92.910004      11.0  2024-04-08   \n",
       "67      2486              laptop  124.949997      11.0  2024-04-08   \n",
       "68      2506              laptop   34.740002       1.0  2024-04-08   \n",
       "69      2705         auriculares   87.290001       2.0  2024-04-08   \n",
       "\n",
       "            categoria  origen_df  \n",
       "0          decoracion  df_ventas  \n",
       "1          decoracion  df_ventas  \n",
       "2          decoracion  df_ventas  \n",
       "3   electrodomesticos  df_ventas  \n",
       "4         electronica  df_ventas  \n",
       "..                ...        ...  \n",
       "65  electrodomesticos  df_ventas  \n",
       "66        electronica  df_ventas  \n",
       "67        electronica  df_ventas  \n",
       "68        electronica  df_ventas  \n",
       "69        electronica  df_ventas  \n",
       "\n",
       "[70 rows x 7 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def buscar_y_eliminar_duplicados_exactos( keep='first'):\n",
    "    \"\"\"\n",
    "    Elimina duplicados exactos de los DataFrames dentro de dic_dfs y pisa los DataFrames originales.\n",
    "\n",
    "    Parámetros:\n",
    "    -----------\n",
    "    dic_dfs : dict\n",
    "        Diccionario {nombre_df: df}\n",
    "    keep : str, default 'first'\n",
    "        - 'first': mantiene la primera ocurrencia\n",
    "        - 'last': mantiene la última ocurrencia\n",
    "        - False: elimina todas las ocurrencias\n",
    "\n",
    "    Retorna:\n",
    "    --------\n",
    "    df_duplicados_total : DataFrame\n",
    "        Todos los duplicados encontrados con columna \"origen_df\"\n",
    "    \"\"\"\n",
    "    df_duplicados_total = pd.DataFrame()\n",
    "\n",
    "    print(f\"\"\"{Fore.WHITE+Back.BLUE}\n",
    "╔═════════════════════════════════════════════════════════════════════════════╗\n",
    "║                              REPORTE DUPLICADOS                             ║\n",
    "╠═════════════════════════════════════════════════════════════════════════════╣{Style.RESET_ALL}\"\"\")\n",
    "\n",
    "    for nombre_df, df_cada in dic_dfs.items():\n",
    "        mascara_duplicados = df_cada.duplicated(keep=False)\n",
    "        n_duplicados = mascara_duplicados.sum()\n",
    "\n",
    "        if n_duplicados > 0:\n",
    "            duplicados = df_cada[mascara_duplicados].copy()\n",
    "            duplicados['origen_df'] = nombre_df\n",
    "\n",
    "            df_duplicados_total = pd.concat([df_duplicados_total, duplicados], ignore_index=True)\n",
    "\n",
    "            print(f\"\"\"{Fore.WHITE+Back.BLUE}║ {Fore.BLACK+Back.YELLOW}{f\"[{nombre_df}] Se encontraron {n_duplicados} duplicados exactos\".center(75)}{Fore.WHITE+Back.BLUE} ║{Style.RESET_ALL}\"\"\")\n",
    "\n",
    "            # Pisar DataFrame dentro del diccionario\n",
    "            dic_dfs[nombre_df] = df_cada.drop_duplicates(keep=keep)\n",
    "        else:\n",
    "            print(f\"\"\"{Fore.WHITE+Back.BLUE}║ {Fore.BLACK+Back.GREEN}{f\"[{nombre_df}] No hay duplicados\".center(75)}{Fore.WHITE+Back.BLUE} ║{Style.RESET_ALL}\"\"\")\n",
    "\n",
    "    print(f\"\"\"{Fore.WHITE+Back.BLUE}╚═════════════════════════════════════════════════════════════════════════════╝{Style.RESET_ALL}\"\"\")\n",
    "    return df_duplicados_total\n",
    "buscar_y_eliminar_duplicados_exactos()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e1eebc-ace8-466b-84f1-e4cdc388466e",
   "metadata": {},
   "source": [
    "### 4.1.9 Valores atípicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6e0227e6-e3da-4d48-bb8b-917e01167f16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Funciones utilitarias definidas.\n"
     ]
    }
   ],
   "source": [
    "def buscar_valores_atipicos_zscore(serie):\n",
    "    \"\"\"\n",
    "    Devuelve máscara booleana (True = outlier) según Z-score.\n",
    "    \"\"\"\n",
    "    serie_limpia = serie.dropna().astype(float)\n",
    "    if serie_limpia.shape[0] < 4 or serie_limpia.std() == 0:\n",
    "        return pd.Series([False] * len(serie), index=serie.index)\n",
    "    puntaje_z = (serie - serie_limpia.mean()) / serie_limpia.std()\n",
    "    return puntaje_z.abs() > desviacion_umbral  \n",
    "print('Funciones utilitarias definidas.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "55788567-c11e-48eb-8e28-45ab210962a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def buscar_valores_atipicos_rango_intercuartil(serie):# Detección de outliers (IQR) - función corregida y robusta\n",
    "    \"\"\"\n",
    "    Devuelve una tupla: (mascara_bool_series, cantidad_outliers, (limite_inferior, limite_superior))\n",
    "    \"\"\"\n",
    "    serie = pd.to_numeric(serie, errors='coerce')\n",
    "    serie_limpia = serie.dropna().astype(float)\n",
    "    \n",
    "    if serie_limpia.shape[0] < 4:\n",
    "        mascara = pd.Series([False] * len(serie), index=serie.index)\n",
    "        return mascara, int(mascara.sum()), (None, None)\n",
    "    \n",
    "    cuartil_1 = float(serie_limpia.quantile(0.25))\n",
    "    cuartil_3 = float(serie_limpia.quantile(0.75))\n",
    "    rango_intercuartil = cuartil_3 - cuartil_1\n",
    "    limite_inferior = cuartil_1 - desviacion_margen * rango_intercuartil\n",
    "    limite_superior = cuartil_3 + desviacion_margen * rango_intercuartil\n",
    "    \n",
    "    mascara = (serie < limite_inferior) | (serie > limite_superior)\n",
    "    mascara = mascara.fillna(False).astype(bool)\n",
    "    \n",
    "    return mascara, int(mascara.sum()), (limite_inferior, limite_superior)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e77b5f-a069-4dd7-b831-56e141c7adcc",
   "metadata": {},
   "source": [
    "## 4.2.Guardar valores\n",
    "### 4.2.1 Guardar valores CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bdad9403-e17e-487d-8791-8a602739201f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def guardar_csv(df, ruta):# Función auxiliar para guardar CSVs\n",
    "    \"\"\"\n",
    "    Guarda df en ruta (string o Path). Crea directorio padre si no existe.\n",
    "    \"\"\"\n",
    "    ruta = Path(ruta)\n",
    "    ruta.parent.mkdir(parents=True, exist_ok=True)\n",
    "    df.to_csv(ruta, index=False, encoding='utf-8')\n",
    "    return ruta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6e42599a-abe2-4447-b8e6-6c1024f0d651",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nombre_limpio = ventas_limpio.csv\n",
      "Guardado cleaned en: datasets_salida\\limpios\\ventas_limpio.csv\n",
      "nombre_limpio = clientes_limpio.csv\n",
      "Guardado cleaned en: datasets_salida\\limpios\\clientes_limpio.csv\n",
      "nombre_limpio = marketing_limpio.csv\n",
      "Guardado cleaned en: datasets_salida\\limpios\\marketing_limpio.csv\n"
     ]
    }
   ],
   "source": [
    "for [path_archivo, df_actual],[nombre_archivo,_] in zip( dic_dfs.items() , reglas_por_archivo.items() ):\n",
    "\n",
    "    nombre_limpio = nombre_archivo[:-4] + '_limpio.csv' if nombre_archivo.lower().endswith('.csv') else nombre_archivo + ' limpio.csv'\n",
    "    print(f'nombre_limpio = {nombre_limpio}')\n",
    "    # guardar cleaned\n",
    "    ruta_guardado = carpeta_limpios / nombre_limpio\n",
    "    guardar_csv(df_actual, ruta_guardado)\n",
    "    print(f'Guardado cleaned en: {ruta_guardado}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd104a5-137a-4135-aaf0-357aef533ba8",
   "metadata": {},
   "source": [
    "### 4.2.1 Guardar valores Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "10bdb094-3598-45a3-9958-6b98c36bf76f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def guardar_excel():\n",
    "    \"\"\"\n",
    "    Guarda los DataFrames de análisis en un archivo Excel con múltiples hojas.\n",
    "    \n",
    "    Hojas:\n",
    "    - outliers: Valores atípicos detectados\n",
    "    - duplicados: Registros duplicados encontrados\n",
    "    - eliminados: Registros eliminados por NaN u otros motivos\n",
    "    \"\"\"\n",
    "    global df_outliers, df_duplicados_total, df_registros_eliminados\n",
    "    mensajes = []\n",
    "    guardado_ok = False\n",
    "        \n",
    "    try:\n",
    "        with pd.ExcelWriter(ruta_excel, engine='openpyxl') as writer:\n",
    "            \n",
    "            # Hoja 1: Outliers\n",
    "            try:\n",
    "                if 'df_outliers' in globals() and df_outliers is not None and not df_outliers.empty:\n",
    "                    df_outliers.to_excel(writer, index=False, sheet_name='outliers')\n",
    "                    mensajes.append(f'Hoja \"outliers\": {len(df_outliers)} registros')\n",
    "                else:\n",
    "                    pd.DataFrame({'mensaje': ['No se detectaron outliers']}).to_excel(writer, index=False, sheet_name='outliers')\n",
    "                    mensajes.append('Hoja \"outliers\": vacía')\n",
    "            except Exception as e:\n",
    "                pd.DataFrame({'error': [str(e)]}).to_excel(writer, index=False, sheet_name='outliers')\n",
    "                mensajes.append(f'Error en hoja \"outliers\": {str(e)}')\n",
    "            \n",
    "            # Hoja 2: Duplicados\n",
    "            try:\n",
    "                if 'df_duplicados_total' in globals() and df_duplicados_total is not None and not df_duplicados_total.empty:\n",
    "                    df_duplicados_total.to_excel(writer, index=False, sheet_name='duplicados')\n",
    "                    mensajes.append(f'Hoja \"duplicados\": {len(df_duplicados_total)} registros')\n",
    "                else:\n",
    "                    pd.DataFrame({'mensaje': ['No se encontraron duplicados']}).to_excel(writer, index=False, sheet_name='duplicados')\n",
    "                    mensajes.append('Hoja \"duplicados\": vacía')\n",
    "            except Exception as e:\n",
    "                pd.DataFrame({'error': [str(e)]}).to_excel(writer, index=False, sheet_name='duplicados')\n",
    "                mensajes.append(f'Error en hoja \"duplicados\": {str(e)}')\n",
    "            \n",
    "            # Hoja 3: Registros eliminados\n",
    "            try:\n",
    "                if 'df_registros_eliminados' in globals() and df_registros_eliminados is not None and not df_registros_eliminados.empty:\n",
    "                    df_registros_eliminados.to_excel(writer, index=False, sheet_name='eliminados')\n",
    "                    mensajes.append(f'Hoja \"eliminados\": {len(df_registros_eliminados)} registros')\n",
    "                else:\n",
    "                    pd.DataFrame({'mensaje': ['No se eliminaron registros']}).to_excel(writer, index=False, sheet_name='eliminados')\n",
    "                    mensajes.append('Hoja \"eliminados\": vacía')\n",
    "            except Exception as e:\n",
    "                pd.DataFrame({'error': [str(e)]}).to_excel(writer, index=False, sheet_name='eliminados')\n",
    "                mensajes.append(f'Error en hoja \"eliminados\": {str(e)}')\n",
    "        \n",
    "        guardado_ok = True\n",
    "        \n",
    "    except Exception as e_openpyxl:\n",
    "        mensajes.append(f'Error usando openpyxl: {str(e_openpyxl)}')\n",
    "        guardado_ok = False\n",
    "    print(f\"\"\"{Fore.WHITE+Back.BLUE}\\n\n",
    "╔═════════════════════════════════════════════════════════════════════════════╗\n",
    "║                              REPORTE EXCEL GUARDADO                         ║\n",
    "║                     Ruta:    {str(ruta_excel).center(40)} ║\n",
    "║                     Estado:  {str(guardado_ok).center(20)}                           ║\n",
    "║                              {\"EXITOSO\".center(20) if guardado_ok else \"FALLIDO\".center(20)}                           ║\n",
    "║    Detalle por hoja:                                                        ║\n",
    "╠═════════════════════════════════════════════════════════════════════════════╣\n",
    "║                     Aplico reglas según columna específica                  ║\"\"\")\n",
    "    for m in mensajes:\n",
    "        print (f\"\"\"║                     Estado:  {m.ljust(40)}       ║\"\"\")\n",
    "    print (f\"\"\"╚═════════════════════════════════════════════════════════════════════════════╝{Style.RESET_ALL}\"\"\")\n",
    "    return guardado_ok"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f411cb90-17af-45f2-9dfb-9fe7534bacbb",
   "metadata": {},
   "source": [
    "# 4.3 limpieza y normalización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "32235fb9-1e09-422e-931b-3471d6fbf123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "\u001b[37m\u001b[44m\n",
      "\n",
      "╔═════════════════════════════════════════════════════════════════════════════╗\n",
      "║                              Valores Modificado                             ║\n",
      "╠═════════════════════════════════════════════════════════════════════════════╣\n",
      "║     Afecta                                                                  ║\n",
      "║         Elimina espacios iniciales y finales.                               ║\n",
      "║         Borra Na                                                            ║\n",
      "║         Borra duplicados                                                    ║\n",
      "╠═════════════════════════════════════════════════════════════════════════════╣\n",
      "║                     Aplico reglas según columna específica                  ║\n",
      "╠═════════════════════════════════════════════════════════════════════════════╣\n",
      "║     Afecta                                                                  ║\n",
      "║             Numéricos (int/float)                                           ║\n",
      "║             fechas --> YYYY,MM,DD                                           ║\n",
      "╚═════════════════════════════════════════════════════════════════════════════╝\u001b[0m\n",
      "\u001b[37m\u001b[44m\n",
      "\n",
      "╔═════════════════════════════════════════════════════════════════════════════╗\n",
      "║                                   ventas.csv                                ║\n",
      "╚═════════════════════════════════════════════════════════════════════════════╝\u001b[0m\n",
      "\n",
      "╔═══════════════════════════════════════════════════════════════════════════╗\n",
      "║ DataFrame:                          ventas.csv                            ║\n",
      "║ Columna:                             id_venta                             ║\n",
      "╠═══════════════════════════════════════════════════════════════════════════╣\n",
      "║ Outliers por Z-score:                          0                          ║\n",
      "║ Outliers por IQR:                              0                          ║\n",
      "║ Total combinado:                               0                          ║\n",
      "║ Límites IQR:           [ -1498.0  ,   4500.0  ]                           ║\n",
      "╚═══════════════════════════════════════════════════════════════════════════╝\n",
      "\n",
      "\n",
      "╔═══════════════════════════════════════════════════════════════════════════╗\n",
      "║ DataFrame:                          ventas.csv                            ║\n",
      "║ Columna:                              precio                              ║\n",
      "╠═══════════════════════════════════════════════════════════════════════════╣\n",
      "║ Outliers por Z-score:                          0                          ║\n",
      "║ Outliers por IQR:                              0                          ║\n",
      "║ Total combinado:                               0                          ║\n",
      "║ Límites IQR:           [  -25.03  ,   175.12  ]                           ║\n",
      "╚═══════════════════════════════════════════════════════════════════════════╝\n",
      "\n",
      "\n",
      "╔═══════════════════════════════════════════════════════════════════════════╗\n",
      "║ DataFrame:                          ventas.csv                            ║\n",
      "║ Columna:                             cantidad                             ║\n",
      "╠═══════════════════════════════════════════════════════════════════════════╣\n",
      "║ Outliers por Z-score:                          0                          ║\n",
      "║ Outliers por IQR:                              0                          ║\n",
      "║ Total combinado:                               0                          ║\n",
      "║ Límites IQR:           [   -6.0   ,    18.0   ]                           ║\n",
      "╚═══════════════════════════════════════════════════════════════════════════╝\n",
      "\n",
      "\n",
      "================================================================================\n",
      "RESUMEN TOTAL DE OUTLIERS DETECTADOS: 0\n",
      "================================================================================\n",
      "\n",
      "\u001b[37m\u001b[44m\n",
      "\n",
      "╔═════════════════════════════════════════════════════════════════════════════╗\n",
      "║                                  clientes.csv                               ║\n",
      "╚═════════════════════════════════════════════════════════════════════════════╝\u001b[0m\n",
      "\n",
      "╔═══════════════════════════════════════════════════════════════════════════╗\n",
      "║ DataFrame:                         clientes.csv                           ║\n",
      "║ Columna:                            id_cliente                            ║\n",
      "╠═══════════════════════════════════════════════════════════════════════════╣\n",
      "║ Outliers por Z-score:                          0                          ║\n",
      "║ Outliers por IQR:                              0                          ║\n",
      "║ Total combinado:                               0                          ║\n",
      "║ Límites IQR:           [  -287.5  ,   866.5   ]                           ║\n",
      "╚═══════════════════════════════════════════════════════════════════════════╝\n",
      "\n",
      "\n",
      "╔═══════════════════════════════════════════════════════════════════════════╗\n",
      "║ DataFrame:                         clientes.csv                           ║\n",
      "║ Columna:                               edad                               ║\n",
      "╠═══════════════════════════════════════════════════════════════════════════╣\n",
      "║ Outliers por Z-score:                          9                          ║\n",
      "║ Outliers por IQR:                              17                         ║\n",
      "║ Total combinado:                               17                         ║\n",
      "║ Límites IQR:           [   10.5   ,    62.5   ]                           ║\n",
      "╚═══════════════════════════════════════════════════════════════════════════╝\n",
      "\n",
      "\n",
      "╔═══════════════════════════════════════════════════════════════════════════╗\n",
      "║ DataFrame:                         clientes.csv                           ║\n",
      "║ Columna:                             ingresos                             ║\n",
      "╠═══════════════════════════════════════════════════════════════════════════╣\n",
      "║ Outliers por Z-score:                          2                          ║\n",
      "║ Outliers por IQR:                              6                          ║\n",
      "║ Total combinado:                               6                          ║\n",
      "║ Límites IQR:           [  1397.0  ,  67322.5  ]                           ║\n",
      "╚═══════════════════════════════════════════════════════════════════════════╝\n",
      "\n",
      "\n",
      "================================================================================\n",
      "RESUMEN TOTAL DE OUTLIERS DETECTADOS: 23\n",
      "================================================================================\n",
      "\n",
      "      dataframe columna  indice  valor metodo_deteccion   z_score  \\\n",
      "0  clientes.csv    edad      10   69.0     Z-score, IQR  3.026471   \n",
      "1  clientes.csv    edad     114   65.0              IQR  2.636350   \n",
      "2  clientes.csv    edad     127   81.0     Z-score, IQR  4.196832   \n",
      "3  clientes.csv    edad     177   75.0     Z-score, IQR  3.611651   \n",
      "4  clientes.csv    edad     214   71.0     Z-score, IQR  3.221531   \n",
      "\n",
      "   limite_inf_iqr  limite_sup_iqr  media_serie  std_serie  \n",
      "0            10.5            62.5    37.968858  10.253244  \n",
      "1            10.5            62.5    37.968858  10.253244  \n",
      "2            10.5            62.5    37.968858  10.253244  \n",
      "3            10.5            62.5    37.968858  10.253244  \n",
      "4            10.5            62.5    37.968858  10.253244  \n",
      "\n",
      " Outliers guardados en: datasets_salida\\reportes\\outliers_detectados.csv\n",
      "\u001b[37m\u001b[44m\n",
      "\n",
      "╔═════════════════════════════════════════════════════════════════════════════╗\n",
      "║                                 marketing.csv                               ║\n",
      "╚═════════════════════════════════════════════════════════════════════════════╝\u001b[0m\n",
      "\n",
      "╔═══════════════════════════════════════════════════════════════════════════╗\n",
      "║ DataFrame:                        marketing.csv                           ║\n",
      "║ Columna:                           id_campanha                            ║\n",
      "╠═══════════════════════════════════════════════════════════════════════════╣\n",
      "║ Outliers por Z-score:                          0                          ║\n",
      "║ Outliers por IQR:                              0                          ║\n",
      "║ Total combinado:                               0                          ║\n",
      "║ Límites IQR:           [  -43.5   ,   134.5   ]                           ║\n",
      "╚═══════════════════════════════════════════════════════════════════════════╝\n",
      "\n",
      "\n",
      "╔═══════════════════════════════════════════════════════════════════════════╗\n",
      "║ DataFrame:                        marketing.csv                           ║\n",
      "║ Columna:                              costo                               ║\n",
      "╠═══════════════════════════════════════════════════════════════════════════╣\n",
      "║ Outliers por Z-score:                          0                          ║\n",
      "║ Outliers por IQR:                              1                          ║\n",
      "║ Total combinado:                               1                          ║\n",
      "║ Límites IQR:           [   2.59   ,    7.35   ]                           ║\n",
      "╚═══════════════════════════════════════════════════════════════════════════╝\n",
      "\n",
      "\n",
      "================================================================================\n",
      "RESUMEN TOTAL DE OUTLIERS DETECTADOS: 24\n",
      "================================================================================\n",
      "\n",
      "      dataframe columna  indice  valor metodo_deteccion   z_score  \\\n",
      "0  clientes.csv    edad      10   69.0     Z-score, IQR  3.026471   \n",
      "1  clientes.csv    edad     114   65.0              IQR  2.636350   \n",
      "2  clientes.csv    edad     127   81.0     Z-score, IQR  4.196832   \n",
      "3  clientes.csv    edad     177   75.0     Z-score, IQR  3.611651   \n",
      "4  clientes.csv    edad     214   71.0     Z-score, IQR  3.221531   \n",
      "\n",
      "   limite_inf_iqr  limite_sup_iqr  media_serie  std_serie  \n",
      "0            10.5            62.5    37.968858  10.253244  \n",
      "1            10.5            62.5    37.968858  10.253244  \n",
      "2            10.5            62.5    37.968858  10.253244  \n",
      "3            10.5            62.5    37.968858  10.253244  \n",
      "4            10.5            62.5    37.968858  10.253244  \n",
      "\n",
      " Outliers guardados en: datasets_salida\\reportes\\outliers_detectados.csv\n",
      "\u001b[37m\u001b[44m\n",
      "\n",
      "╔═════════════════════════════════════════════════════════════════════════════╗\n",
      "║                              REPORTE EXCEL GUARDADO                         ║\n",
      "║                     Ruta:    datasets_salida\\reportes\\reporte_limpieza.xlsx ║\n",
      "║                     Estado:          True                                   ║\n",
      "║                                    EXITOSO                                  ║\n",
      "║    Detalle por hoja:                                                        ║\n",
      "╠═════════════════════════════════════════════════════════════════════════════╣\n",
      "║                     Aplico reglas según columna específica                  ║\n",
      "║                     Estado:  Hoja \"outliers\": 24 registros                  ║\n",
      "║                     Estado:  Hoja \"duplicados\": vacía                       ║\n",
      "║                     Estado:  Hoja \"eliminados\": 2 registros                 ║\n",
      "╚═════════════════════════════════════════════════════════════════════════════╝\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def menu_procesar_diccionario():\n",
    "    \"\"\"\n",
    "    Recorre dic_frames y detecta outliers, guardándolos en un DataFrame\n",
    "    \"\"\"\n",
    "    print(f\"\"\"{Fore.WHITE+Back.BLUE}\\n\n",
    "╔═════════════════════════════════════════════════════════════════════════════╗\n",
    "║                              Valores Modificado                             ║\n",
    "╠═════════════════════════════════════════════════════════════════════════════╣\n",
    "║     Afecta                                                                  ║\n",
    "║         Elimina espacios iniciales y finales.                               ║\n",
    "║         Borra Na                                                            ║\n",
    "║         Borra duplicados                                                    ║\n",
    "╠═════════════════════════════════════════════════════════════════════════════╣\n",
    "║                     Aplico reglas según columna específica                  ║\n",
    "╠═════════════════════════════════════════════════════════════════════════════╣\n",
    "║     Afecta                                                                  ║\n",
    "║             Numéricos (int/float)                                           ║\n",
    "║             fechas --> YYYY,MM,DD                                           ║\n",
    "╚═════════════════════════════════════════════════════════════════════════════╝{Style.RESET_ALL}\"\"\")\n",
    "    outliers_totales = [] \n",
    "    for [path_archivo, df_actual], [nombre_archivo, _] in zip(dic_dfs.items(), reglas_por_archivo.items()):\n",
    "        print(f\"\"\"{Fore.WHITE+Back.BLUE}\\n\n",
    "╔═════════════════════════════════════════════════════════════════════════════╗\n",
    "║                              {nombre_archivo.center(20)}                           ║\n",
    "╚═════════════════════════════════════════════════════════════════════════════╝{Style.RESET_ALL}\"\"\")\n",
    "        for columna in df_actual.columns:\n",
    "            serie = df_actual[columna]\n",
    "            \n",
    "            # Verificar si es numérica\n",
    "            if serie.dtype.kind not in ['i', 'f']:\n",
    "                continue\n",
    "\n",
    "            if len(serie) < 4:\n",
    "                continue\n",
    "            mascara_zscore = buscar_valores_atipicos_zscore(serie)\n",
    "            \n",
    "            # Detección por IQR\n",
    "            mascara_iqr, cant_iqr, (lim_inf, lim_sup) = buscar_valores_atipicos_rango_intercuartil(serie)\n",
    "            lim_inf=round(lim_inf,2)\n",
    "            lim_sup=round(lim_sup,2)\n",
    "            # Combinar métodos: outlier detectado por al menos un método\n",
    "            mascara_combinada = mascara_zscore | mascara_iqr\n",
    "            \n",
    "            # Si hay outliers, guardarlos\n",
    "            if mascara_combinada.sum() > 0:\n",
    "                # Obtener índices de outliers\n",
    "                indices_outliers = serie[mascara_combinada].index\n",
    "                \n",
    "                for idx in indices_outliers:\n",
    "                    valor = serie.loc[idx]\n",
    "                    \n",
    "                    # Determinar qué métodos lo detectaron\n",
    "                    metodos = []\n",
    "                    if mascara_zscore.loc[idx]:\n",
    "                        metodos.append('Z-score')\n",
    "                    if mascara_iqr.loc[idx]:\n",
    "                        metodos.append('IQR')\n",
    "                    \n",
    "                    # Calcular Z-score del valor\n",
    "                    if serie.std() != 0:\n",
    "                        z_valor = (valor - serie.mean()) / serie.std()\n",
    "                    else:\n",
    "                        z_valor = None\n",
    "                    \n",
    "                    outliers_totales.append({\n",
    "                        'dataframe': nombre_archivo,\n",
    "                        'columna': columna,\n",
    "                        'indice': idx,\n",
    "                        'valor': valor,\n",
    "                        'metodo_deteccion': ', '.join(metodos),\n",
    "                        'z_score': z_valor,\n",
    "                        'limite_inf_iqr': lim_inf,\n",
    "                        'limite_sup_iqr': lim_sup,\n",
    "                        'media_serie': serie.mean(),\n",
    "                        'std_serie': serie.std()\n",
    "                    })\n",
    "            \n",
    "            # Imprimir resumen\n",
    "            print(f\"\"\"\n",
    "╔═══════════════════════════════════════════════════════════════════════════╗\n",
    "║ DataFrame: {nombre_archivo.center(60)}   ║\n",
    "║ Columna: {columna.center(64)} ║\n",
    "╠═══════════════════════════════════════════════════════════════════════════╣\n",
    "║ Outliers por Z-score:  {str(mascara_zscore.sum()).center(50)} ║\n",
    "║ Outliers por IQR:      {str(cant_iqr).center(50)} ║\n",
    "║ Total combinado:       {str(mascara_combinada.sum()).center(50)} ║\n",
    "║ Límites IQR:           [{str(lim_inf).center(10)}, {str(lim_sup).center(10)}]                           ║\n",
    "╚═══════════════════════════════════════════════════════════════════════════╝\n",
    "\"\"\")\n",
    "        \n",
    "        # Crear DataFrame con todos los outliers\n",
    "        df_outliers = pd.DataFrame(outliers_totales)\n",
    "        \n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"RESUMEN TOTAL DE OUTLIERS DETECTADOS: {len(df_outliers)}\")\n",
    "        print(f\"{'='*80}\\n\")\n",
    "        \n",
    "        if not df_outliers.empty:\n",
    "            print(df_outliers.head(5))\n",
    "            ruta_outliers = carpeta_reportes / 'outliers_detectados.csv'\n",
    "            guardar_csv(df_outliers, ruta_outliers)\n",
    "            print(f\"\\n Outliers guardados en: {ruta_outliers}\")\n",
    "    return df_outliers\n",
    "print (\"*\"*50)\n",
    "df_outliers = menu_procesar_diccionario()\n",
    "guardar_excel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910df609-1bb9-4014-9ff5-80d402844c0e",
   "metadata": {},
   "source": [
    "# 4.4 Limpieza"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f4ffe5-0f8d-465e-be9e-6d180fa42789",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#CCCCCC; padding:10px; border-radius:6px;\">\n",
    "    <h1 style=\"color:black; text-align:center;\">Limpieza de Datos</h1>\n",
    "    <h2 style=\"color:black; text-align:center;\">Resultados</h2>\n",
    "    <p style=\"color:black;\">- Revisados los 3 csv  pasados a DataFrames.</p>\n",
    "    <p style=\"color:blue;\">- DataFrames filtrados.</p>\n",
    "        <ul>\n",
    "            <li style=\"color:black;\">- Filtrado de Nulos.</li>\n",
    "            <li style=\"color:black;\">- Filtrado de duplicados.</li>\n",
    "            <li style=\"color:black;\">- Sin '', 'na', 'n/a', 'null', 'none', 'sin dato', 's/d', 'nd', '-', '--', '?', 'sin_dato', 'n/d'</li>    \n",
    "            <li style=\"color:black;\">- Normalisados Strings segun reglas. Estilo (lower,string.upper) unicodedata.normalize('NFKD')</li>\n",
    "            <li style=\"color:black;\">- Normalisados Strings segun reglas. sin acentos</li>\n",
    "            <li style=\"color:black;\">- Normalisados precios a float sin signo ($)</li>\n",
    "            <li style=\"color:black;\">- Normalisados Numericos a int o float segun regla</li>    \n",
    "            <li style=\"color:black;\">- Normalisados Fechas segun regla YYYY/MM/DD</li>    \n",
    "        </ul>\n",
    "    <p style=\"color:black;\">- Resguardo <code>datasets_salida/limpios/clientes_limpio.csv</code>.</p>\n",
    "    <p style=\"color:black;\">- Resguardo <code>datasets_salida/limpios/marketing_limpio.csv</code>.</p>\n",
    "    <p style=\"color:black;\">- Resguardo <code>datasets_salida/limpios/ventas_limpio.csv</code>.</p>\n",
    "    <p style=\"color:blue;\">- Registros filtrados eliminados</p>\n",
    "    <p style=\"color:black;\">- Resguardo <code>datasets_salida/reportes/reporte_limpieza.xlsx</code> con hojas (duplicados con igual id borrados, outliers, valores faltantes)</p>\n",
    "</div><!-- dios salve lña tabulacion :)-->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f43150b-eb7b-4ae8-a0a6-233f4b6ca5f1",
   "metadata": {},
   "source": [
    "ventas.csv  análisis de ventas, limpieza de datos y estadísticas descriptivas.\n",
    " \t\n",
    "clientes.csv  unirse a las ventas mediante el uso de funciones de combinación para analizar características de los clientes relacionados con sus \tcompras.\n",
    " \t\n",
    "marketing.csv analizar la efectividad de las campañas de marketing en las ventas y buscar correlaciones.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2f6a01-00ac-43f3-884d-b985421212e0",
   "metadata": {},
   "source": [
    "# 4.5 Nuevos campos calculados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b1a5b562-2f60-48f6-a526-54d48ea11ac5",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'df_ventas'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m dic_dfs[\u001b[33m\"\u001b[39m\u001b[33mdf_ventas\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m'\u001b[39m\u001b[33mprecio_total\u001b[39m\u001b[33m'\u001b[39m] = \u001b[43mdic_dfs\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdf_ventas\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m[\u001b[33m'\u001b[39m\u001b[33mprecio\u001b[39m\u001b[33m'\u001b[39m] * dic_dfs[\u001b[33m\"\u001b[39m\u001b[33mdf_ventas\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m'\u001b[39m\u001b[33mcantidad\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m (\u001b[33mf\u001b[39m\u001b[33m\"\"\"\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;132;01m{\u001b[39;00mdic_dfs[\u001b[33m\"\u001b[39m\u001b[33mdf_ventas\u001b[39m\u001b[33m\"\u001b[39m].columns\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;132;01m{\u001b[39;00mdic_dfs[\u001b[33m\"\u001b[39m\u001b[33mdf_ventas\u001b[39m\u001b[33m\"\u001b[39m].head(\u001b[32m5\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[33m\"\"\"\u001b[39m)\n",
      "\u001b[31mKeyError\u001b[39m: 'df_ventas'"
     ]
    }
   ],
   "source": [
    "dic_dfs[\"df_ventas\"]['precio_total'] = dic_dfs[\"df_ventas\"]['precio'] * dic_dfs[\"df_ventas\"]['cantidad']\n",
    "print (f\"\"\"\n",
    "{dic_dfs[\"df_ventas\"].columns}\n",
    "{dic_dfs[\"df_ventas\"].head(5)}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "501281d1-33d0-4f5a-af86-e949dd73c080",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'df_ventas'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28mprint\u001b[39m (\u001b[33mf\u001b[39m\u001b[33m\"\"\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;132;01m{\u001b[39;00m\u001b[43mdic_dfs\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdf_ventas\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m.columns\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;132;01m{\u001b[39;00mdic_dfs[\u001b[33m\"\u001b[39m\u001b[33mdf_marketing\u001b[39m\u001b[33m\"\u001b[39m].columns\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[33m\"\"\"\u001b[39m)\n",
      "\u001b[31mKeyError\u001b[39m: 'df_ventas'"
     ]
    }
   ],
   "source": [
    "print (f\"\"\"\n",
    "{dic_dfs[\"df_ventas\"].columns}\n",
    "{dic_dfs[\"df_marketing\"].columns}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd63754c-313e-4e2d-a66a-1250074bb1bb",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#CCCCCC; padding:10px; border-radius:6px;\">\n",
    "<h1 style=\"color:black; text-align:center;\">Transformación de Datos</h1>\n",
    "    <h2 style=\"color:black; text-align:center;\">Precio total</h2>\n",
    "    <p style=\"color:black;\">En \"df_ventas\" creo la serie 'precio_total' como 'precio'(unitario) * 'cantidad'</p>\n",
    "</div><!-- dios salve lña tabulacion :)-->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faad6ec9-8c39-4c96-8d4f-2695136ae42c",
   "metadata": {},
   "source": [
    "# 4.6 Concatenar dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3eef642d-0165-45ea-9fd5-64fb9f379d49",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'df_marketing'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m mark_latest = (\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     \u001b[43mdic_dfs\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdf_marketing\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m      3\u001b[39m     .sort_values([\u001b[33m'\u001b[39m\u001b[33mproducto\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mfecha_inicio\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m      4\u001b[39m     .drop_duplicates(subset=[\u001b[33m'\u001b[39m\u001b[33mproducto\u001b[39m\u001b[33m'\u001b[39m], keep=\u001b[33m'\u001b[39m\u001b[33mlast\u001b[39m\u001b[33m'\u001b[39m)   \u001b[38;5;66;03m# keep='last' -> la más reciente\u001b[39;00m\n\u001b[32m      5\u001b[39m     .reset_index(drop=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m      6\u001b[39m )\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# Ahora la unión será m:1 en el side derecho\u001b[39;00m\n\u001b[32m      9\u001b[39m ventas_marketing = pd.merge(\n\u001b[32m     10\u001b[39m     dic_dfs[\u001b[33m\"\u001b[39m\u001b[33mdf_ventas\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m     11\u001b[39m     mark_latest[[\u001b[33m'\u001b[39m\u001b[33mproducto\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mid_campanha\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mcanal\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mcosto\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mfecha_inicio\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mfecha_fin\u001b[39m\u001b[33m'\u001b[39m]],\n\u001b[32m   (...)\u001b[39m\u001b[32m     14\u001b[39m     validate=\u001b[33m'\u001b[39m\u001b[33mm:1\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m     15\u001b[39m )\n",
      "\u001b[31mKeyError\u001b[39m: 'df_marketing'"
     ]
    }
   ],
   "source": [
    "mark_latest = (\n",
    "    dic_dfs[\"df_marketing\"]\n",
    "    .sort_values(['producto', 'fecha_inicio'])\n",
    "    .drop_duplicates(subset=['producto'], keep='last')   # keep='last' -> la más reciente\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "# Ahora la unión será m:1 en el side derecho\n",
    "ventas_marketing = pd.merge(\n",
    "    dic_dfs[\"df_ventas\"],\n",
    "    mark_latest[['producto', 'id_campanha', 'canal', 'costo', 'fecha_inicio', 'fecha_fin']],\n",
    "    on='producto',\n",
    "    how='left',\n",
    "    validate='m:1'\n",
    ")\n",
    "dic_dfs[\"df_ventas_marketing\"] = ventas_marketing\n",
    "print (f\"\"\"\n",
    "{dic_dfs.keys()}\n",
    "{dic_dfs['df_ventas_marketing'].columns}\n",
    "{dic_dfs['df_ventas_marketing'].head(5)}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfaa0998-b391-4456-9ae0-4cfd6c1ec8ca",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#CCCCCC; padding:10px; border-radius:6px;\">\n",
    "    <h1 style=\"color:black; text-align:center;\">Integración de Datos</h1>\n",
    "    <h2 style=\"color:black; text-align:center;\">merge o concat</h2>\n",
    "    <p style=\"color:black;\">- En base a los 3 CSV 'limpios' pasados a DataFrames.</p>\n",
    "    <p style=\"color:blue;\">Intersecciones observadas:</p>\n",
    "    <ul>\n",
    "        <li style=\"color:green;\">ventas ∩ marketing → producto (clave natural para unir campañas con ventas por producto)</li>\n",
    "        <li style=\"color:red;\">ventas ∩ clientes → ninguna columna en común</li>\n",
    "        <li style=\"color:red;\">clientes ∩ marketing → ninguna columna en común</li>\n",
    "    </ul>\n",
    "    <p style=\"color:green;\">Se puede unir ventas con marketing por producto (p. ej. para ver qué canal promocionó qué producto y coste).</p>\n",
    "    <p style=\"color:red;\">No se puede unir directamente ventas con clientes porque <code>ventas_limpio</code> no contiene id_cliente ni email ni nombre_cliente.</p>\n",
    "    <p style=\"color:red;\">Para unir ventas ↔ clientes se necesita que, por ejemplo, 'ventas' tenga una columna <code>id_cliente</code>, o una tabla/fichero/map que vincule <code>id_venta → id_cliente</code>.</p>\n",
    "</div>\n",
    "<!-- dios salve lña tabulacion :)-->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd68077-86eb-4417-bc80-f0022b45e405",
   "metadata": {},
   "source": [
    "# 4.7 Agregar nuevos DFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d69aa48-fbf6-4cf6-93ba-51279e927686",
   "metadata": {},
   "outputs": [],
   "source": [
    "ventas_por_canal = (\n",
    "    dic_dfs[\"df_ventas_marketing\"]\n",
    "    .groupby('canal', dropna=False)\n",
    "    .agg(\n",
    "        total_monto=('precio_total', 'sum'),\n",
    "        cantidad_transacciones=('precio_total', 'count'),\n",
    "        ticket_promedio=('precio_total', 'mean')\n",
    "    )\n",
    "    .reset_index()\n",
    "    .sort_values('total_monto', ascending=False)\n",
    ")\n",
    "\n",
    "dic_dfs[\"df_ventas_por_canal\"] = ventas_por_canal\n",
    "print (f\"\"\"\n",
    "{dic_dfs.keys()}\n",
    "{dic_dfs['df_ventas_por_canal'].columns}\n",
    "{dic_dfs['df_ventas_por_canal'].head(5)}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603ec368-72d0-4fdb-9c09-465171540e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "ventas_categoria_canal = (\n",
    "    dic_dfs[\"df_ventas_marketing\"]\n",
    "    .groupby(['categoria', 'producto'], dropna=False)\n",
    "    .agg(\n",
    "        total_monto     = ('precio_total', 'sum'),\n",
    "        transacciones   = ('precio_total', 'count'),\n",
    "        ticket_promedio = ('precio_total', 'mean')\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "dic_dfs[\"df_ventas_categoria_canal\"] = ventas_categoria_canal\n",
    "\n",
    "# Verificar\n",
    "print(f\"\"\"\n",
    "{dic_dfs.keys()}\n",
    "{dic_dfs['df_ventas_categoria_canal'].columns}\n",
    "{dic_dfs['df_ventas_categoria_canal'].head(5)}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "546f5f4c-62b9-4444-8b3b-a302630d0fd0",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#CCCCCC; padding:10px; border-radius:6px; font-family:Arial, sans-serif; max-width:800px; margin:auto;\">\n",
    "    <h1 style=\"color:#000000; text-align:center; margin-bottom:20px;\">Agregación de Datos</h1>\n",
    "    <!-- Precio total -->\n",
    "    <section style=\"margin-bottom:20px;\">\n",
    "        <h2 style=\"color:#444; border-bottom:2px solid #888; padding-bottom:5px;\">Precio Total</h2>\n",
    "        <p style=\"color:#0000ff;\">- Resguardo en <code>datasets_salida/limpios/ventas_precio_total.csv</code> con columna <code>precio_total</code>.</p>\n",
    "    </section>\n",
    "    <!-- Ventas con marketing -->\n",
    "    <section style=\"margin-bottom:20px;\">\n",
    "        <h2 style=\"color:#444; border-bottom:2px solid #888; padding-bottom:5px;\">Ventas con Marketing</h2>\n",
    "        <p style=\"color:#0000ff;\">- Resguardo en <code>datasets_salida/limpios/ventas_marketing.csv</code>, incluye todas las ventas fusionadas con información de marketing.</p>\n",
    "    </section>\n",
    "    <!-- Canal de marketing -->\n",
    "    <section style=\"margin-bottom:20px;\">\n",
    "        <h2 style=\"color:#444; border-bottom:2px solid #888; padding-bottom:5px;\">Canal de Marketing (TV, RRSS, EMAIL)</h2>\n",
    "        <p style=\"color:#000000;\">- Monto total, cantidad de transacciones y promedio de tickets por canal.</p>\n",
    "        <p style=\"color:#0000ff;\">- Resguardo en <code>datasets_salida/limpios/ventas_por_canal.csv</code>.</p>\n",
    "    </section>\n",
    "    <!-- Categorías y productos -->\n",
    "    <section style=\"margin-bottom:20px;\">\n",
    "        <h2 style=\"color:#444; border-bottom:2px solid #888; padding-bottom:5px;\">Categorías y Productos</h2>\n",
    "        <p style=\"color:#000000;\">- Monto total, cantidad de transacciones y promedio de tickets por categoría y producto.</p>\n",
    "        <p style=\"color:#0000ff;\">- Resguardo en <code>datasets_salida/limpios/ventas_categoria_canal.csv</code>.</p>\n",
    "    </section>\n",
    "    <!-- Totales generales -->\n",
    "    <section>\n",
    "        <h2 style=\"color:#444; border-bottom:2px solid #888; padding-bottom:5px;\">Totales Generales</h2>\n",
    "        <p style=\"color:#000000;\">- Monto total y cantidad total de ventas.</p>\n",
    "        <p style=\"color:#0000ff;\">- Resguardo en <code>datasets_salida/limpios/ventas_y_cant_totales.csv</code>.</p>\n",
    "    </section>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ed38b2-a0ed-4460-aa3b-a038dd80ee27",
   "metadata": {},
   "outputs": [],
   "source": [
    "por_articulos = (\n",
    "    dic_dfs[\"df_ventas\"] .groupby(['categoria', 'producto'], dropna=False)\n",
    "         .agg(\n",
    "             cantidad_total=('cantidad', 'sum'),\n",
    "             precio_total=('precio_total', 'sum')\n",
    "         )\n",
    "         .reset_index()\n",
    "         .sort_values(['categoria', 'precio_total'], ascending=[True, False])\n",
    ")\n",
    "dic_dfs[\"df_cant_ventas_totales\"] = por_articulos\n",
    "print (f\"\"\"\n",
    "{dic_dfs.keys()}\n",
    "{dic_dfs['df_cant_ventas_totales'].columns}\n",
    "{dic_dfs['df_cant_ventas_totales'].head(5)}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76bc602c-9efa-44fa-a915-0a79e0005262",
   "metadata": {},
   "source": [
    "# 4.8 Graficos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c81f07-163b-4c4a-bdd4-9bee5fa17e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionar los 10 productos más vendidos (por monto)\n",
    "top_productos = dic_dfs[\"df_cant_ventas_totales\"].sort_values('precio_total', ascending= False).head(10)\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.barh(top_productos['producto'], top_productos['precio_total'], color='skyblue')\n",
    "plt.title('Top 10 productos más vendidos')\n",
    "plt.xlabel('Monto total vendido ($)')\n",
    "plt.ylabel('Producto')\n",
    "plt.gca().invert_yaxis()  # El más alto arriba\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6caf7143-4182-4997-ae06-beac0eda40b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "nombres_nuevos = {\n",
    "                \"ventas_y_cant_totales.csv\":dic_dfs[\"df_cant_ventas_totales\"],\n",
    "                \"ventas_marketing.csv\":dic_dfs[\"df_ventas_marketing\"],\n",
    "                \"ventas_por_canal.csv\":dic_dfs[\"df_ventas_por_canal\"],\n",
    "                \"ventas_categoria_canal.csv\":dic_dfs[\"df_ventas_categoria_canal\"]\n",
    "                 }\n",
    "\n",
    "for nombre_nuevo,df_actual in nombres_nuevos.items():\n",
    "    print(f'nombre_nuevo = {nombre_nuevo}')\n",
    "    ruta_guardado = carpeta_limpios / nombre_nuevo\n",
    "    guardar_csv(df_actual, ruta_guardado)\n",
    "    print(f'Guardado cleaned en: {ruta_guardado}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be7ea93-526e-4b9a-b514-5c108454a785",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "sns.barplot(data=top_productos, x='precio_total', y='producto', hue='categoria')\n",
    "plt.title('Top 10 productos por categoría')\n",
    "plt.xlabel('Monto total vendido ($)')\n",
    "plt.ylabel('Producto')\n",
    "plt.legend(title='Categoría')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac691bd-d59b-41cc-88d8-a3baf48602a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "plt.bar(ventas_por_canal['canal'], ventas_por_canal['total_monto'])\n",
    "plt.title('Ventas totales por canal')\n",
    "plt.xlabel('Canal de venta')\n",
    "plt.ylabel('Monto total vendido ($)')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deed74fa-7be4-4611-98f4-40adc3963827",
   "metadata": {},
   "source": [
    "# 4.9 Reportes\n",
    "##  4.9.1 Reportes ventas_mensuales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0737e69-7b61-4fa9-b678-3a178e09b62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (f\"\"\"Elimino dia de fecha para que quede YYYY/MM\n",
    "{dic_dfs[\"df_ventas\"].columns}\n",
    "\"\"\")\n",
    "\n",
    "dic_dfs[\"df_ventas\"]['mes'] = dic_dfs[\"df_ventas\"]['fecha_venta'].dt.to_period('M').astype(str)\n",
    "ventas_mensuales = (\n",
    "    dic_dfs[\"df_ventas\"].groupby('mes', dropna=False)\n",
    "         .agg(\n",
    "             cantidad_total=('cantidad', 'sum'),\n",
    "             precio_total=('precio_total', 'sum')\n",
    "         )\n",
    "         .reset_index()\n",
    "         .sort_values('mes')\n",
    ")\n",
    "\n",
    "print(f\"\"\"{Fore.WHITE+Back.BLUE}\\n\n",
    "╔═════════════════════════════════════════════════════════════════════════════╗\n",
    "║                             REPORTE VENTAS MENSUALES                        ║\n",
    "╠═════════════════════════════════════════════════════════════════════════════╣\"\"\")\n",
    "for idx, fila in ventas_mensuales.iterrows():\n",
    "    print(f\"\"\"║ {f\"Mes: {fila['mes']},   Cantidad total: {fila['cantidad_total']},   Monto total: {fila['precio_total']}\".ljust(75)} ║\"\"\")\n",
    "print (f\"\"\"╚═════════════════════════════════════════════════════════════════════════════╝{Style.RESET_ALL}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c718e8b-5d0e-4577-b116-d43534a92e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# monto total por mes 1\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(ventas_mensuales['mes'], ventas_mensuales['precio_total'], marker='o', linewidth=2)\n",
    "plt.title('Evolución de ventas mensuales (monto total)')\n",
    "plt.xlabel('Mes')\n",
    "plt.ylabel('Monto total vendido ($)')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5506e771-f0f3-4f5d-9f3f-ab15f2390e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  cantidad total por mes 2\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.bar(ventas_mensuales['mes'], ventas_mensuales['cantidad_total'])\n",
    "plt.title('Evolución de ventas mensuales (cantidad de artículos)')\n",
    "plt.xlabel('Mes')\n",
    "plt.ylabel('Cantidad total vendida')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a1ef4b-d331-429f-896b-ec94f0a54cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  precio total por mes 3 torta\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.pie(\n",
    "    ventas_mensuales['precio_total'],\n",
    "    labels=ventas_mensuales['mes'],\n",
    "    autopct='%1.1f%%',\n",
    "    startangle=90,\n",
    "    counterclock=False\n",
    ")\n",
    "\n",
    "plt.title('Distribución porcentual de ventas mensuales (monto total)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5261a3ea-59ba-4edc-a026-a592c7010fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  monto total por mes 3 torta\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.pie(\n",
    "    ventas_mensuales['cantidad_total'],\n",
    "    labels=ventas_mensuales['mes'],\n",
    "    autopct='%1.1f%%',\n",
    "    startangle=90,\n",
    "    counterclock=False\n",
    ")\n",
    "plt.title('Distribución porcentual de ventas mensuales (cantidad de artículos)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c01e4d7-9121-4aa5-be28-34b0dc1e4a2e",
   "metadata": {},
   "source": [
    "## 4.9.2 Reportes percentil_80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65774cce-e62e-4a81-826a-260f0f04fb0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "percentil_80 = dic_dfs[\"df_ventas\"][\"precio_total\"].quantile(0.80)\n",
    "print(f\"\")\n",
    "print(f\"\"\"{Fore.WHITE+Back.BLUE}\\n\n",
    "╔═════════════════════════════════════════════════════════════════════════════╗\n",
    "║                              REPORTE VENTAS TOTALES                         ║\n",
    "║                 El percentil 80 del valor total es: {str(round(percentil_80,2)).center(10)}              ║\n",
    "╚═════════════════════════════════════════════════════════════════════════════╝{Style.RESET_ALL}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff94e3c9-a0d6-451b-bd8a-4e2d9a24ecb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (F\"\"\"\"\n",
    "{dic_dfs[\"df_ventas\"].columns}\n",
    "\n",
    "\"\"\")\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.hist(dic_dfs[\"df_ventas\"][\"precio_total\"], bins=30)\n",
    "plt.axvline(percentil_80, color='red', linestyle='--', label=f'Percentil 80 = {percentil_80:,.0f}')\n",
    "plt.title(\"Distribución del valor total de ventas\")\n",
    "plt.xlabel(\"Precio × Cantidad (Valor total)\")\n",
    "plt.ylabel(\"Frecuencia\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8458180f-25cd-447e-beec-174b8096d24b",
   "metadata": {},
   "source": [
    "## 4.9.3 Reportes ventas_alto_rendimiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285d8fa3-ce75-4292-9636-55b2fe87b2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filtrar las ventas “de alto rendimiento”\n",
    "ventas_alto_rendimiento = dic_dfs[\"df_ventas\"][\n",
    "    dic_dfs[\"df_ventas\"][\"precio_total\"] > percentil_80\n",
    "]\n",
    "\n",
    "print(f\"Ventas de alto rendimiento encontradas: {len(ventas_alto_rendimiento)} registros\")\n",
    "print (ventas_alto_rendimiento.columns)\n",
    "print (ventas_alto_rendimiento.head())\n",
    "#Index(['id_venta', 'producto', 'precio', 'cantidad', 'fecha_venta', 'categoria', 'precio_total', 'mes\n",
    "print(f\"\"\"{Fore.WHITE+Back.BLUE}\\n\n",
    "╔═════════════════════════════════════════════════════════════════════════════╗\n",
    "║                      REPORTE VENTAS DE ALTO RENDIMIENTO                     ║\n",
    "║             50 primeras ventas de alto rendimiento encontradas              ║\n",
    "╠═════════════════════════════════════════════════════════════════════════════╣\"\"\")\n",
    "for idx, fila in ventas_alto_rendimiento.head(50).iterrows():\n",
    "    print(f\"\"\"║ {f\"Mes: {fila['mes']},   Cantidad total: {fila['cantidad']},   Monto total: {fila['precio_total']}\".ljust(75)} ║\"\"\")\n",
    "print (f\"\"\"╚═════════════════════════════════════════════════════════════════════════════╝{Style.RESET_ALL}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed7d3ae-d4be-4567-a2aa-b4ae44be27c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
